<!-- This layout is used in all pages. Making changes here will efect all pages. We recommend not to change anything here. --> <!DOCTYPE html><html lang="en"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" /><link rel="dns-prefetch" href="//fonts.googleapis.com" /><link rel="dns-prefetch" href="//google-analytics.com" /><link rel="dns-prefetch" href="//www.google-analytics.com" /><link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com" /><link rel="dns-prefetch" href="//ajax.googleapis.com" /><link rel="dns-prefetch" href="//fonts.gstatic.com" /><link rel="dns-prefetch" href="https://webjeda-demo.disqus.com/" /><title>Corporate Credit Rating Forecasting | Blackcurrant</title><meta name="generator" content="Jekyll v3.8.4" /><meta property="og:title" content="Corporate Credit Rating Forecasting" /><meta name="author" content="Alan Gewerc" /><meta property="og:locale" content="en_US" /><meta name="description" content="Introduction This notebook contains the results of the data analysis performed on a set of corporate credit ratings given by ratings agencies to a set of companies. The aim of the data analysis is to build a machine learning model from the rating data that can be used to predict the rating a company will receive. The first section section of the notebook shows the exploratory data analysis (EDA) performed to explore and understand the data. It looks at each attribute (variable) in the data to understand the nature and distribution of the attribute values. It also examines the correlation between the variables through visual analysis. A summary at the end highlights the key findings of the EDA. The second section shows the development of a machine learning model. Many diffferent models are tested and the performance of all models are compared. Subsequently, a winner is selected and we do hyperparameter tunning. In the model evaluation step we use different techniques such as a confusion matrix and scores as F1, Precision and Recall to understand different aspects of the performance of the model. We also perform feature selection to know what financial indicators are more relevant for the rating agencies. The Dataset There are 30 features for every company of which 25 are financial indicators. They can be divided in: Liquidity Measurement Ratios: currentRatio, quickRatio, cashRatio, daysOfSalesOutstanding Profitability Indicator Ratios: grossProfitMargin, operatingProfitMargin, pretaxProfitMargin, netProfitMargin, effectiveTaxRate, returnOnAssets, returnOnEquity, returnOnCapitalEmployed Debt Ratios: debtRatio, debtEquityRatio Operating Performance Ratios: assetTurnover Cash Flow Indicator Ratios: operatingCashFlowPerShare, freeCashFlowPerShare, cashPerShare, operatingCashFlowSalesRatio, freeCashFlowOperatingCashFlowRatio Libraries used: pandas numpy matplotlib seaborn random sklearn xgboost wordcloud Load the Libraries used in the notebook import pandas as pdf import numpy as np from numpy import loadtxt from numpy import sort import matplotlib.pyplot as plt %matplotlib inline from matplotlib.ticker import PercentFormatter import matplotlib.ticker as mtick from wordcloud import WordCloud, STOPWORDS from random import sample import seaborn as sns import xgboost as xgb from xgboost import XGBClassifier from sklearn .... Import Dataset df_rating = pd.read_csv(&#39;data/corporate_rating.csv&#39;) Exploratory Data Analysis Our first step is to perform an exploratory data analysis to understand the charateristics of dataset. Here are some quesitons we will try to adress: What are the dimensions of the data? How do predictors relate to each other? What are the classes of the data? How are the predictors distributed? How are the labels distributed? Do we have missing values? Are outliers are relevant? Are there any transformations that must be done with the dataset? # Display the dimensions print(&quot;The credit rating dataset has&quot;, df_rating.shape[0], &quot;records, each with&quot;, df_rating.shape[1], &quot;attributes&quot;) The credit rating dataset has 2029 records, each with 31 attributes We will now use the function .info() to see the classes of columns and search missing values. # Display the structure df_rating.info() RangeIndex: 2029 entries, 0 to 2028 Data columns (total 31 columns): Rating 2029 non-null object Name 2029 non-null object Symbol 2029 non-null object Rating Agency Name 2029 non-null object Date 2029 non-null object Sector 2029 non-null object currentRatio 2029 non-null float64 quickRatio 2029 non-null float64 cashRatio 2029 non-null float64 daysOfSalesOutstanding 2029 non-null float64 netProfitMargin 2029 non-null float64 pretaxProfitMargin 2029 non-null float64 grossProfitMargin 2029 non-null float64 operatingProfitMargin 2029 non-null float64 returnOnAssets 2029 non-null float64 ... dtypes: float64(25), object(6) memory usage: 491.5+ KB We have 26 columns of numerical data and 6 descriptive columns (one of which is the label).There are no missing values. A first look at the data: df_rating.head() Rating Name Symbol Rating Agency Name Date Sector currentRatio ... 0 A Whirlpool Corporation WHR Egan-Jones Ratings Company 11/27/2015 Consumer Durables 0.945894 ... 1 BBB Whirlpool Corporation WHR Egan-Jones Ratings Company 2/13/2014 Consumer Durables 1.033559 ... 2 BBB Whirlpool Corporation WHR Fitch Ratings 3/6/2015 Consumer Durables 0.963703 ... 3 BBB Whirlpool Corporation WHR Fitch Ratings 6/15/2012 Consumer Durables 1.019851 ... 4 BBB Whirlpool Corporation WHR Standard &amp; Poor&#39;s Ratings Services 10/24/2016 Consumer Durables 0.957844 ... 5 rows × 31 columns Analyse Labels As we know we are working with ordinal labels. That means there is a scale from more secure to less secure ratings. For instance, the triple-A (AAA) is the most secure rating a company can receive. On the other hand, the rating D is the less secure. It means the company will likely default on its creditors. Let’s have a first look at the how many reatings we have of each in the dataset. df_rating.Rating.value_counts() BBB 671 BB 490 A 398 B 302 AA 89 CCC 64 AAA 7 CC 5 C 2 D 1 Name: Rating, dtype: int64 We observe that the dataset is very unbalanced. We have 671 triple-Bs (BBB) but only 1 D. However, we are working with Ratings from different companies such as Moody&#39;s, Standard &amp; Poor&#39;s and more. Therefore it is preferred to simplify the labels according to this table from the website investopedia. We will classify our labels according to the grading risk and not the rate. Bond Rating         Moody’s Standard &amp; Poor’s Fitch Grade Risk Aaa AAA AAA Investment Lowest Risk Aa AA AA Investment Low Risk A A A Investment Low Risk Baa BBB BBB Investment Medium Risk Ba, B BB, B BB, B Junk High Risk Caa/Ca CCC/CC/C CCC/CC/C Junk Highest Risk C D D Junk In Default To do it we will replace with a dictonary each of this ratings. rating_dict = {&#39;AAA&#39;:&#39;Lowest Risk&#39;, &#39;AA&#39;:&#39;Low Risk&#39;, &#39;A&#39;:&#39;Low Risk&#39;, &#39;BBB&#39;:&#39;Medium Risk&#39;, &#39;BB&#39;:&#39;High Risk&#39;, &#39;B&#39;:&#39;High Risk&#39;, &#39;CCC&#39;:&#39;Highest Risk&#39;, &#39;CC&#39;:&#39;Highest Risk&#39;, &#39;C&#39;:&#39;Highest Risk&#39;, &#39;D&#39;:&#39;In Default&#39;} df_rating.Rating = df_rating.Rating.map(rating_dict) ax = df_rating[&#39;Rating&#39;].value_counts().plot(kind=&#39;bar&#39;, figsize=(8,4), title=&quot;Count of Rating by Type&quot;, grid=True) Unfortunately, given the lack of Credit Ratings classified as Lowest Risk and In Default we will have to eliminate then from the table. However, the dataset will keep unbalanced and if needed we will have to adress this issue in further steps. df_rating = df_rating[df_rating[&#39;Rating&#39;]!=&#39;Lowest Risk&#39;] # filter Lowest Risk df_rating = df_rating[df_rating[&#39;Rating&#39;]!=&#39;In Default&#39;] # filter In Default df_rating.reset_index(inplace = True, drop=True) # reset index Descriptive Statistics Now we will use statistical tools, especially from pandas to improve the understanding from the dataset, especially the numerical features. We have seen there are 25 numerical columns in the dataset, all of each are financial indicators from the companies. The function describe() returns information about the distribution of the data such as quantiles, min and max. # Statistical summary df_rating.describe() currentRatio quickRatio cashRatio daysOfSalesOutstanding netProfitMargin ... count 2021.000000 2021.000000 2021.000000 2021.000000 2021.000000 ... 2021.000000 mean 3.535411 2.657150 0.669048 334.855415 0.278725 ... std 44.139386 33.009920 3.590902 4456.606352 6.076128 ... min -0.932005 -1.893266 -0.192736 -811.845623 -101.845815 ... 25% 1.071930 0.602298 0.131433 22.806507 0.020894 ... 50% 1.492804 0.979094 0.297859 42.281804 0.064323 ... 75% 2.160710 1.450457 0.625355 59.165369 0.113871 ... max 1725.505005 1139.541703 125.917417 115961.637400 198.517873 ... 8 rows × 25 columns Skewness and Outliers We observe a lot of skewness in the data with this first exploration. In this case, it means that most variables in the dataset may strong presence of outliers. Taking as observation the table above the first column: currentRatio: This 50% of its variables between 1.071 and 2.166891. The minimum value is -0.932005 however the maximum value is 1725.505005. It means, in other words, there is a giant outlier that is extremely distant from most points from the data (currentRatio). The same pattern can be observed in the following columns such as quickRatio, cashRatio, daysOfSalesOutstanding, netProfitMargin and so on. To observe how this reflect on the distribution of the data lets make some plots of variables chose randomly. column_list = list(df_rating.columns[6:31]) column_list = sample(column_list,4) print(column_list) [&#39;operatingCashFlowSalesRatio&#39;, &#39;grossProfitMargin&#39;, &#39;returnOnEquity&#39;, &#39;companyEquityMultiplier&#39;] &lt;/samp&gt; figure, axes = plt.subplots(nrows=2, ncols=4, figsize=(9,5)) axes[0, 0].hist(df_rating[column_list[0]]) axes[0, 1].hist(df_rating[column_list[1]]) axes[1, 0].hist(df_rating[column_list[2]]) axes[1, 1].hist(df_rating[column_list[3]]) axes[0, 2].boxplot(df_rating[column_list[0]]) axes[1, 2].boxplot(df_rating[column_list[1]]) axes[0, 3].boxplot(df_rating[column_list[2]]) axes[1, 3].boxplot(df_rating[column_list[3]]) figure.tight_layout() As predicted, the data is comtaminated by outliers. We canot observe real behaviour of the distribution because some points differ too much from the others. We will use the function .skew from pandas in all columns. It should return between 0 and 1 if a column is normally distributed. df_rating.skew(axis=0) currentRatio 34.271115 quickRatio 30.864610 cashRatio 27.046952 daysOfSalesOutstanding 20.359098 netProfitMargin 17.585073 pretaxProfitMargin 22.052558 grossProfitMargin -14.198688 operatingProfitMargin 26.441502 returnOnAssets -32.049111 returnOnCapitalEmployed -33.252701 returnOnEquity 31.639845 assetTurnover 25.968848 fixedAssetTurnover 26.068762 debtEquityRatio 0.268074 debtRatio 1.284256 effectiveTaxRate 32.265705 freeCashFlowOperatingCashFlowRatio -22.868222 freeCashFlowPerShare 33.610677 cashPerShare 33.958646 companyEquityMultiplier 0.268175 ebitPerRevenue 22.055668 enterpriseValueMultiple 13.920117 operatingCashFlowPerShare 30.292914 operatingCashFlowSalesRatio 25.400129 payablesTurnover 25.868293 dtype: float64 We observe this is a generalized problem. As we can see almost all columns are extremely skewed. We will now go deeper in the investigation of outliers. The following code will return the proportion of outliers in each column . The definition of outlier will be the one from the boxplot - above or bellow 1.5 x IQR. for c in df_rating.columns[6:31]: q1 = df_rating[c].quantile(0.25) q3 = df_rating[c].quantile(0.75) iqr = q3 - q1 #Interquartile range fence_low = q3-1.5*iqr fence_high = q1+1.5*iqr lower_out = len(df_rating.loc[(df_rating[c] &lt; fence_low) ,c]) upper_out = len(df_rating.loc[(df_rating[c] &gt; fence_high) ,c]) outlier_count = upper_out+lower_out prop_out = outlier_count/len(df_rating) print(c, &quot;: &quot;+&quot;{:.2%}&quot;.format(prop_out)) currentRatio : 18.01% quickRatio : 19.05% cashRatio : 14.84% daysOfSalesOutstanding : 23.55% netProfitMargin : 25.09% pretaxProfitMargin : 24.49% grossProfitMargin : 0.99% operatingProfitMargin : 22.12% returnOnAssets : 24.25% returnOnCapitalEmployed : 22.07% returnOnEquity : 28.70% assetTurnover : 15.83% fixedAssetTurnover : 13.46% debtEquityRatio : 22.07% debtRatio : 21.33% effectiveTaxRate : 28.06% freeCashFlowOperatingCashFlowRatio : 16.92% freeCashFlowPerShare : 23.55% cashPerShare : 17.12% companyEquityMultiplier : 22.02% ebitPerRevenue : 24.34% enterpriseValueMultiple : 23.70% operatingCashFlowPerShare : 17.66% operatingCashFlowSalesRatio : 16.87% payablesTurnover : 14.45% Most columns have a significant number of outliers. However it is not clear for us if there are a few rows that all outliers or each of the rows may be contributing individually with some outliers. We will now check by row the distribution of outliers. We will create a new dataframe that df_rating_outlier that will be used with this purpose. In this dataframe every cell will 1 one if the corresponding cell is an outlier in df_raint and 0 if it is not. df_rating_outlier = df_rating.copy() for c in df_rating_outlier.columns[6:31]: q1 = df_rating_outlier[c].quantile(0.25) q3 = df_rating_outlier[c].quantile(0.75) iqr = q3 - q1 #Interquartile range fence_low = q3-1.5*iqr fence_high = q1+1.5*iqr for i in range(len(df_rating_outlier)): if df_rating.loc[i,c] &lt; fence_low or df_rating.loc[i,c] &gt; fence_high: # if Outlier df_rating_outlier.loc[i,c] = 1 else: # Not Outlier df_rating_outlier.loc[i,c] = 0 Now we will be able to count how many outliers each row has and plot it. df_rating_outlier[&quot;total&quot;] = df_rating_outlier.sum(axis=1) df_rating_outlier.total.hist(bins = 20) This is a very interesting plot. We can see that only up to 400 rows don’t have any outliers. Most rows have outliers and maybe they will be useful in the further classification tasks. Therefore we see no value in excluding the outliers from the dataset. However we will perform a transformation on the data so we can reduce its negative impact. Data reshaping We will now perform the following steps in each of the numerical data. Normalize the data between 0 and 1 (and multiply by 1.000). Apply log on base 10 on each of the variables. from sklearn import preprocessing min_max_scaler = preprocessing.MinMaxScaler() for c in df_rating.columns[6:31]: df_rating[[c]] = min_max_scaler.fit_transform(df_rating[[c]].to_numpy())*1000 df_rating[[c]] = df_rating[c].apply(lambda x: np.log10(x+0.01)) Again the plots figure, axes = plt.subplots(nrows=2, ncols=4, figsize=(9,5)) axes[0, 0].hist(df_rating[column_list[0]]) axes[0, 1].hist(df_rating[column_list[1]]) axes[1, 0].hist(df_rating[column_list[2]]) axes[1, 1].hist(df_rating[column_list[3]]) axes[0, 2].boxplot(df_rating[column_list[0]]) axes[1, 2].boxplot(df_rating[column_list[1]]) axes[0, 3].boxplot(df_rating[column_list[2]]) axes[1, 3].boxplot(df_rating[column_list[3]]) figure.tight_layout() We have a problem with respect to vizualisation of the data. The impact of the outliers is so big that we cannot observe the patterns in the data. To enhance our visualization we will from now ignore outliers. We will replace then by values with lower impact such as the lower hinge. In this way we will be able to continue with our EDA. To preserve our dataset we will use a new table called df_rating_no_out. df_rating_no_out = df_rating.copy() for c in df_rating_no_out.columns[6:31]: q05 = df_rating_no_out[c].quantile(0.10) q95 = df_rating_no_out[c].quantile(0.90) iqr = q95 - q05 #Interquartile range fence_low = q05-1.5*iqr fence_high = q95+1.5*iqr df_rating_no_out.loc[df_rating_no_out[c] &gt; fence_high,c] = df_rating_no_out[c].quantile(0.25) df_rating_no_out.loc[df_rating_no_out[c] &lt; fence_low,c] = df_rating_no_out[c].quantile(0.75) Now that we have this dataframe we can use it use it to observe the data from a different angle. We will be able to observe the distribution that was hidden by the outliers. The first step: Plot all columns (boxplot) by each label:High Risk, Low Risk, Medium Risk, Highest Risk. figure, axes = plt.subplots(nrows=8, ncols=3, figsize=(20,44)) i = 0 j = 0 for c in df_rating_no_out.columns[6:30]: sns.boxplot(x=df_rating_no_out.Rating, y=df_rating_no_out[c], palette=&quot;Set3&quot;, ax=axes[i, j]) if j == 2: j=0 i+=1 else: j+=1 The most interesting point about the previous plots is the fact that they clearly show a difference in the medians and distribution according to the rating (Risk). It points to a scenario where the variables will have good predictive power for classification. Following with our analysis we will create scatter plots to see if we can observe who the variables relate to each other and how labels can be observer in respect to it. df_rating.colors = &#39;a&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Lowest Risk&#39;, &#39;color&#39;] = &#39;r&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Low Risk&#39;, &#39;color&#39;] = &#39;g&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Medium Risk&#39;, &#39;color&#39;] = &#39;b&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;High Risk&#39;,&#39;color&#39;] = &#39;y&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Highest Risk&#39;, &#39;color&#39;] = &#39;m&#39; column_list = list(df_rating.columns[6:31]) column_list = sample(column_list,12) figure, axes = plt.subplots(nrows=3, ncols=2, figsize=(14,14)) i = 0 j = 0 for c in range(0,12, 2): sns.scatterplot(x = column_list[c], y=column_list[c+1], hue=&quot;color&quot;, data=df_rating_no_out, ax=axes[j,i]) if i == 1: i = 0 j +=1 else: i+=1 In fact, we are working with a dataset that has a big numer of dimensions. With two variables it would not be possible to make any predictions. However this is not the case. Unfortunately we are not able to vizualise the data in all its dimensions, but luckely we will be able to perform accurate classificaitons. Machine Learning Is it possible to predict what creidt profile a company will receive from a rating agency based on its financial indicators? If so, what are the most important predictors? Apparently not much work has been done with regards to this question. This academic paper was the only work found about it. It is worth checking it out. As we will do it, it tests most ML algorithms and identifies the most important features. In the following steps we will perform the following: Prepare the dataset Split in train and test Transform/Encode the features kand labels Test a wide range of ML models (Tree-based, Probabilistic and so on). Compare the accuracry of all models. Choose our winning model and tune hyperparameters to target a higher accuracy. Make a more profound evaluation of the result with a confusion matrix and different measures. identify the most important features to predict the rating. Prepare the Dataset le = preprocessing.LabelEncoder() le.fit(df_rating.Sector) df_rating.Sector = le.transform(df_rating.Sector) # encode sector le.fit(df_rating.Rating) df_rating.Rating = le.transform(df_rating.Rating) # encode rating df_train, df_test = train_test_split(df_rating, test_size=0.2, random_state = 1234) X_train, y_train = df_train.iloc[:,5:31], df_train.iloc[:,0] X_test, y_test = df_test.iloc[:,5:31], df_test.iloc[:,0] Fit Models Now we will test a range of models. In each we will fit the model in the train data, make predictons for the test data and obtain the accuracy. In later steps we will compare the accuracy of all the models. We will use primarily the library sklearn but also XGBoost. XGBoost XGB_model = xgb.XGBRegressor(objective =&#39;multi:softmax&#39;, num_class =4) XGB_model.fit(X_train, y_train) y_pred_XGB = XGB_model.predict(X_test) Accuracy_XGB = metrics.accuracy_score(y_test, y_pred_XGB) print(&quot;XGB Accuracy:&quot;,Accuracy_XGB) XGB Accuracy: 0.691358024691358 Gradient Boosting Classifier GBT_model = GradientBoostingClassifier(random_state=123) GBT_model.fit(X_train, y_train) y_pred_GBT = GBT_model.predict(X_test) Accuracy_GBT = metrics.accuracy_score(y_test, y_pred_GBT) print(&quot;GBT Accuracy:&quot;,Accuracy_GBT) GBT Accuracy: 0.6320987654320988 Random Forest RF_model = RandomForestClassifier(random_state=1234) RF_model.fit(X_train,y_train) y_pred_RF = RF_model.predict(X_test) Accuracy_RF = metrics.accuracy_score(y_test, y_pred_RF) print(&quot;RF Accuracy:&quot;,Accuracy_RF) RF Accuracy: 0.6246913580246913 Support Vector Machine SVC_model = svm.SVC(kernel=&#39;rbf&#39;, gamma= 2, C = 5, random_state=1234) SVC_model.fit(X_train, y_train) y_pred_SVM = SVC_model.predict(X_test) Accuracy_SVM = metrics.accuracy_score(y_test, y_pred_SVM) print(&quot;SVM Accuracy:&quot;,Accuracy_SVM) SVM Accuracy: 0.5333333333333333 Neural Network MLP_model = MLPClassifier(hidden_layer_sizes=(5,5,5), activation=&#39;logistic&#39;, solver=&#39;adam&#39;, max_iter=1500) MLP_model.fit(X_train, y_train) y_pred_MLP = MLP_model.predict(X_test) Accuracy_MLP = metrics.accuracy_score(y_test, y_pred_MLP) print(&quot;MLP Accuracy:&quot;,Accuracy_MLP) MLP Accuracy: 0.3654320987654321 Naive Bayes GNB_model = GaussianNB() GNB_model.fit(X_train, y_train) y_pred_GNB = GNB_model.predict(X_test) Accuracy_GNB = metrics.accuracy_score(y_test, y_pred_GNB) print(&quot;GNB Accuracy:&quot;,Accuracy_GNB) GNB Accuracy: 0.30864197530864196 Linear Discriminant Analysis LDA_model = LinearDiscriminantAnalysis() LDA_model.fit(X_train,y_train) y_pred_LDA = LDA_model.predict(X_test) Accuracy_LDA = metrics.accuracy_score(y_test, y_pred_LDA) print(&quot;LDA Accuracy:&quot;,Accuracy_LDA) LDA Accuracy: 0.38765432098765434 Quadratic Discriminant Analysis QDA_model = QuadraticDiscriminantAnalysis() QDA_model.fit(X_train,y_train) y_pred_QDA = QDA_model.predict(X_test) Accuracy_QDA = metrics.accuracy_score(y_test, y_pred_QDA) print(&quot;QDA Accuracy:&quot;,Accuracy_QDA) QDA Accuracy: 0.35555555555555557 K Nearest Neighbours KNN_model = KNeighborsClassifier(n_neighbors = 3) KNN_model.fit(X_train,y_train) y_pred_KNN = KNN_model.predict(X_test) Accuracy_KNN = metrics.accuracy_score(y_test, y_pred_KNN) print(&quot;KNN Accuracy:&quot;,Accuracy_KNN) KNN Accuracy: 0.5802469135802469 Logistic Regression LR_model = LogisticRegression(random_state=1234 , multi_class=&#39;multinomial&#39;, solver=&#39;newton-cg&#39;) LR_model = LR_model.fit(X_train, y_train) y_pred_LR = LR_model.predict(X_test) Accuracy_LR = metrics.accuracy_score(y_test, y_pred_LR) print(&quot;LR Accuracy:&quot;,Accuracy_LR) LR Accuracy: 0.3925925925925926 Compare Results accuracy_list = [Accuracy_XGB, Accuracy_GBT, Accuracy_RF, Accuracy_SVM, Accuracy_MLP, Accuracy_GNB, Accuracy_LDA, Accuracy_QDA, Accuracy_KNN, Accuracy_LR] model_list = [&#39;XGBboost&#39;, &#39;Gradient Boosting&#39;, &#39;Random Forest&#39;, &#39;Support Vector Machine&#39;, &quot;Neural Network&quot;, &#39;Naive Bayes&#39;, &#39;Linear Discriminat&#39;, &#39;Quadratic Discriminat&#39;, &#39;KNN&#39;, &#39;Logistic Regression&#39;] df_accuracy = pd.DataFrame({&#39;Model&#39;: model_list, &#39;Accuracy&#39;: accuracy_list}) order = list(df_accuracy.sort_values(&#39;Accuracy&#39;, ascending=False).Model) df_accuracy = df_accuracy.sort_values(&#39;Accuracy&#39;, ascending=False).reset_index().drop([&#39;index&#39;], axis=1) plt.figure(figsize=(12,8)) # make barplot and sort bars x = sns.barplot(x=&#39;Model&#39;, y=&quot;Accuracy&quot;, data=df_accuracy, order = order, palette=&quot;rocket&quot;) plt.xlabel(&quot;Model&quot;, fontsize=20) plt.ylabel(&quot;Accuracy&quot;, fontsize=20) plt.title(&quot;Accuracy by Model&quot;, fontsize=20) plt.grid(linestyle=&#39;-&#39;, linewidth=&#39;0.5&#39;, color=&#39;grey&#39;) plt.xticks(rotation=70, fontsize=12) plt.ylim(0,1) plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1)) for i in range(len(model_list)): plt.text(x = i, y = df_accuracy.loc[i, &#39;Accuracy&#39;] + 0.05, s = str(round((df_accuracy.loc[i, &#39;Accuracy&#39;])*100, 2))+&#39;%&#39;, fontsize = 14, color=&#39;black&#39;,horizontalalignment=&#39;center&#39;) y_value=[&#39;{:,.2f}&#39;.format(x) + &#39;%&#39; for x in ax.get_yticks()] ax.set_yticklabels(y_value) plt.tight_layout() We have our winner. XGboost is the best performing model. XGBoost Hyperparameter Tunning The XGboost model has achieved a very high accuracy given that we have 4 different classes. Now we will try to increase the performance even more. We will use a cross-validation approach and we will follow similar steps to this tutorial. First we load the train and test data into DMatrices. DMatrix is a data structure used by XGBoost to optimize both memory efficiency and training speed. dtrain = xgb.DMatrix(X_train, label=y_train) dtest = xgb.DMatrix(X_test, label=y_test) The params dictionary We create a dictonary with the parameters from our previous XGboost model. params = XGB_model.get_xgb_params() {&#39;objective&#39;: &#39;multi:softmax&#39;, &#39;base_score&#39;: 0.5, &#39;booster&#39;: &#39;gbtree&#39;, &#39;colsample_bylevel&#39;: 1, &#39;colsample_bynode&#39;: 1, &#39;colsample_bytree&#39;: 1, &#39;gamma&#39;: 0, &#39;gpu_id&#39;: -1, &#39;interaction_constraints&#39;: &#39;&#39;, &#39;learning_rate&#39;: 0.300000012, &#39;max_delta_step&#39;: 0, &#39;max_depth&#39;: 6, &#39;min_child_weight&#39;: 1, &#39;monotone_constraints&#39;: &#39;()&#39;, &#39;n_jobs&#39;: 0, &#39;num_parallel_tree&#39;: 1, &#39;random_state&#39;: 0, &#39;reg_alpha&#39;: 0, &#39;reg_lambda&#39;: 1, &#39;scale_pos_weight&#39;: None, &#39;subsample&#39;: 1, &#39;tree_method&#39;: &#39;exact&#39;, &#39;validate_parameters&#39;: 1, &#39;verbosity&#39;: None, &#39;num_class&#39;: 4} We will use the merror error parameter from classification. It is basic an accuracy. params[&#39;eval_metric&#39;] = &quot;merror&quot; The num_boost_round which corresponds to the maximum number of boosting rounds that we allow. num_boost_round = 1000 model = xgb.train( params, dtrain, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)], early_stopping_rounds=50, verbose_eval=30) print(&quot;Best merror: {:.2f} with {} rounds&quot;.format( model.best_score, model.best_iteration+1)) [0] Test-merror:0.44691&lt;br&gt; Will train until Test-merror hasn&#39;t improved in 50 rounds.&lt;br&gt; [30] Test-merror:0.34568&lt;br&gt; [60] Test-merror:0.32839&lt;br&gt; [90] Test-merror:0.30617&lt;br&gt; [120] Test-merror:0.30864&lt;br&gt; [150] Test-merror:0.30864&lt;br&gt; Stopping. Best iteration:&lt;br&gt; [104] Test-merror:0.29877&lt;br&gt; Best merror: 0.30 with 105 rounds Using XGBoost’s CV In order to tune the other hyperparameters, we will use the cv function from XGBoost. It allows us to run cross-validation on our training dataset and returns a mean merror score. We will use a k = 5 for every parameter. cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=50, verbose_eval=30 ) cv_results.tail() [0] train-merror:0.24412+0.00946 test-merror:0.44677+0.01983 [30] train-merror:0.00015+0.00031 test-merror:0.35580+0.04214 [60] train-merror:0.00000+0.00000 test-merror:0.34466+0.03896 [90] train-merror:0.00000+0.00000 test-merror:0.34775+0.04295 train-merror-mean train-merror-std test-merror-mean test-merror-std 55 0.0 0.0 0.347756 0.036916 56 0.0 0.0 0.345899 0.036946 57 0.0 0.0 0.345284 0.039353 58 0.0 0.0 0.343426 0.038823 59 0.0 0.0 0.342811 0.037624 cv_results[&#39;test-merror-mean&#39;].min() 0.34281059999999997 Now we are ready to start tuning. We will first tune our parameters to minimize the merror on cross-validation, and then check the performance of our model on the test dataset. Parameters max_depth and min_child_weight. gridsearch_params = [ (max_depth, min_child_weight) for max_depth in range(5,12) for min_child_weight in range(5,8) ] # Define initial best params and MAE min_merror = float(&quot;Inf&quot;) best_params = None for max_depth, min_child_weight in gridsearch_params: print(&quot;CV with max_depth={}, min_child_weight={}&quot;.format( max_depth, min_child_weight)) # Update our parameters params[&#39;max_depth&#39;] = max_depth params[&#39;min_child_weight&#39;] = min_child_weight # Run CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=50, verbose_eval=False ) # Update best merror mean_merror = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\tMAE {} for {} rounds&quot;.format(mean_merror, boost_rounds)) if mean_merror &lt; min_merror: min_merror = mean_merror best_params = (max_depth,min_child_weight) print(&quot;Best params: {}, {}, merror: {}&quot;.format(best_params[0], best_params[1], min_merror)) CV with max_depth=5, min_child_weight=5 MAE 0.3533254 for 75 rounds CV with max_depth=5, min_child_weight=6 MAE 0.3533292 for 132 rounds CV with max_depth=5, min_child_weight=7 MAE 0.3588922 for 100 rounds CV with max_depth=6, min_child_weight=5 MAE 0.3496082 for 84 rounds CV with max_depth=6, min_child_weight=6 MAE 0.3508504 for 165 rounds CV with max_depth=6, min_child_weight=7 MAE 0.3545598 for 79 rounds CV with max_depth=7, min_child_weight=5 MAE 0.33784559999999997 for 82 rounds CV with max_depth=7, min_child_weight=6 MAE 0.3471276 for 220 rounds CV with max_depth=7, min_child_weight=7 MAE 0.3533136 for 45 rounds CV with max_depth=8, min_child_weight=5 MAE 0.3446568 for 70 rounds CV with max_depth=8, min_child_weight=6 MAE 0.3514716 for 45 rounds CV with max_depth=8, min_child_weight=7 MAE 0.35703860000000004 for 95 rounds CV with max_depth=9, min_child_weight=5 MAE 0.3409416 for 80 rounds CV with max_depth=9, min_child_weight=6 MAE 0.3384664 for 60 rounds CV with max_depth=9, min_child_weight=7 MAE 0.34961180000000003 for 60 rounds CV with max_depth=10, min_child_weight=5 MAE 0.3458856 for 46 rounds CV with max_depth=10, min_child_weight=6 MAE 0.3403222 for 135 rounds CV with max_depth=10, min_child_weight=7 MAE 0.34712400000000004 for 43 rounds CV with max_depth=11, min_child_weight=5 MAE 0.3390972 for 117 rounds CV with max_depth=11, min_child_weight=6 MAE 0.34837559999999995 for 81 rounds CV with max_depth=11, min_child_weight=7 MAE 0.34157399999999993 for 134 rounds Best params: 7, 5, merror: 0.33784559999999997 We get the best score with a max_depth of 9 and min_child_weight of 6, so let’s params[&#39;max_depth&#39;] = 7 params[&#39;min_child_weight&#39;] = 5 Parameters subsample and colsample_bytree gridsearch_params = [ (subsample, colsample) for subsample in [i/10. for i in range(7,11)] for colsample in [i/10. for i in range(7,11)] ] # Define initial best params and MAE min_merror = float(&quot;Inf&quot;) best_params = None for subsample, colsample in reversed(gridsearch_params): print(&quot;CV with subsample={}, colsample={}&quot;.format( subsample, colsample)) # We update our parameters params[&#39;subsample&#39;] = subsample params[&#39;colsample_bytree&#39;] = colsample # Run CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=10, verbose_eval=False ) # Update best MAE mean_merror = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\tMAE {} for {} rounds&quot;.format(mean_merror, boost_rounds)) if mean_merror &lt; min_merror: min_merror = mean_merror best_params = (subsample,colsample) print(&quot;Best params: {}, {}, merror: {}&quot;.format(best_params[0], best_params[1], min_mae)) CV with subsample=1.0, colsample=1.0 MAE 0.34280299999999997 for 57 rounds CV with subsample=1.0, colsample=0.9 MAE 0.35086200000000006 for 47 rounds CV with subsample=1.0, colsample=0.8 MAE 0.335384 for 53 rounds CV with subsample=1.0, colsample=0.7 MAE 0.3477508 for 46 rounds CV with subsample=0.9, colsample=1.0 MAE 0.3489852 for 47 rounds CV with subsample=0.9, colsample=0.9 MAE 0.36075179999999996 for 32 rounds CV with subsample=0.9, colsample=0.8 MAE 0.35519259999999997 for 22 rounds CV with subsample=0.9, colsample=0.7 MAE 0.3316686 for 67 rounds CV with subsample=0.8, colsample=1.0 MAE 0.344668 for 22 rounds CV with subsample=0.8, colsample=0.9 MAE 0.344045 for 31 rounds CV with subsample=0.8, colsample=0.8 MAE 0.3490044 for 49 rounds CV with subsample=0.8, colsample=0.7 MAE 0.356431 for 41 rounds CV with subsample=0.7, colsample=1.0 MAE 0.34713720000000003 for 51 rounds CV with subsample=0.7, colsample=0.9 MAE 0.352079 for 66 rounds CV with subsample=0.7, colsample=0.8 MAE 0.34591779999999994 for 65 rounds CV with subsample=0.7, colsample=0.7 MAE 0.3521078 for 57 rounds Best params: 0.9, 0.7, merror: 0.3316686 params[&#39;subsample&#39;] =0.9 params[&#39;colsample_bytree&#39;] = 0.7 Parameter ETA %time # This can take some time… min_merror = float(&quot;Inf&quot;) best_params = None for eta in [.3, .2, .1, .05, .01, .005]: print(&quot;CV with eta={}&quot;.format(eta)) # We update our parameters params[&#39;eta&#39;] = eta # Run and time CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics=[&#39;merror&#39;], early_stopping_rounds=10 ) # Update best score mean_mae = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\tMAE {} for {} rounds\n&quot;.format(mean_mae, boost_rounds)) if mean_mae &lt; min_mae: min_mae = mean_mae best_params = eta print(&quot;Best params: {}, merror: {}&quot;.format(best_params, min_mae)) Wall time: 0 ns CV with eta=0.3 MAE 0.3316686 for 67 rounds CV with eta=0.2 MAE 0.3316686 for 67 rounds CV with eta=0.1 MAE 0.3316686 for 67 rounds CV with eta=0.05 MAE 0.3316686 for 67 rounds CV with eta=0.01 MAE 0.3316686 for 67 rounds CV with eta=0.005 MAE 0.3316686 for 67 rounds Best params: None, merror: 0.3316686 params[&#39;eta&#39;] = .3 Results This are the final parameters of our tunned model. params {&#39;objective&#39;: &#39;multi:softmax&#39;, &#39;base_score&#39;: 0.5, &#39;booster&#39;: &#39;gbtree&#39;, &#39;colsample_bylevel&#39;: 1, &#39;colsample_bynode&#39;: 1, &#39;colsample_bytree&#39;: 0.7, &#39;gamma&#39;: 0, &#39;gpu_id&#39;: -1, &#39;interaction_constraints&#39;: &#39;&#39;, &#39;learning_rate&#39;: 0.300000012, &#39;max_delta_step&#39;: 0, &#39;max_depth&#39;: 7, &#39;min_child_weight&#39;: 5, &#39;monotone_constraints&#39;: &#39;()&#39;, &#39;n_jobs&#39;: 0, &#39;num_parallel_tree&#39;: 1, &#39;random_state&#39;: 0, &#39;reg_alpha&#39;: 0, &#39;reg_lambda&#39;: 1, &#39;scale_pos_weight&#39;: None, &#39;subsample&#39;: 0.9, &#39;tree_method&#39;: &#39;exact&#39;, &#39;validate_parameters&#39;: 1, &#39;verbosity&#39;: None, &#39;num_class&#39;: 4, &#39;eval_metric&#39;: &#39;merror&#39;, &#39;eta&#39;: 0.3} Let’s train a model with it and see how well it does on our test set! model = xgb.train( params, dtrain, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)], early_stopping_rounds=1000, verbose_eval=100 ) [0] Test-merror:0.45679 Will train until Test-merror hasn&#39;t improved in 1000 rounds. [100] Test-merror:0.34321 [200] Test-merror:0.33827 [300] Test-merror:0.34321 [400] Test-merror:0.34321 [500] Test-merror:0.34815 [600] Test-merror:0.35062 [700] Test-merror:0.34815 [800] Test-merror:0.34815 [900] Test-merror:0.35062 [999] Test-merror:0.35556 num_boost_round = model.best_iteration + 1 best_model = xgb.train( params, dtrain, verbose_eval=100, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)] ) [0] Test-merror:0.45679 [100] Test-merror:0.34321 [200] Test-merror:0.33827 [278] Test-merror:0.32593 metrics.accuracy_score(best_model.predict(dtest), y_test) 0.674074074074074 We did not arrive in an enhanced model with this tunning. Anyone is welcome to continue this tunning and achieve a superior accuracy. Confusion Matrix We will now analyse according to each class the performance of the model. The best way to do it is with a confusion matrix. We can see how many points were missclassified and where were then classified to if not the right rating. cm = confusion_matrix(y_test, y_pred_XGB) fig, ax = plt.subplots(figsize=(8,8)) sns.heatmap(cm, annot = True, ax = ax, vmin=0, vmax=150, fmt=&quot;d&quot;, linewidths=.5, linecolor = &#39;white&#39;, cmap=&quot;Reds&quot;) # annot=True to annotate cells # labels, title and ticks ax.set_xlabel(&#39;Predicted labels&#39;) ax.set_ylabel(&#39;True labels&#39;); ax.set_title(&#39;Confusion Matrix&#39;); ax.xaxis.set_ticklabels([&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;]) ax.yaxis.set_ticklabels([&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;]); # This part is to correct a bug from the heatmap funciton from pyplot b, t = plt.ylim() # discover the values for bottom and top b += 0.5 # Add 0.5 to the bottom t -= 0.5 # Subtract 0.5 from the top plt.ylim(b, t) # update the ylim(bottom, top) values plt.show() Analysis Given the fact that the dataset is very unbalanced, with have achieved a very low accuracy (actually 0) for very risky companies. To deal with it we wiould have to apply upsampling techniques which we may in a future work. Now we analyse other metrics as Precision, recall and F1 from our targets. print(classification_report(y_test, y_pred_XGB, target_names = [&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;])) precision recall f1-score support Medium Risk 0.72 0.83 0.77 148 Highest Risk 0.00 0.00 0.00 8 Low Risk 0.73 0.67 0.70 107 High Risk 0.64 0.60 0.62 142 accuracy 0.69 405 macro avg 0.52 0.53 0.52 405 weighted avg 0.68 0.69 0.68 405 Apparetly the fact that we have more labels in the edium Risk has enhanced its classification. However, overall we have achieved good classification scaores for most, with the exception of Highest Risk. Feature Selection In our tast task we will identify which features were the most valuable for our model. In our first step we will check if by any chance we can increase the accuracy of our model extracting a feature. thresholds = sort(XGB_model.feature_importances_) for thresh in thresholds: # select features using threshold selection = SelectFromModel(XGB_model, threshold=thresh, prefit=True) select_X_train = selection.transform(X_train) # train model selection_model = XGBClassifier() selection_model.fit(select_X_train, y_train) # eval model select_X_test = selection.transform(X_test) y_pred = selection_model.predict(select_X_test) predictions = [round(value) for value in y_pred] accuracy = accuracy_score(y_test, predictions) print(&quot;Thresh=%.3f, n=%d, Accuracy: %.2f%%&quot; % (thresh, select_X_train.shape[1], accuracy*100.0)) Thresh=0.025, n=26, Accuracy: 69.14% Thresh=0.026, n=25, Accuracy: 67.16% Thresh=0.026, n=24, Accuracy: 67.16% Thresh=0.027, n=23, Accuracy: 64.69% Thresh=0.027, n=22, Accuracy: 64.44% Thresh=0.027, n=21, Accuracy: 65.93% Thresh=0.028, n=20, Accuracy: 64.44% ... It is not the case. Now lets visualize which are the most relevant features. from xgboost import plot_importance fig, ax = plt.subplots(figsize=(8, 8)) # xgboost.plot_importance(..., ax=ax) plot_importance(model, ax=ax) plt.show() Visualize Companies Bonus: In this dataset we are working exclusevely with companies that are traded in the stock exchanges from the US. Now, we will visualize which companies are considered secure to lend money according to agencies. We will make 4 different wordclouds, one for each rating of risk. #### Create a function to generate text for the word cloud def WCloud(dataframe, column, rating): words = &#39;&#39; # iterate through the csv file for val in dataframe.loc[dataframe[&#39;Rating&#39;] == rating, column]: # typecaste each val to string val = str(val) val = val.replace(&quot;.&quot;, &quot;&quot;) val = val.replace(&quot;,&quot;, &quot;&quot;) # split the value tokens = val.split() #Converts each token into lowercase for i in range(len(tokens)): tokens[i] = tokens[i].lower() words += &quot; &quot;.join(tokens) + &quot; &quot; return words You may observe that some companies may be in different plots. Thats because they have been rated in different times with different rates." /><meta property="og:description" content="Introduction This notebook contains the results of the data analysis performed on a set of corporate credit ratings given by ratings agencies to a set of companies. The aim of the data analysis is to build a machine learning model from the rating data that can be used to predict the rating a company will receive. The first section section of the notebook shows the exploratory data analysis (EDA) performed to explore and understand the data. It looks at each attribute (variable) in the data to understand the nature and distribution of the attribute values. It also examines the correlation between the variables through visual analysis. A summary at the end highlights the key findings of the EDA. The second section shows the development of a machine learning model. Many diffferent models are tested and the performance of all models are compared. Subsequently, a winner is selected and we do hyperparameter tunning. In the model evaluation step we use different techniques such as a confusion matrix and scores as F1, Precision and Recall to understand different aspects of the performance of the model. We also perform feature selection to know what financial indicators are more relevant for the rating agencies. The Dataset There are 30 features for every company of which 25 are financial indicators. They can be divided in: Liquidity Measurement Ratios: currentRatio, quickRatio, cashRatio, daysOfSalesOutstanding Profitability Indicator Ratios: grossProfitMargin, operatingProfitMargin, pretaxProfitMargin, netProfitMargin, effectiveTaxRate, returnOnAssets, returnOnEquity, returnOnCapitalEmployed Debt Ratios: debtRatio, debtEquityRatio Operating Performance Ratios: assetTurnover Cash Flow Indicator Ratios: operatingCashFlowPerShare, freeCashFlowPerShare, cashPerShare, operatingCashFlowSalesRatio, freeCashFlowOperatingCashFlowRatio Libraries used: pandas numpy matplotlib seaborn random sklearn xgboost wordcloud Load the Libraries used in the notebook import pandas as pdf import numpy as np from numpy import loadtxt from numpy import sort import matplotlib.pyplot as plt %matplotlib inline from matplotlib.ticker import PercentFormatter import matplotlib.ticker as mtick from wordcloud import WordCloud, STOPWORDS from random import sample import seaborn as sns import xgboost as xgb from xgboost import XGBClassifier from sklearn .... Import Dataset df_rating = pd.read_csv(&#39;data/corporate_rating.csv&#39;) Exploratory Data Analysis Our first step is to perform an exploratory data analysis to understand the charateristics of dataset. Here are some quesitons we will try to adress: What are the dimensions of the data? How do predictors relate to each other? What are the classes of the data? How are the predictors distributed? How are the labels distributed? Do we have missing values? Are outliers are relevant? Are there any transformations that must be done with the dataset? # Display the dimensions print(&quot;The credit rating dataset has&quot;, df_rating.shape[0], &quot;records, each with&quot;, df_rating.shape[1], &quot;attributes&quot;) The credit rating dataset has 2029 records, each with 31 attributes We will now use the function .info() to see the classes of columns and search missing values. # Display the structure df_rating.info() RangeIndex: 2029 entries, 0 to 2028 Data columns (total 31 columns): Rating 2029 non-null object Name 2029 non-null object Symbol 2029 non-null object Rating Agency Name 2029 non-null object Date 2029 non-null object Sector 2029 non-null object currentRatio 2029 non-null float64 quickRatio 2029 non-null float64 cashRatio 2029 non-null float64 daysOfSalesOutstanding 2029 non-null float64 netProfitMargin 2029 non-null float64 pretaxProfitMargin 2029 non-null float64 grossProfitMargin 2029 non-null float64 operatingProfitMargin 2029 non-null float64 returnOnAssets 2029 non-null float64 ... dtypes: float64(25), object(6) memory usage: 491.5+ KB We have 26 columns of numerical data and 6 descriptive columns (one of which is the label).There are no missing values. A first look at the data: df_rating.head() Rating Name Symbol Rating Agency Name Date Sector currentRatio ... 0 A Whirlpool Corporation WHR Egan-Jones Ratings Company 11/27/2015 Consumer Durables 0.945894 ... 1 BBB Whirlpool Corporation WHR Egan-Jones Ratings Company 2/13/2014 Consumer Durables 1.033559 ... 2 BBB Whirlpool Corporation WHR Fitch Ratings 3/6/2015 Consumer Durables 0.963703 ... 3 BBB Whirlpool Corporation WHR Fitch Ratings 6/15/2012 Consumer Durables 1.019851 ... 4 BBB Whirlpool Corporation WHR Standard &amp; Poor&#39;s Ratings Services 10/24/2016 Consumer Durables 0.957844 ... 5 rows × 31 columns Analyse Labels As we know we are working with ordinal labels. That means there is a scale from more secure to less secure ratings. For instance, the triple-A (AAA) is the most secure rating a company can receive. On the other hand, the rating D is the less secure. It means the company will likely default on its creditors. Let’s have a first look at the how many reatings we have of each in the dataset. df_rating.Rating.value_counts() BBB 671 BB 490 A 398 B 302 AA 89 CCC 64 AAA 7 CC 5 C 2 D 1 Name: Rating, dtype: int64 We observe that the dataset is very unbalanced. We have 671 triple-Bs (BBB) but only 1 D. However, we are working with Ratings from different companies such as Moody&#39;s, Standard &amp; Poor&#39;s and more. Therefore it is preferred to simplify the labels according to this table from the website investopedia. We will classify our labels according to the grading risk and not the rate. Bond Rating         Moody’s Standard &amp; Poor’s Fitch Grade Risk Aaa AAA AAA Investment Lowest Risk Aa AA AA Investment Low Risk A A A Investment Low Risk Baa BBB BBB Investment Medium Risk Ba, B BB, B BB, B Junk High Risk Caa/Ca CCC/CC/C CCC/CC/C Junk Highest Risk C D D Junk In Default To do it we will replace with a dictonary each of this ratings. rating_dict = {&#39;AAA&#39;:&#39;Lowest Risk&#39;, &#39;AA&#39;:&#39;Low Risk&#39;, &#39;A&#39;:&#39;Low Risk&#39;, &#39;BBB&#39;:&#39;Medium Risk&#39;, &#39;BB&#39;:&#39;High Risk&#39;, &#39;B&#39;:&#39;High Risk&#39;, &#39;CCC&#39;:&#39;Highest Risk&#39;, &#39;CC&#39;:&#39;Highest Risk&#39;, &#39;C&#39;:&#39;Highest Risk&#39;, &#39;D&#39;:&#39;In Default&#39;} df_rating.Rating = df_rating.Rating.map(rating_dict) ax = df_rating[&#39;Rating&#39;].value_counts().plot(kind=&#39;bar&#39;, figsize=(8,4), title=&quot;Count of Rating by Type&quot;, grid=True) Unfortunately, given the lack of Credit Ratings classified as Lowest Risk and In Default we will have to eliminate then from the table. However, the dataset will keep unbalanced and if needed we will have to adress this issue in further steps. df_rating = df_rating[df_rating[&#39;Rating&#39;]!=&#39;Lowest Risk&#39;] # filter Lowest Risk df_rating = df_rating[df_rating[&#39;Rating&#39;]!=&#39;In Default&#39;] # filter In Default df_rating.reset_index(inplace = True, drop=True) # reset index Descriptive Statistics Now we will use statistical tools, especially from pandas to improve the understanding from the dataset, especially the numerical features. We have seen there are 25 numerical columns in the dataset, all of each are financial indicators from the companies. The function describe() returns information about the distribution of the data such as quantiles, min and max. # Statistical summary df_rating.describe() currentRatio quickRatio cashRatio daysOfSalesOutstanding netProfitMargin ... count 2021.000000 2021.000000 2021.000000 2021.000000 2021.000000 ... 2021.000000 mean 3.535411 2.657150 0.669048 334.855415 0.278725 ... std 44.139386 33.009920 3.590902 4456.606352 6.076128 ... min -0.932005 -1.893266 -0.192736 -811.845623 -101.845815 ... 25% 1.071930 0.602298 0.131433 22.806507 0.020894 ... 50% 1.492804 0.979094 0.297859 42.281804 0.064323 ... 75% 2.160710 1.450457 0.625355 59.165369 0.113871 ... max 1725.505005 1139.541703 125.917417 115961.637400 198.517873 ... 8 rows × 25 columns Skewness and Outliers We observe a lot of skewness in the data with this first exploration. In this case, it means that most variables in the dataset may strong presence of outliers. Taking as observation the table above the first column: currentRatio: This 50% of its variables between 1.071 and 2.166891. The minimum value is -0.932005 however the maximum value is 1725.505005. It means, in other words, there is a giant outlier that is extremely distant from most points from the data (currentRatio). The same pattern can be observed in the following columns such as quickRatio, cashRatio, daysOfSalesOutstanding, netProfitMargin and so on. To observe how this reflect on the distribution of the data lets make some plots of variables chose randomly. column_list = list(df_rating.columns[6:31]) column_list = sample(column_list,4) print(column_list) [&#39;operatingCashFlowSalesRatio&#39;, &#39;grossProfitMargin&#39;, &#39;returnOnEquity&#39;, &#39;companyEquityMultiplier&#39;] &lt;/samp&gt; figure, axes = plt.subplots(nrows=2, ncols=4, figsize=(9,5)) axes[0, 0].hist(df_rating[column_list[0]]) axes[0, 1].hist(df_rating[column_list[1]]) axes[1, 0].hist(df_rating[column_list[2]]) axes[1, 1].hist(df_rating[column_list[3]]) axes[0, 2].boxplot(df_rating[column_list[0]]) axes[1, 2].boxplot(df_rating[column_list[1]]) axes[0, 3].boxplot(df_rating[column_list[2]]) axes[1, 3].boxplot(df_rating[column_list[3]]) figure.tight_layout() As predicted, the data is comtaminated by outliers. We canot observe real behaviour of the distribution because some points differ too much from the others. We will use the function .skew from pandas in all columns. It should return between 0 and 1 if a column is normally distributed. df_rating.skew(axis=0) currentRatio 34.271115 quickRatio 30.864610 cashRatio 27.046952 daysOfSalesOutstanding 20.359098 netProfitMargin 17.585073 pretaxProfitMargin 22.052558 grossProfitMargin -14.198688 operatingProfitMargin 26.441502 returnOnAssets -32.049111 returnOnCapitalEmployed -33.252701 returnOnEquity 31.639845 assetTurnover 25.968848 fixedAssetTurnover 26.068762 debtEquityRatio 0.268074 debtRatio 1.284256 effectiveTaxRate 32.265705 freeCashFlowOperatingCashFlowRatio -22.868222 freeCashFlowPerShare 33.610677 cashPerShare 33.958646 companyEquityMultiplier 0.268175 ebitPerRevenue 22.055668 enterpriseValueMultiple 13.920117 operatingCashFlowPerShare 30.292914 operatingCashFlowSalesRatio 25.400129 payablesTurnover 25.868293 dtype: float64 We observe this is a generalized problem. As we can see almost all columns are extremely skewed. We will now go deeper in the investigation of outliers. The following code will return the proportion of outliers in each column . The definition of outlier will be the one from the boxplot - above or bellow 1.5 x IQR. for c in df_rating.columns[6:31]: q1 = df_rating[c].quantile(0.25) q3 = df_rating[c].quantile(0.75) iqr = q3 - q1 #Interquartile range fence_low = q3-1.5*iqr fence_high = q1+1.5*iqr lower_out = len(df_rating.loc[(df_rating[c] &lt; fence_low) ,c]) upper_out = len(df_rating.loc[(df_rating[c] &gt; fence_high) ,c]) outlier_count = upper_out+lower_out prop_out = outlier_count/len(df_rating) print(c, &quot;: &quot;+&quot;{:.2%}&quot;.format(prop_out)) currentRatio : 18.01% quickRatio : 19.05% cashRatio : 14.84% daysOfSalesOutstanding : 23.55% netProfitMargin : 25.09% pretaxProfitMargin : 24.49% grossProfitMargin : 0.99% operatingProfitMargin : 22.12% returnOnAssets : 24.25% returnOnCapitalEmployed : 22.07% returnOnEquity : 28.70% assetTurnover : 15.83% fixedAssetTurnover : 13.46% debtEquityRatio : 22.07% debtRatio : 21.33% effectiveTaxRate : 28.06% freeCashFlowOperatingCashFlowRatio : 16.92% freeCashFlowPerShare : 23.55% cashPerShare : 17.12% companyEquityMultiplier : 22.02% ebitPerRevenue : 24.34% enterpriseValueMultiple : 23.70% operatingCashFlowPerShare : 17.66% operatingCashFlowSalesRatio : 16.87% payablesTurnover : 14.45% Most columns have a significant number of outliers. However it is not clear for us if there are a few rows that all outliers or each of the rows may be contributing individually with some outliers. We will now check by row the distribution of outliers. We will create a new dataframe that df_rating_outlier that will be used with this purpose. In this dataframe every cell will 1 one if the corresponding cell is an outlier in df_raint and 0 if it is not. df_rating_outlier = df_rating.copy() for c in df_rating_outlier.columns[6:31]: q1 = df_rating_outlier[c].quantile(0.25) q3 = df_rating_outlier[c].quantile(0.75) iqr = q3 - q1 #Interquartile range fence_low = q3-1.5*iqr fence_high = q1+1.5*iqr for i in range(len(df_rating_outlier)): if df_rating.loc[i,c] &lt; fence_low or df_rating.loc[i,c] &gt; fence_high: # if Outlier df_rating_outlier.loc[i,c] = 1 else: # Not Outlier df_rating_outlier.loc[i,c] = 0 Now we will be able to count how many outliers each row has and plot it. df_rating_outlier[&quot;total&quot;] = df_rating_outlier.sum(axis=1) df_rating_outlier.total.hist(bins = 20) This is a very interesting plot. We can see that only up to 400 rows don’t have any outliers. Most rows have outliers and maybe they will be useful in the further classification tasks. Therefore we see no value in excluding the outliers from the dataset. However we will perform a transformation on the data so we can reduce its negative impact. Data reshaping We will now perform the following steps in each of the numerical data. Normalize the data between 0 and 1 (and multiply by 1.000). Apply log on base 10 on each of the variables. from sklearn import preprocessing min_max_scaler = preprocessing.MinMaxScaler() for c in df_rating.columns[6:31]: df_rating[[c]] = min_max_scaler.fit_transform(df_rating[[c]].to_numpy())*1000 df_rating[[c]] = df_rating[c].apply(lambda x: np.log10(x+0.01)) Again the plots figure, axes = plt.subplots(nrows=2, ncols=4, figsize=(9,5)) axes[0, 0].hist(df_rating[column_list[0]]) axes[0, 1].hist(df_rating[column_list[1]]) axes[1, 0].hist(df_rating[column_list[2]]) axes[1, 1].hist(df_rating[column_list[3]]) axes[0, 2].boxplot(df_rating[column_list[0]]) axes[1, 2].boxplot(df_rating[column_list[1]]) axes[0, 3].boxplot(df_rating[column_list[2]]) axes[1, 3].boxplot(df_rating[column_list[3]]) figure.tight_layout() We have a problem with respect to vizualisation of the data. The impact of the outliers is so big that we cannot observe the patterns in the data. To enhance our visualization we will from now ignore outliers. We will replace then by values with lower impact such as the lower hinge. In this way we will be able to continue with our EDA. To preserve our dataset we will use a new table called df_rating_no_out. df_rating_no_out = df_rating.copy() for c in df_rating_no_out.columns[6:31]: q05 = df_rating_no_out[c].quantile(0.10) q95 = df_rating_no_out[c].quantile(0.90) iqr = q95 - q05 #Interquartile range fence_low = q05-1.5*iqr fence_high = q95+1.5*iqr df_rating_no_out.loc[df_rating_no_out[c] &gt; fence_high,c] = df_rating_no_out[c].quantile(0.25) df_rating_no_out.loc[df_rating_no_out[c] &lt; fence_low,c] = df_rating_no_out[c].quantile(0.75) Now that we have this dataframe we can use it use it to observe the data from a different angle. We will be able to observe the distribution that was hidden by the outliers. The first step: Plot all columns (boxplot) by each label:High Risk, Low Risk, Medium Risk, Highest Risk. figure, axes = plt.subplots(nrows=8, ncols=3, figsize=(20,44)) i = 0 j = 0 for c in df_rating_no_out.columns[6:30]: sns.boxplot(x=df_rating_no_out.Rating, y=df_rating_no_out[c], palette=&quot;Set3&quot;, ax=axes[i, j]) if j == 2: j=0 i+=1 else: j+=1 The most interesting point about the previous plots is the fact that they clearly show a difference in the medians and distribution according to the rating (Risk). It points to a scenario where the variables will have good predictive power for classification. Following with our analysis we will create scatter plots to see if we can observe who the variables relate to each other and how labels can be observer in respect to it. df_rating.colors = &#39;a&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Lowest Risk&#39;, &#39;color&#39;] = &#39;r&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Low Risk&#39;, &#39;color&#39;] = &#39;g&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Medium Risk&#39;, &#39;color&#39;] = &#39;b&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;High Risk&#39;,&#39;color&#39;] = &#39;y&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Highest Risk&#39;, &#39;color&#39;] = &#39;m&#39; column_list = list(df_rating.columns[6:31]) column_list = sample(column_list,12) figure, axes = plt.subplots(nrows=3, ncols=2, figsize=(14,14)) i = 0 j = 0 for c in range(0,12, 2): sns.scatterplot(x = column_list[c], y=column_list[c+1], hue=&quot;color&quot;, data=df_rating_no_out, ax=axes[j,i]) if i == 1: i = 0 j +=1 else: i+=1 In fact, we are working with a dataset that has a big numer of dimensions. With two variables it would not be possible to make any predictions. However this is not the case. Unfortunately we are not able to vizualise the data in all its dimensions, but luckely we will be able to perform accurate classificaitons. Machine Learning Is it possible to predict what creidt profile a company will receive from a rating agency based on its financial indicators? If so, what are the most important predictors? Apparently not much work has been done with regards to this question. This academic paper was the only work found about it. It is worth checking it out. As we will do it, it tests most ML algorithms and identifies the most important features. In the following steps we will perform the following: Prepare the dataset Split in train and test Transform/Encode the features kand labels Test a wide range of ML models (Tree-based, Probabilistic and so on). Compare the accuracry of all models. Choose our winning model and tune hyperparameters to target a higher accuracy. Make a more profound evaluation of the result with a confusion matrix and different measures. identify the most important features to predict the rating. Prepare the Dataset le = preprocessing.LabelEncoder() le.fit(df_rating.Sector) df_rating.Sector = le.transform(df_rating.Sector) # encode sector le.fit(df_rating.Rating) df_rating.Rating = le.transform(df_rating.Rating) # encode rating df_train, df_test = train_test_split(df_rating, test_size=0.2, random_state = 1234) X_train, y_train = df_train.iloc[:,5:31], df_train.iloc[:,0] X_test, y_test = df_test.iloc[:,5:31], df_test.iloc[:,0] Fit Models Now we will test a range of models. In each we will fit the model in the train data, make predictons for the test data and obtain the accuracy. In later steps we will compare the accuracy of all the models. We will use primarily the library sklearn but also XGBoost. XGBoost XGB_model = xgb.XGBRegressor(objective =&#39;multi:softmax&#39;, num_class =4) XGB_model.fit(X_train, y_train) y_pred_XGB = XGB_model.predict(X_test) Accuracy_XGB = metrics.accuracy_score(y_test, y_pred_XGB) print(&quot;XGB Accuracy:&quot;,Accuracy_XGB) XGB Accuracy: 0.691358024691358 Gradient Boosting Classifier GBT_model = GradientBoostingClassifier(random_state=123) GBT_model.fit(X_train, y_train) y_pred_GBT = GBT_model.predict(X_test) Accuracy_GBT = metrics.accuracy_score(y_test, y_pred_GBT) print(&quot;GBT Accuracy:&quot;,Accuracy_GBT) GBT Accuracy: 0.6320987654320988 Random Forest RF_model = RandomForestClassifier(random_state=1234) RF_model.fit(X_train,y_train) y_pred_RF = RF_model.predict(X_test) Accuracy_RF = metrics.accuracy_score(y_test, y_pred_RF) print(&quot;RF Accuracy:&quot;,Accuracy_RF) RF Accuracy: 0.6246913580246913 Support Vector Machine SVC_model = svm.SVC(kernel=&#39;rbf&#39;, gamma= 2, C = 5, random_state=1234) SVC_model.fit(X_train, y_train) y_pred_SVM = SVC_model.predict(X_test) Accuracy_SVM = metrics.accuracy_score(y_test, y_pred_SVM) print(&quot;SVM Accuracy:&quot;,Accuracy_SVM) SVM Accuracy: 0.5333333333333333 Neural Network MLP_model = MLPClassifier(hidden_layer_sizes=(5,5,5), activation=&#39;logistic&#39;, solver=&#39;adam&#39;, max_iter=1500) MLP_model.fit(X_train, y_train) y_pred_MLP = MLP_model.predict(X_test) Accuracy_MLP = metrics.accuracy_score(y_test, y_pred_MLP) print(&quot;MLP Accuracy:&quot;,Accuracy_MLP) MLP Accuracy: 0.3654320987654321 Naive Bayes GNB_model = GaussianNB() GNB_model.fit(X_train, y_train) y_pred_GNB = GNB_model.predict(X_test) Accuracy_GNB = metrics.accuracy_score(y_test, y_pred_GNB) print(&quot;GNB Accuracy:&quot;,Accuracy_GNB) GNB Accuracy: 0.30864197530864196 Linear Discriminant Analysis LDA_model = LinearDiscriminantAnalysis() LDA_model.fit(X_train,y_train) y_pred_LDA = LDA_model.predict(X_test) Accuracy_LDA = metrics.accuracy_score(y_test, y_pred_LDA) print(&quot;LDA Accuracy:&quot;,Accuracy_LDA) LDA Accuracy: 0.38765432098765434 Quadratic Discriminant Analysis QDA_model = QuadraticDiscriminantAnalysis() QDA_model.fit(X_train,y_train) y_pred_QDA = QDA_model.predict(X_test) Accuracy_QDA = metrics.accuracy_score(y_test, y_pred_QDA) print(&quot;QDA Accuracy:&quot;,Accuracy_QDA) QDA Accuracy: 0.35555555555555557 K Nearest Neighbours KNN_model = KNeighborsClassifier(n_neighbors = 3) KNN_model.fit(X_train,y_train) y_pred_KNN = KNN_model.predict(X_test) Accuracy_KNN = metrics.accuracy_score(y_test, y_pred_KNN) print(&quot;KNN Accuracy:&quot;,Accuracy_KNN) KNN Accuracy: 0.5802469135802469 Logistic Regression LR_model = LogisticRegression(random_state=1234 , multi_class=&#39;multinomial&#39;, solver=&#39;newton-cg&#39;) LR_model = LR_model.fit(X_train, y_train) y_pred_LR = LR_model.predict(X_test) Accuracy_LR = metrics.accuracy_score(y_test, y_pred_LR) print(&quot;LR Accuracy:&quot;,Accuracy_LR) LR Accuracy: 0.3925925925925926 Compare Results accuracy_list = [Accuracy_XGB, Accuracy_GBT, Accuracy_RF, Accuracy_SVM, Accuracy_MLP, Accuracy_GNB, Accuracy_LDA, Accuracy_QDA, Accuracy_KNN, Accuracy_LR] model_list = [&#39;XGBboost&#39;, &#39;Gradient Boosting&#39;, &#39;Random Forest&#39;, &#39;Support Vector Machine&#39;, &quot;Neural Network&quot;, &#39;Naive Bayes&#39;, &#39;Linear Discriminat&#39;, &#39;Quadratic Discriminat&#39;, &#39;KNN&#39;, &#39;Logistic Regression&#39;] df_accuracy = pd.DataFrame({&#39;Model&#39;: model_list, &#39;Accuracy&#39;: accuracy_list}) order = list(df_accuracy.sort_values(&#39;Accuracy&#39;, ascending=False).Model) df_accuracy = df_accuracy.sort_values(&#39;Accuracy&#39;, ascending=False).reset_index().drop([&#39;index&#39;], axis=1) plt.figure(figsize=(12,8)) # make barplot and sort bars x = sns.barplot(x=&#39;Model&#39;, y=&quot;Accuracy&quot;, data=df_accuracy, order = order, palette=&quot;rocket&quot;) plt.xlabel(&quot;Model&quot;, fontsize=20) plt.ylabel(&quot;Accuracy&quot;, fontsize=20) plt.title(&quot;Accuracy by Model&quot;, fontsize=20) plt.grid(linestyle=&#39;-&#39;, linewidth=&#39;0.5&#39;, color=&#39;grey&#39;) plt.xticks(rotation=70, fontsize=12) plt.ylim(0,1) plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1)) for i in range(len(model_list)): plt.text(x = i, y = df_accuracy.loc[i, &#39;Accuracy&#39;] + 0.05, s = str(round((df_accuracy.loc[i, &#39;Accuracy&#39;])*100, 2))+&#39;%&#39;, fontsize = 14, color=&#39;black&#39;,horizontalalignment=&#39;center&#39;) y_value=[&#39;{:,.2f}&#39;.format(x) + &#39;%&#39; for x in ax.get_yticks()] ax.set_yticklabels(y_value) plt.tight_layout() We have our winner. XGboost is the best performing model. XGBoost Hyperparameter Tunning The XGboost model has achieved a very high accuracy given that we have 4 different classes. Now we will try to increase the performance even more. We will use a cross-validation approach and we will follow similar steps to this tutorial. First we load the train and test data into DMatrices. DMatrix is a data structure used by XGBoost to optimize both memory efficiency and training speed. dtrain = xgb.DMatrix(X_train, label=y_train) dtest = xgb.DMatrix(X_test, label=y_test) The params dictionary We create a dictonary with the parameters from our previous XGboost model. params = XGB_model.get_xgb_params() {&#39;objective&#39;: &#39;multi:softmax&#39;, &#39;base_score&#39;: 0.5, &#39;booster&#39;: &#39;gbtree&#39;, &#39;colsample_bylevel&#39;: 1, &#39;colsample_bynode&#39;: 1, &#39;colsample_bytree&#39;: 1, &#39;gamma&#39;: 0, &#39;gpu_id&#39;: -1, &#39;interaction_constraints&#39;: &#39;&#39;, &#39;learning_rate&#39;: 0.300000012, &#39;max_delta_step&#39;: 0, &#39;max_depth&#39;: 6, &#39;min_child_weight&#39;: 1, &#39;monotone_constraints&#39;: &#39;()&#39;, &#39;n_jobs&#39;: 0, &#39;num_parallel_tree&#39;: 1, &#39;random_state&#39;: 0, &#39;reg_alpha&#39;: 0, &#39;reg_lambda&#39;: 1, &#39;scale_pos_weight&#39;: None, &#39;subsample&#39;: 1, &#39;tree_method&#39;: &#39;exact&#39;, &#39;validate_parameters&#39;: 1, &#39;verbosity&#39;: None, &#39;num_class&#39;: 4} We will use the merror error parameter from classification. It is basic an accuracy. params[&#39;eval_metric&#39;] = &quot;merror&quot; The num_boost_round which corresponds to the maximum number of boosting rounds that we allow. num_boost_round = 1000 model = xgb.train( params, dtrain, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)], early_stopping_rounds=50, verbose_eval=30) print(&quot;Best merror: {:.2f} with {} rounds&quot;.format( model.best_score, model.best_iteration+1)) [0] Test-merror:0.44691&lt;br&gt; Will train until Test-merror hasn&#39;t improved in 50 rounds.&lt;br&gt; [30] Test-merror:0.34568&lt;br&gt; [60] Test-merror:0.32839&lt;br&gt; [90] Test-merror:0.30617&lt;br&gt; [120] Test-merror:0.30864&lt;br&gt; [150] Test-merror:0.30864&lt;br&gt; Stopping. Best iteration:&lt;br&gt; [104] Test-merror:0.29877&lt;br&gt; Best merror: 0.30 with 105 rounds Using XGBoost’s CV In order to tune the other hyperparameters, we will use the cv function from XGBoost. It allows us to run cross-validation on our training dataset and returns a mean merror score. We will use a k = 5 for every parameter. cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=50, verbose_eval=30 ) cv_results.tail() [0] train-merror:0.24412+0.00946 test-merror:0.44677+0.01983 [30] train-merror:0.00015+0.00031 test-merror:0.35580+0.04214 [60] train-merror:0.00000+0.00000 test-merror:0.34466+0.03896 [90] train-merror:0.00000+0.00000 test-merror:0.34775+0.04295 train-merror-mean train-merror-std test-merror-mean test-merror-std 55 0.0 0.0 0.347756 0.036916 56 0.0 0.0 0.345899 0.036946 57 0.0 0.0 0.345284 0.039353 58 0.0 0.0 0.343426 0.038823 59 0.0 0.0 0.342811 0.037624 cv_results[&#39;test-merror-mean&#39;].min() 0.34281059999999997 Now we are ready to start tuning. We will first tune our parameters to minimize the merror on cross-validation, and then check the performance of our model on the test dataset. Parameters max_depth and min_child_weight. gridsearch_params = [ (max_depth, min_child_weight) for max_depth in range(5,12) for min_child_weight in range(5,8) ] # Define initial best params and MAE min_merror = float(&quot;Inf&quot;) best_params = None for max_depth, min_child_weight in gridsearch_params: print(&quot;CV with max_depth={}, min_child_weight={}&quot;.format( max_depth, min_child_weight)) # Update our parameters params[&#39;max_depth&#39;] = max_depth params[&#39;min_child_weight&#39;] = min_child_weight # Run CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=50, verbose_eval=False ) # Update best merror mean_merror = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\tMAE {} for {} rounds&quot;.format(mean_merror, boost_rounds)) if mean_merror &lt; min_merror: min_merror = mean_merror best_params = (max_depth,min_child_weight) print(&quot;Best params: {}, {}, merror: {}&quot;.format(best_params[0], best_params[1], min_merror)) CV with max_depth=5, min_child_weight=5 MAE 0.3533254 for 75 rounds CV with max_depth=5, min_child_weight=6 MAE 0.3533292 for 132 rounds CV with max_depth=5, min_child_weight=7 MAE 0.3588922 for 100 rounds CV with max_depth=6, min_child_weight=5 MAE 0.3496082 for 84 rounds CV with max_depth=6, min_child_weight=6 MAE 0.3508504 for 165 rounds CV with max_depth=6, min_child_weight=7 MAE 0.3545598 for 79 rounds CV with max_depth=7, min_child_weight=5 MAE 0.33784559999999997 for 82 rounds CV with max_depth=7, min_child_weight=6 MAE 0.3471276 for 220 rounds CV with max_depth=7, min_child_weight=7 MAE 0.3533136 for 45 rounds CV with max_depth=8, min_child_weight=5 MAE 0.3446568 for 70 rounds CV with max_depth=8, min_child_weight=6 MAE 0.3514716 for 45 rounds CV with max_depth=8, min_child_weight=7 MAE 0.35703860000000004 for 95 rounds CV with max_depth=9, min_child_weight=5 MAE 0.3409416 for 80 rounds CV with max_depth=9, min_child_weight=6 MAE 0.3384664 for 60 rounds CV with max_depth=9, min_child_weight=7 MAE 0.34961180000000003 for 60 rounds CV with max_depth=10, min_child_weight=5 MAE 0.3458856 for 46 rounds CV with max_depth=10, min_child_weight=6 MAE 0.3403222 for 135 rounds CV with max_depth=10, min_child_weight=7 MAE 0.34712400000000004 for 43 rounds CV with max_depth=11, min_child_weight=5 MAE 0.3390972 for 117 rounds CV with max_depth=11, min_child_weight=6 MAE 0.34837559999999995 for 81 rounds CV with max_depth=11, min_child_weight=7 MAE 0.34157399999999993 for 134 rounds Best params: 7, 5, merror: 0.33784559999999997 We get the best score with a max_depth of 9 and min_child_weight of 6, so let’s params[&#39;max_depth&#39;] = 7 params[&#39;min_child_weight&#39;] = 5 Parameters subsample and colsample_bytree gridsearch_params = [ (subsample, colsample) for subsample in [i/10. for i in range(7,11)] for colsample in [i/10. for i in range(7,11)] ] # Define initial best params and MAE min_merror = float(&quot;Inf&quot;) best_params = None for subsample, colsample in reversed(gridsearch_params): print(&quot;CV with subsample={}, colsample={}&quot;.format( subsample, colsample)) # We update our parameters params[&#39;subsample&#39;] = subsample params[&#39;colsample_bytree&#39;] = colsample # Run CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=10, verbose_eval=False ) # Update best MAE mean_merror = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\tMAE {} for {} rounds&quot;.format(mean_merror, boost_rounds)) if mean_merror &lt; min_merror: min_merror = mean_merror best_params = (subsample,colsample) print(&quot;Best params: {}, {}, merror: {}&quot;.format(best_params[0], best_params[1], min_mae)) CV with subsample=1.0, colsample=1.0 MAE 0.34280299999999997 for 57 rounds CV with subsample=1.0, colsample=0.9 MAE 0.35086200000000006 for 47 rounds CV with subsample=1.0, colsample=0.8 MAE 0.335384 for 53 rounds CV with subsample=1.0, colsample=0.7 MAE 0.3477508 for 46 rounds CV with subsample=0.9, colsample=1.0 MAE 0.3489852 for 47 rounds CV with subsample=0.9, colsample=0.9 MAE 0.36075179999999996 for 32 rounds CV with subsample=0.9, colsample=0.8 MAE 0.35519259999999997 for 22 rounds CV with subsample=0.9, colsample=0.7 MAE 0.3316686 for 67 rounds CV with subsample=0.8, colsample=1.0 MAE 0.344668 for 22 rounds CV with subsample=0.8, colsample=0.9 MAE 0.344045 for 31 rounds CV with subsample=0.8, colsample=0.8 MAE 0.3490044 for 49 rounds CV with subsample=0.8, colsample=0.7 MAE 0.356431 for 41 rounds CV with subsample=0.7, colsample=1.0 MAE 0.34713720000000003 for 51 rounds CV with subsample=0.7, colsample=0.9 MAE 0.352079 for 66 rounds CV with subsample=0.7, colsample=0.8 MAE 0.34591779999999994 for 65 rounds CV with subsample=0.7, colsample=0.7 MAE 0.3521078 for 57 rounds Best params: 0.9, 0.7, merror: 0.3316686 params[&#39;subsample&#39;] =0.9 params[&#39;colsample_bytree&#39;] = 0.7 Parameter ETA %time # This can take some time… min_merror = float(&quot;Inf&quot;) best_params = None for eta in [.3, .2, .1, .05, .01, .005]: print(&quot;CV with eta={}&quot;.format(eta)) # We update our parameters params[&#39;eta&#39;] = eta # Run and time CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics=[&#39;merror&#39;], early_stopping_rounds=10 ) # Update best score mean_mae = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\tMAE {} for {} rounds\n&quot;.format(mean_mae, boost_rounds)) if mean_mae &lt; min_mae: min_mae = mean_mae best_params = eta print(&quot;Best params: {}, merror: {}&quot;.format(best_params, min_mae)) Wall time: 0 ns CV with eta=0.3 MAE 0.3316686 for 67 rounds CV with eta=0.2 MAE 0.3316686 for 67 rounds CV with eta=0.1 MAE 0.3316686 for 67 rounds CV with eta=0.05 MAE 0.3316686 for 67 rounds CV with eta=0.01 MAE 0.3316686 for 67 rounds CV with eta=0.005 MAE 0.3316686 for 67 rounds Best params: None, merror: 0.3316686 params[&#39;eta&#39;] = .3 Results This are the final parameters of our tunned model. params {&#39;objective&#39;: &#39;multi:softmax&#39;, &#39;base_score&#39;: 0.5, &#39;booster&#39;: &#39;gbtree&#39;, &#39;colsample_bylevel&#39;: 1, &#39;colsample_bynode&#39;: 1, &#39;colsample_bytree&#39;: 0.7, &#39;gamma&#39;: 0, &#39;gpu_id&#39;: -1, &#39;interaction_constraints&#39;: &#39;&#39;, &#39;learning_rate&#39;: 0.300000012, &#39;max_delta_step&#39;: 0, &#39;max_depth&#39;: 7, &#39;min_child_weight&#39;: 5, &#39;monotone_constraints&#39;: &#39;()&#39;, &#39;n_jobs&#39;: 0, &#39;num_parallel_tree&#39;: 1, &#39;random_state&#39;: 0, &#39;reg_alpha&#39;: 0, &#39;reg_lambda&#39;: 1, &#39;scale_pos_weight&#39;: None, &#39;subsample&#39;: 0.9, &#39;tree_method&#39;: &#39;exact&#39;, &#39;validate_parameters&#39;: 1, &#39;verbosity&#39;: None, &#39;num_class&#39;: 4, &#39;eval_metric&#39;: &#39;merror&#39;, &#39;eta&#39;: 0.3} Let’s train a model with it and see how well it does on our test set! model = xgb.train( params, dtrain, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)], early_stopping_rounds=1000, verbose_eval=100 ) [0] Test-merror:0.45679 Will train until Test-merror hasn&#39;t improved in 1000 rounds. [100] Test-merror:0.34321 [200] Test-merror:0.33827 [300] Test-merror:0.34321 [400] Test-merror:0.34321 [500] Test-merror:0.34815 [600] Test-merror:0.35062 [700] Test-merror:0.34815 [800] Test-merror:0.34815 [900] Test-merror:0.35062 [999] Test-merror:0.35556 num_boost_round = model.best_iteration + 1 best_model = xgb.train( params, dtrain, verbose_eval=100, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)] ) [0] Test-merror:0.45679 [100] Test-merror:0.34321 [200] Test-merror:0.33827 [278] Test-merror:0.32593 metrics.accuracy_score(best_model.predict(dtest), y_test) 0.674074074074074 We did not arrive in an enhanced model with this tunning. Anyone is welcome to continue this tunning and achieve a superior accuracy. Confusion Matrix We will now analyse according to each class the performance of the model. The best way to do it is with a confusion matrix. We can see how many points were missclassified and where were then classified to if not the right rating. cm = confusion_matrix(y_test, y_pred_XGB) fig, ax = plt.subplots(figsize=(8,8)) sns.heatmap(cm, annot = True, ax = ax, vmin=0, vmax=150, fmt=&quot;d&quot;, linewidths=.5, linecolor = &#39;white&#39;, cmap=&quot;Reds&quot;) # annot=True to annotate cells # labels, title and ticks ax.set_xlabel(&#39;Predicted labels&#39;) ax.set_ylabel(&#39;True labels&#39;); ax.set_title(&#39;Confusion Matrix&#39;); ax.xaxis.set_ticklabels([&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;]) ax.yaxis.set_ticklabels([&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;]); # This part is to correct a bug from the heatmap funciton from pyplot b, t = plt.ylim() # discover the values for bottom and top b += 0.5 # Add 0.5 to the bottom t -= 0.5 # Subtract 0.5 from the top plt.ylim(b, t) # update the ylim(bottom, top) values plt.show() Analysis Given the fact that the dataset is very unbalanced, with have achieved a very low accuracy (actually 0) for very risky companies. To deal with it we wiould have to apply upsampling techniques which we may in a future work. Now we analyse other metrics as Precision, recall and F1 from our targets. print(classification_report(y_test, y_pred_XGB, target_names = [&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;])) precision recall f1-score support Medium Risk 0.72 0.83 0.77 148 Highest Risk 0.00 0.00 0.00 8 Low Risk 0.73 0.67 0.70 107 High Risk 0.64 0.60 0.62 142 accuracy 0.69 405 macro avg 0.52 0.53 0.52 405 weighted avg 0.68 0.69 0.68 405 Apparetly the fact that we have more labels in the edium Risk has enhanced its classification. However, overall we have achieved good classification scaores for most, with the exception of Highest Risk. Feature Selection In our tast task we will identify which features were the most valuable for our model. In our first step we will check if by any chance we can increase the accuracy of our model extracting a feature. thresholds = sort(XGB_model.feature_importances_) for thresh in thresholds: # select features using threshold selection = SelectFromModel(XGB_model, threshold=thresh, prefit=True) select_X_train = selection.transform(X_train) # train model selection_model = XGBClassifier() selection_model.fit(select_X_train, y_train) # eval model select_X_test = selection.transform(X_test) y_pred = selection_model.predict(select_X_test) predictions = [round(value) for value in y_pred] accuracy = accuracy_score(y_test, predictions) print(&quot;Thresh=%.3f, n=%d, Accuracy: %.2f%%&quot; % (thresh, select_X_train.shape[1], accuracy*100.0)) Thresh=0.025, n=26, Accuracy: 69.14% Thresh=0.026, n=25, Accuracy: 67.16% Thresh=0.026, n=24, Accuracy: 67.16% Thresh=0.027, n=23, Accuracy: 64.69% Thresh=0.027, n=22, Accuracy: 64.44% Thresh=0.027, n=21, Accuracy: 65.93% Thresh=0.028, n=20, Accuracy: 64.44% ... It is not the case. Now lets visualize which are the most relevant features. from xgboost import plot_importance fig, ax = plt.subplots(figsize=(8, 8)) # xgboost.plot_importance(..., ax=ax) plot_importance(model, ax=ax) plt.show() Visualize Companies Bonus: In this dataset we are working exclusevely with companies that are traded in the stock exchanges from the US. Now, we will visualize which companies are considered secure to lend money according to agencies. We will make 4 different wordclouds, one for each rating of risk. #### Create a function to generate text for the word cloud def WCloud(dataframe, column, rating): words = &#39;&#39; # iterate through the csv file for val in dataframe.loc[dataframe[&#39;Rating&#39;] == rating, column]: # typecaste each val to string val = str(val) val = val.replace(&quot;.&quot;, &quot;&quot;) val = val.replace(&quot;,&quot;, &quot;&quot;) # split the value tokens = val.split() #Converts each token into lowercase for i in range(len(tokens)): tokens[i] = tokens[i].lower() words += &quot; &quot;.join(tokens) + &quot; &quot; return words You may observe that some companies may be in different plots. Thats because they have been rated in different times with different rates." /><link rel="canonical" href="http://localhost:4000/blog/corporateCreditRatingPrediction/" /><meta property="og:url" content="http://localhost:4000/blog/corporateCreditRatingPrediction/" /><meta property="og:site_name" content="Blackcurrant" /><meta property="og:image" content="http://localhost:4000/assets/images/finance.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2018-11-01T00:00:00+11:00" /><script type="application/ld+json"> {"datePublished":"2018-11-01T00:00:00+11:00","@type":"BlogPosting","image":"http://localhost:4000/assets/images/finance.jpg","url":"http://localhost:4000/blog/corporateCreditRatingPrediction/","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/corporateCreditRatingPrediction/"},"author":{"@type":"Person","name":"Alan Gewerc"},"headline":"Corporate Credit Rating Forecasting","dateModified":"2018-11-01T00:00:00+11:00","description":"Introduction This notebook contains the results of the data analysis performed on a set of corporate credit ratings given by ratings agencies to a set of companies. The aim of the data analysis is to build a machine learning model from the rating data that can be used to predict the rating a company will receive. The first section section of the notebook shows the exploratory data analysis (EDA) performed to explore and understand the data. It looks at each attribute (variable) in the data to understand the nature and distribution of the attribute values. It also examines the correlation between the variables through visual analysis. A summary at the end highlights the key findings of the EDA. The second section shows the development of a machine learning model. Many diffferent models are tested and the performance of all models are compared. Subsequently, a winner is selected and we do hyperparameter tunning. In the model evaluation step we use different techniques such as a confusion matrix and scores as F1, Precision and Recall to understand different aspects of the performance of the model. We also perform feature selection to know what financial indicators are more relevant for the rating agencies. The Dataset There are 30 features for every company of which 25 are financial indicators. They can be divided in: Liquidity Measurement Ratios: currentRatio, quickRatio, cashRatio, daysOfSalesOutstanding Profitability Indicator Ratios: grossProfitMargin, operatingProfitMargin, pretaxProfitMargin, netProfitMargin, effectiveTaxRate, returnOnAssets, returnOnEquity, returnOnCapitalEmployed Debt Ratios: debtRatio, debtEquityRatio Operating Performance Ratios: assetTurnover Cash Flow Indicator Ratios: operatingCashFlowPerShare, freeCashFlowPerShare, cashPerShare, operatingCashFlowSalesRatio, freeCashFlowOperatingCashFlowRatio Libraries used: pandas numpy matplotlib seaborn random sklearn xgboost wordcloud Load the Libraries used in the notebook import pandas as pdf import numpy as np from numpy import loadtxt from numpy import sort import matplotlib.pyplot as plt %matplotlib inline from matplotlib.ticker import PercentFormatter import matplotlib.ticker as mtick from wordcloud import WordCloud, STOPWORDS from random import sample import seaborn as sns import xgboost as xgb from xgboost import XGBClassifier from sklearn .... Import Dataset df_rating = pd.read_csv(&#39;data/corporate_rating.csv&#39;) Exploratory Data Analysis Our first step is to perform an exploratory data analysis to understand the charateristics of dataset. Here are some quesitons we will try to adress: What are the dimensions of the data? How do predictors relate to each other? What are the classes of the data? How are the predictors distributed? How are the labels distributed? Do we have missing values? Are outliers are relevant? Are there any transformations that must be done with the dataset? # Display the dimensions print(&quot;The credit rating dataset has&quot;, df_rating.shape[0], &quot;records, each with&quot;, df_rating.shape[1], &quot;attributes&quot;) The credit rating dataset has 2029 records, each with 31 attributes We will now use the function .info() to see the classes of columns and search missing values. # Display the structure df_rating.info() RangeIndex: 2029 entries, 0 to 2028 Data columns (total 31 columns): Rating 2029 non-null object Name 2029 non-null object Symbol 2029 non-null object Rating Agency Name 2029 non-null object Date 2029 non-null object Sector 2029 non-null object currentRatio 2029 non-null float64 quickRatio 2029 non-null float64 cashRatio 2029 non-null float64 daysOfSalesOutstanding 2029 non-null float64 netProfitMargin 2029 non-null float64 pretaxProfitMargin 2029 non-null float64 grossProfitMargin 2029 non-null float64 operatingProfitMargin 2029 non-null float64 returnOnAssets 2029 non-null float64 ... dtypes: float64(25), object(6) memory usage: 491.5+ KB We have 26 columns of numerical data and 6 descriptive columns (one of which is the label).There are no missing values. A first look at the data: df_rating.head() Rating Name Symbol Rating Agency Name Date Sector currentRatio ... 0 A Whirlpool Corporation WHR Egan-Jones Ratings Company 11/27/2015 Consumer Durables 0.945894 ... 1 BBB Whirlpool Corporation WHR Egan-Jones Ratings Company 2/13/2014 Consumer Durables 1.033559 ... 2 BBB Whirlpool Corporation WHR Fitch Ratings 3/6/2015 Consumer Durables 0.963703 ... 3 BBB Whirlpool Corporation WHR Fitch Ratings 6/15/2012 Consumer Durables 1.019851 ... 4 BBB Whirlpool Corporation WHR Standard &amp; Poor&#39;s Ratings Services 10/24/2016 Consumer Durables 0.957844 ... 5 rows × 31 columns Analyse Labels As we know we are working with ordinal labels. That means there is a scale from more secure to less secure ratings. For instance, the triple-A (AAA) is the most secure rating a company can receive. On the other hand, the rating D is the less secure. It means the company will likely default on its creditors. Let’s have a first look at the how many reatings we have of each in the dataset. df_rating.Rating.value_counts() BBB 671 BB 490 A 398 B 302 AA 89 CCC 64 AAA 7 CC 5 C 2 D 1 Name: Rating, dtype: int64 We observe that the dataset is very unbalanced. We have 671 triple-Bs (BBB) but only 1 D. However, we are working with Ratings from different companies such as Moody&#39;s, Standard &amp; Poor&#39;s and more. Therefore it is preferred to simplify the labels according to this table from the website investopedia. We will classify our labels according to the grading risk and not the rate. Bond Rating         Moody’s Standard &amp; Poor’s Fitch Grade Risk Aaa AAA AAA Investment Lowest Risk Aa AA AA Investment Low Risk A A A Investment Low Risk Baa BBB BBB Investment Medium Risk Ba, B BB, B BB, B Junk High Risk Caa/Ca CCC/CC/C CCC/CC/C Junk Highest Risk C D D Junk In Default To do it we will replace with a dictonary each of this ratings. rating_dict = {&#39;AAA&#39;:&#39;Lowest Risk&#39;, &#39;AA&#39;:&#39;Low Risk&#39;, &#39;A&#39;:&#39;Low Risk&#39;, &#39;BBB&#39;:&#39;Medium Risk&#39;, &#39;BB&#39;:&#39;High Risk&#39;, &#39;B&#39;:&#39;High Risk&#39;, &#39;CCC&#39;:&#39;Highest Risk&#39;, &#39;CC&#39;:&#39;Highest Risk&#39;, &#39;C&#39;:&#39;Highest Risk&#39;, &#39;D&#39;:&#39;In Default&#39;} df_rating.Rating = df_rating.Rating.map(rating_dict) ax = df_rating[&#39;Rating&#39;].value_counts().plot(kind=&#39;bar&#39;, figsize=(8,4), title=&quot;Count of Rating by Type&quot;, grid=True) Unfortunately, given the lack of Credit Ratings classified as Lowest Risk and In Default we will have to eliminate then from the table. However, the dataset will keep unbalanced and if needed we will have to adress this issue in further steps. df_rating = df_rating[df_rating[&#39;Rating&#39;]!=&#39;Lowest Risk&#39;] # filter Lowest Risk df_rating = df_rating[df_rating[&#39;Rating&#39;]!=&#39;In Default&#39;] # filter In Default df_rating.reset_index(inplace = True, drop=True) # reset index Descriptive Statistics Now we will use statistical tools, especially from pandas to improve the understanding from the dataset, especially the numerical features. We have seen there are 25 numerical columns in the dataset, all of each are financial indicators from the companies. The function describe() returns information about the distribution of the data such as quantiles, min and max. # Statistical summary df_rating.describe() currentRatio quickRatio cashRatio daysOfSalesOutstanding netProfitMargin ... count 2021.000000 2021.000000 2021.000000 2021.000000 2021.000000 ... 2021.000000 mean 3.535411 2.657150 0.669048 334.855415 0.278725 ... std 44.139386 33.009920 3.590902 4456.606352 6.076128 ... min -0.932005 -1.893266 -0.192736 -811.845623 -101.845815 ... 25% 1.071930 0.602298 0.131433 22.806507 0.020894 ... 50% 1.492804 0.979094 0.297859 42.281804 0.064323 ... 75% 2.160710 1.450457 0.625355 59.165369 0.113871 ... max 1725.505005 1139.541703 125.917417 115961.637400 198.517873 ... 8 rows × 25 columns Skewness and Outliers We observe a lot of skewness in the data with this first exploration. In this case, it means that most variables in the dataset may strong presence of outliers. Taking as observation the table above the first column: currentRatio: This 50% of its variables between 1.071 and 2.166891. The minimum value is -0.932005 however the maximum value is 1725.505005. It means, in other words, there is a giant outlier that is extremely distant from most points from the data (currentRatio). The same pattern can be observed in the following columns such as quickRatio, cashRatio, daysOfSalesOutstanding, netProfitMargin and so on. To observe how this reflect on the distribution of the data lets make some plots of variables chose randomly. column_list = list(df_rating.columns[6:31]) column_list = sample(column_list,4) print(column_list) [&#39;operatingCashFlowSalesRatio&#39;, &#39;grossProfitMargin&#39;, &#39;returnOnEquity&#39;, &#39;companyEquityMultiplier&#39;] &lt;/samp&gt; figure, axes = plt.subplots(nrows=2, ncols=4, figsize=(9,5)) axes[0, 0].hist(df_rating[column_list[0]]) axes[0, 1].hist(df_rating[column_list[1]]) axes[1, 0].hist(df_rating[column_list[2]]) axes[1, 1].hist(df_rating[column_list[3]]) axes[0, 2].boxplot(df_rating[column_list[0]]) axes[1, 2].boxplot(df_rating[column_list[1]]) axes[0, 3].boxplot(df_rating[column_list[2]]) axes[1, 3].boxplot(df_rating[column_list[3]]) figure.tight_layout() As predicted, the data is comtaminated by outliers. We canot observe real behaviour of the distribution because some points differ too much from the others. We will use the function .skew from pandas in all columns. It should return between 0 and 1 if a column is normally distributed. df_rating.skew(axis=0) currentRatio 34.271115 quickRatio 30.864610 cashRatio 27.046952 daysOfSalesOutstanding 20.359098 netProfitMargin 17.585073 pretaxProfitMargin 22.052558 grossProfitMargin -14.198688 operatingProfitMargin 26.441502 returnOnAssets -32.049111 returnOnCapitalEmployed -33.252701 returnOnEquity 31.639845 assetTurnover 25.968848 fixedAssetTurnover 26.068762 debtEquityRatio 0.268074 debtRatio 1.284256 effectiveTaxRate 32.265705 freeCashFlowOperatingCashFlowRatio -22.868222 freeCashFlowPerShare 33.610677 cashPerShare 33.958646 companyEquityMultiplier 0.268175 ebitPerRevenue 22.055668 enterpriseValueMultiple 13.920117 operatingCashFlowPerShare 30.292914 operatingCashFlowSalesRatio 25.400129 payablesTurnover 25.868293 dtype: float64 We observe this is a generalized problem. As we can see almost all columns are extremely skewed. We will now go deeper in the investigation of outliers. The following code will return the proportion of outliers in each column . The definition of outlier will be the one from the boxplot - above or bellow 1.5 x IQR. for c in df_rating.columns[6:31]: q1 = df_rating[c].quantile(0.25) q3 = df_rating[c].quantile(0.75) iqr = q3 - q1 #Interquartile range fence_low = q3-1.5*iqr fence_high = q1+1.5*iqr lower_out = len(df_rating.loc[(df_rating[c] &lt; fence_low) ,c]) upper_out = len(df_rating.loc[(df_rating[c] &gt; fence_high) ,c]) outlier_count = upper_out+lower_out prop_out = outlier_count/len(df_rating) print(c, &quot;: &quot;+&quot;{:.2%}&quot;.format(prop_out)) currentRatio : 18.01% quickRatio : 19.05% cashRatio : 14.84% daysOfSalesOutstanding : 23.55% netProfitMargin : 25.09% pretaxProfitMargin : 24.49% grossProfitMargin : 0.99% operatingProfitMargin : 22.12% returnOnAssets : 24.25% returnOnCapitalEmployed : 22.07% returnOnEquity : 28.70% assetTurnover : 15.83% fixedAssetTurnover : 13.46% debtEquityRatio : 22.07% debtRatio : 21.33% effectiveTaxRate : 28.06% freeCashFlowOperatingCashFlowRatio : 16.92% freeCashFlowPerShare : 23.55% cashPerShare : 17.12% companyEquityMultiplier : 22.02% ebitPerRevenue : 24.34% enterpriseValueMultiple : 23.70% operatingCashFlowPerShare : 17.66% operatingCashFlowSalesRatio : 16.87% payablesTurnover : 14.45% Most columns have a significant number of outliers. However it is not clear for us if there are a few rows that all outliers or each of the rows may be contributing individually with some outliers. We will now check by row the distribution of outliers. We will create a new dataframe that df_rating_outlier that will be used with this purpose. In this dataframe every cell will 1 one if the corresponding cell is an outlier in df_raint and 0 if it is not. df_rating_outlier = df_rating.copy() for c in df_rating_outlier.columns[6:31]: q1 = df_rating_outlier[c].quantile(0.25) q3 = df_rating_outlier[c].quantile(0.75) iqr = q3 - q1 #Interquartile range fence_low = q3-1.5*iqr fence_high = q1+1.5*iqr for i in range(len(df_rating_outlier)): if df_rating.loc[i,c] &lt; fence_low or df_rating.loc[i,c] &gt; fence_high: # if Outlier df_rating_outlier.loc[i,c] = 1 else: # Not Outlier df_rating_outlier.loc[i,c] = 0 Now we will be able to count how many outliers each row has and plot it. df_rating_outlier[&quot;total&quot;] = df_rating_outlier.sum(axis=1) df_rating_outlier.total.hist(bins = 20) This is a very interesting plot. We can see that only up to 400 rows don’t have any outliers. Most rows have outliers and maybe they will be useful in the further classification tasks. Therefore we see no value in excluding the outliers from the dataset. However we will perform a transformation on the data so we can reduce its negative impact. Data reshaping We will now perform the following steps in each of the numerical data. Normalize the data between 0 and 1 (and multiply by 1.000). Apply log on base 10 on each of the variables. from sklearn import preprocessing min_max_scaler = preprocessing.MinMaxScaler() for c in df_rating.columns[6:31]: df_rating[[c]] = min_max_scaler.fit_transform(df_rating[[c]].to_numpy())*1000 df_rating[[c]] = df_rating[c].apply(lambda x: np.log10(x+0.01)) Again the plots figure, axes = plt.subplots(nrows=2, ncols=4, figsize=(9,5)) axes[0, 0].hist(df_rating[column_list[0]]) axes[0, 1].hist(df_rating[column_list[1]]) axes[1, 0].hist(df_rating[column_list[2]]) axes[1, 1].hist(df_rating[column_list[3]]) axes[0, 2].boxplot(df_rating[column_list[0]]) axes[1, 2].boxplot(df_rating[column_list[1]]) axes[0, 3].boxplot(df_rating[column_list[2]]) axes[1, 3].boxplot(df_rating[column_list[3]]) figure.tight_layout() We have a problem with respect to vizualisation of the data. The impact of the outliers is so big that we cannot observe the patterns in the data. To enhance our visualization we will from now ignore outliers. We will replace then by values with lower impact such as the lower hinge. In this way we will be able to continue with our EDA. To preserve our dataset we will use a new table called df_rating_no_out. df_rating_no_out = df_rating.copy() for c in df_rating_no_out.columns[6:31]: q05 = df_rating_no_out[c].quantile(0.10) q95 = df_rating_no_out[c].quantile(0.90) iqr = q95 - q05 #Interquartile range fence_low = q05-1.5*iqr fence_high = q95+1.5*iqr df_rating_no_out.loc[df_rating_no_out[c] &gt; fence_high,c] = df_rating_no_out[c].quantile(0.25) df_rating_no_out.loc[df_rating_no_out[c] &lt; fence_low,c] = df_rating_no_out[c].quantile(0.75) Now that we have this dataframe we can use it use it to observe the data from a different angle. We will be able to observe the distribution that was hidden by the outliers. The first step: Plot all columns (boxplot) by each label:High Risk, Low Risk, Medium Risk, Highest Risk. figure, axes = plt.subplots(nrows=8, ncols=3, figsize=(20,44)) i = 0 j = 0 for c in df_rating_no_out.columns[6:30]: sns.boxplot(x=df_rating_no_out.Rating, y=df_rating_no_out[c], palette=&quot;Set3&quot;, ax=axes[i, j]) if j == 2: j=0 i+=1 else: j+=1 The most interesting point about the previous plots is the fact that they clearly show a difference in the medians and distribution according to the rating (Risk). It points to a scenario where the variables will have good predictive power for classification. Following with our analysis we will create scatter plots to see if we can observe who the variables relate to each other and how labels can be observer in respect to it. df_rating.colors = &#39;a&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Lowest Risk&#39;, &#39;color&#39;] = &#39;r&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Low Risk&#39;, &#39;color&#39;] = &#39;g&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Medium Risk&#39;, &#39;color&#39;] = &#39;b&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;High Risk&#39;,&#39;color&#39;] = &#39;y&#39; df_rating_no_out.loc[df_rating_no_out[&#39;Rating&#39;] == &#39;Highest Risk&#39;, &#39;color&#39;] = &#39;m&#39; column_list = list(df_rating.columns[6:31]) column_list = sample(column_list,12) figure, axes = plt.subplots(nrows=3, ncols=2, figsize=(14,14)) i = 0 j = 0 for c in range(0,12, 2): sns.scatterplot(x = column_list[c], y=column_list[c+1], hue=&quot;color&quot;, data=df_rating_no_out, ax=axes[j,i]) if i == 1: i = 0 j +=1 else: i+=1 In fact, we are working with a dataset that has a big numer of dimensions. With two variables it would not be possible to make any predictions. However this is not the case. Unfortunately we are not able to vizualise the data in all its dimensions, but luckely we will be able to perform accurate classificaitons. Machine Learning Is it possible to predict what creidt profile a company will receive from a rating agency based on its financial indicators? If so, what are the most important predictors? Apparently not much work has been done with regards to this question. This academic paper was the only work found about it. It is worth checking it out. As we will do it, it tests most ML algorithms and identifies the most important features. In the following steps we will perform the following: Prepare the dataset Split in train and test Transform/Encode the features kand labels Test a wide range of ML models (Tree-based, Probabilistic and so on). Compare the accuracry of all models. Choose our winning model and tune hyperparameters to target a higher accuracy. Make a more profound evaluation of the result with a confusion matrix and different measures. identify the most important features to predict the rating. Prepare the Dataset le = preprocessing.LabelEncoder() le.fit(df_rating.Sector) df_rating.Sector = le.transform(df_rating.Sector) # encode sector le.fit(df_rating.Rating) df_rating.Rating = le.transform(df_rating.Rating) # encode rating df_train, df_test = train_test_split(df_rating, test_size=0.2, random_state = 1234) X_train, y_train = df_train.iloc[:,5:31], df_train.iloc[:,0] X_test, y_test = df_test.iloc[:,5:31], df_test.iloc[:,0] Fit Models Now we will test a range of models. In each we will fit the model in the train data, make predictons for the test data and obtain the accuracy. In later steps we will compare the accuracy of all the models. We will use primarily the library sklearn but also XGBoost. XGBoost XGB_model = xgb.XGBRegressor(objective =&#39;multi:softmax&#39;, num_class =4) XGB_model.fit(X_train, y_train) y_pred_XGB = XGB_model.predict(X_test) Accuracy_XGB = metrics.accuracy_score(y_test, y_pred_XGB) print(&quot;XGB Accuracy:&quot;,Accuracy_XGB) XGB Accuracy: 0.691358024691358 Gradient Boosting Classifier GBT_model = GradientBoostingClassifier(random_state=123) GBT_model.fit(X_train, y_train) y_pred_GBT = GBT_model.predict(X_test) Accuracy_GBT = metrics.accuracy_score(y_test, y_pred_GBT) print(&quot;GBT Accuracy:&quot;,Accuracy_GBT) GBT Accuracy: 0.6320987654320988 Random Forest RF_model = RandomForestClassifier(random_state=1234) RF_model.fit(X_train,y_train) y_pred_RF = RF_model.predict(X_test) Accuracy_RF = metrics.accuracy_score(y_test, y_pred_RF) print(&quot;RF Accuracy:&quot;,Accuracy_RF) RF Accuracy: 0.6246913580246913 Support Vector Machine SVC_model = svm.SVC(kernel=&#39;rbf&#39;, gamma= 2, C = 5, random_state=1234) SVC_model.fit(X_train, y_train) y_pred_SVM = SVC_model.predict(X_test) Accuracy_SVM = metrics.accuracy_score(y_test, y_pred_SVM) print(&quot;SVM Accuracy:&quot;,Accuracy_SVM) SVM Accuracy: 0.5333333333333333 Neural Network MLP_model = MLPClassifier(hidden_layer_sizes=(5,5,5), activation=&#39;logistic&#39;, solver=&#39;adam&#39;, max_iter=1500) MLP_model.fit(X_train, y_train) y_pred_MLP = MLP_model.predict(X_test) Accuracy_MLP = metrics.accuracy_score(y_test, y_pred_MLP) print(&quot;MLP Accuracy:&quot;,Accuracy_MLP) MLP Accuracy: 0.3654320987654321 Naive Bayes GNB_model = GaussianNB() GNB_model.fit(X_train, y_train) y_pred_GNB = GNB_model.predict(X_test) Accuracy_GNB = metrics.accuracy_score(y_test, y_pred_GNB) print(&quot;GNB Accuracy:&quot;,Accuracy_GNB) GNB Accuracy: 0.30864197530864196 Linear Discriminant Analysis LDA_model = LinearDiscriminantAnalysis() LDA_model.fit(X_train,y_train) y_pred_LDA = LDA_model.predict(X_test) Accuracy_LDA = metrics.accuracy_score(y_test, y_pred_LDA) print(&quot;LDA Accuracy:&quot;,Accuracy_LDA) LDA Accuracy: 0.38765432098765434 Quadratic Discriminant Analysis QDA_model = QuadraticDiscriminantAnalysis() QDA_model.fit(X_train,y_train) y_pred_QDA = QDA_model.predict(X_test) Accuracy_QDA = metrics.accuracy_score(y_test, y_pred_QDA) print(&quot;QDA Accuracy:&quot;,Accuracy_QDA) QDA Accuracy: 0.35555555555555557 K Nearest Neighbours KNN_model = KNeighborsClassifier(n_neighbors = 3) KNN_model.fit(X_train,y_train) y_pred_KNN = KNN_model.predict(X_test) Accuracy_KNN = metrics.accuracy_score(y_test, y_pred_KNN) print(&quot;KNN Accuracy:&quot;,Accuracy_KNN) KNN Accuracy: 0.5802469135802469 Logistic Regression LR_model = LogisticRegression(random_state=1234 , multi_class=&#39;multinomial&#39;, solver=&#39;newton-cg&#39;) LR_model = LR_model.fit(X_train, y_train) y_pred_LR = LR_model.predict(X_test) Accuracy_LR = metrics.accuracy_score(y_test, y_pred_LR) print(&quot;LR Accuracy:&quot;,Accuracy_LR) LR Accuracy: 0.3925925925925926 Compare Results accuracy_list = [Accuracy_XGB, Accuracy_GBT, Accuracy_RF, Accuracy_SVM, Accuracy_MLP, Accuracy_GNB, Accuracy_LDA, Accuracy_QDA, Accuracy_KNN, Accuracy_LR] model_list = [&#39;XGBboost&#39;, &#39;Gradient Boosting&#39;, &#39;Random Forest&#39;, &#39;Support Vector Machine&#39;, &quot;Neural Network&quot;, &#39;Naive Bayes&#39;, &#39;Linear Discriminat&#39;, &#39;Quadratic Discriminat&#39;, &#39;KNN&#39;, &#39;Logistic Regression&#39;] df_accuracy = pd.DataFrame({&#39;Model&#39;: model_list, &#39;Accuracy&#39;: accuracy_list}) order = list(df_accuracy.sort_values(&#39;Accuracy&#39;, ascending=False).Model) df_accuracy = df_accuracy.sort_values(&#39;Accuracy&#39;, ascending=False).reset_index().drop([&#39;index&#39;], axis=1) plt.figure(figsize=(12,8)) # make barplot and sort bars x = sns.barplot(x=&#39;Model&#39;, y=&quot;Accuracy&quot;, data=df_accuracy, order = order, palette=&quot;rocket&quot;) plt.xlabel(&quot;Model&quot;, fontsize=20) plt.ylabel(&quot;Accuracy&quot;, fontsize=20) plt.title(&quot;Accuracy by Model&quot;, fontsize=20) plt.grid(linestyle=&#39;-&#39;, linewidth=&#39;0.5&#39;, color=&#39;grey&#39;) plt.xticks(rotation=70, fontsize=12) plt.ylim(0,1) plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1)) for i in range(len(model_list)): plt.text(x = i, y = df_accuracy.loc[i, &#39;Accuracy&#39;] + 0.05, s = str(round((df_accuracy.loc[i, &#39;Accuracy&#39;])*100, 2))+&#39;%&#39;, fontsize = 14, color=&#39;black&#39;,horizontalalignment=&#39;center&#39;) y_value=[&#39;{:,.2f}&#39;.format(x) + &#39;%&#39; for x in ax.get_yticks()] ax.set_yticklabels(y_value) plt.tight_layout() We have our winner. XGboost is the best performing model. XGBoost Hyperparameter Tunning The XGboost model has achieved a very high accuracy given that we have 4 different classes. Now we will try to increase the performance even more. We will use a cross-validation approach and we will follow similar steps to this tutorial. First we load the train and test data into DMatrices. DMatrix is a data structure used by XGBoost to optimize both memory efficiency and training speed. dtrain = xgb.DMatrix(X_train, label=y_train) dtest = xgb.DMatrix(X_test, label=y_test) The params dictionary We create a dictonary with the parameters from our previous XGboost model. params = XGB_model.get_xgb_params() {&#39;objective&#39;: &#39;multi:softmax&#39;, &#39;base_score&#39;: 0.5, &#39;booster&#39;: &#39;gbtree&#39;, &#39;colsample_bylevel&#39;: 1, &#39;colsample_bynode&#39;: 1, &#39;colsample_bytree&#39;: 1, &#39;gamma&#39;: 0, &#39;gpu_id&#39;: -1, &#39;interaction_constraints&#39;: &#39;&#39;, &#39;learning_rate&#39;: 0.300000012, &#39;max_delta_step&#39;: 0, &#39;max_depth&#39;: 6, &#39;min_child_weight&#39;: 1, &#39;monotone_constraints&#39;: &#39;()&#39;, &#39;n_jobs&#39;: 0, &#39;num_parallel_tree&#39;: 1, &#39;random_state&#39;: 0, &#39;reg_alpha&#39;: 0, &#39;reg_lambda&#39;: 1, &#39;scale_pos_weight&#39;: None, &#39;subsample&#39;: 1, &#39;tree_method&#39;: &#39;exact&#39;, &#39;validate_parameters&#39;: 1, &#39;verbosity&#39;: None, &#39;num_class&#39;: 4} We will use the merror error parameter from classification. It is basic an accuracy. params[&#39;eval_metric&#39;] = &quot;merror&quot; The num_boost_round which corresponds to the maximum number of boosting rounds that we allow. num_boost_round = 1000 model = xgb.train( params, dtrain, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)], early_stopping_rounds=50, verbose_eval=30) print(&quot;Best merror: {:.2f} with {} rounds&quot;.format( model.best_score, model.best_iteration+1)) [0] Test-merror:0.44691&lt;br&gt; Will train until Test-merror hasn&#39;t improved in 50 rounds.&lt;br&gt; [30] Test-merror:0.34568&lt;br&gt; [60] Test-merror:0.32839&lt;br&gt; [90] Test-merror:0.30617&lt;br&gt; [120] Test-merror:0.30864&lt;br&gt; [150] Test-merror:0.30864&lt;br&gt; Stopping. Best iteration:&lt;br&gt; [104] Test-merror:0.29877&lt;br&gt; Best merror: 0.30 with 105 rounds Using XGBoost’s CV In order to tune the other hyperparameters, we will use the cv function from XGBoost. It allows us to run cross-validation on our training dataset and returns a mean merror score. We will use a k = 5 for every parameter. cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=50, verbose_eval=30 ) cv_results.tail() [0] train-merror:0.24412+0.00946 test-merror:0.44677+0.01983 [30] train-merror:0.00015+0.00031 test-merror:0.35580+0.04214 [60] train-merror:0.00000+0.00000 test-merror:0.34466+0.03896 [90] train-merror:0.00000+0.00000 test-merror:0.34775+0.04295 train-merror-mean train-merror-std test-merror-mean test-merror-std 55 0.0 0.0 0.347756 0.036916 56 0.0 0.0 0.345899 0.036946 57 0.0 0.0 0.345284 0.039353 58 0.0 0.0 0.343426 0.038823 59 0.0 0.0 0.342811 0.037624 cv_results[&#39;test-merror-mean&#39;].min() 0.34281059999999997 Now we are ready to start tuning. We will first tune our parameters to minimize the merror on cross-validation, and then check the performance of our model on the test dataset. Parameters max_depth and min_child_weight. gridsearch_params = [ (max_depth, min_child_weight) for max_depth in range(5,12) for min_child_weight in range(5,8) ] # Define initial best params and MAE min_merror = float(&quot;Inf&quot;) best_params = None for max_depth, min_child_weight in gridsearch_params: print(&quot;CV with max_depth={}, min_child_weight={}&quot;.format( max_depth, min_child_weight)) # Update our parameters params[&#39;max_depth&#39;] = max_depth params[&#39;min_child_weight&#39;] = min_child_weight # Run CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=50, verbose_eval=False ) # Update best merror mean_merror = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\\tMAE {} for {} rounds&quot;.format(mean_merror, boost_rounds)) if mean_merror &lt; min_merror: min_merror = mean_merror best_params = (max_depth,min_child_weight) print(&quot;Best params: {}, {}, merror: {}&quot;.format(best_params[0], best_params[1], min_merror)) CV with max_depth=5, min_child_weight=5 MAE 0.3533254 for 75 rounds CV with max_depth=5, min_child_weight=6 MAE 0.3533292 for 132 rounds CV with max_depth=5, min_child_weight=7 MAE 0.3588922 for 100 rounds CV with max_depth=6, min_child_weight=5 MAE 0.3496082 for 84 rounds CV with max_depth=6, min_child_weight=6 MAE 0.3508504 for 165 rounds CV with max_depth=6, min_child_weight=7 MAE 0.3545598 for 79 rounds CV with max_depth=7, min_child_weight=5 MAE 0.33784559999999997 for 82 rounds CV with max_depth=7, min_child_weight=6 MAE 0.3471276 for 220 rounds CV with max_depth=7, min_child_weight=7 MAE 0.3533136 for 45 rounds CV with max_depth=8, min_child_weight=5 MAE 0.3446568 for 70 rounds CV with max_depth=8, min_child_weight=6 MAE 0.3514716 for 45 rounds CV with max_depth=8, min_child_weight=7 MAE 0.35703860000000004 for 95 rounds CV with max_depth=9, min_child_weight=5 MAE 0.3409416 for 80 rounds CV with max_depth=9, min_child_weight=6 MAE 0.3384664 for 60 rounds CV with max_depth=9, min_child_weight=7 MAE 0.34961180000000003 for 60 rounds CV with max_depth=10, min_child_weight=5 MAE 0.3458856 for 46 rounds CV with max_depth=10, min_child_weight=6 MAE 0.3403222 for 135 rounds CV with max_depth=10, min_child_weight=7 MAE 0.34712400000000004 for 43 rounds CV with max_depth=11, min_child_weight=5 MAE 0.3390972 for 117 rounds CV with max_depth=11, min_child_weight=6 MAE 0.34837559999999995 for 81 rounds CV with max_depth=11, min_child_weight=7 MAE 0.34157399999999993 for 134 rounds Best params: 7, 5, merror: 0.33784559999999997 We get the best score with a max_depth of 9 and min_child_weight of 6, so let’s params[&#39;max_depth&#39;] = 7 params[&#39;min_child_weight&#39;] = 5 Parameters subsample and colsample_bytree gridsearch_params = [ (subsample, colsample) for subsample in [i/10. for i in range(7,11)] for colsample in [i/10. for i in range(7,11)] ] # Define initial best params and MAE min_merror = float(&quot;Inf&quot;) best_params = None for subsample, colsample in reversed(gridsearch_params): print(&quot;CV with subsample={}, colsample={}&quot;.format( subsample, colsample)) # We update our parameters params[&#39;subsample&#39;] = subsample params[&#39;colsample_bytree&#39;] = colsample # Run CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics={&#39;merror&#39;}, early_stopping_rounds=10, verbose_eval=False ) # Update best MAE mean_merror = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\\tMAE {} for {} rounds&quot;.format(mean_merror, boost_rounds)) if mean_merror &lt; min_merror: min_merror = mean_merror best_params = (subsample,colsample) print(&quot;Best params: {}, {}, merror: {}&quot;.format(best_params[0], best_params[1], min_mae)) CV with subsample=1.0, colsample=1.0 MAE 0.34280299999999997 for 57 rounds CV with subsample=1.0, colsample=0.9 MAE 0.35086200000000006 for 47 rounds CV with subsample=1.0, colsample=0.8 MAE 0.335384 for 53 rounds CV with subsample=1.0, colsample=0.7 MAE 0.3477508 for 46 rounds CV with subsample=0.9, colsample=1.0 MAE 0.3489852 for 47 rounds CV with subsample=0.9, colsample=0.9 MAE 0.36075179999999996 for 32 rounds CV with subsample=0.9, colsample=0.8 MAE 0.35519259999999997 for 22 rounds CV with subsample=0.9, colsample=0.7 MAE 0.3316686 for 67 rounds CV with subsample=0.8, colsample=1.0 MAE 0.344668 for 22 rounds CV with subsample=0.8, colsample=0.9 MAE 0.344045 for 31 rounds CV with subsample=0.8, colsample=0.8 MAE 0.3490044 for 49 rounds CV with subsample=0.8, colsample=0.7 MAE 0.356431 for 41 rounds CV with subsample=0.7, colsample=1.0 MAE 0.34713720000000003 for 51 rounds CV with subsample=0.7, colsample=0.9 MAE 0.352079 for 66 rounds CV with subsample=0.7, colsample=0.8 MAE 0.34591779999999994 for 65 rounds CV with subsample=0.7, colsample=0.7 MAE 0.3521078 for 57 rounds Best params: 0.9, 0.7, merror: 0.3316686 params[&#39;subsample&#39;] =0.9 params[&#39;colsample_bytree&#39;] = 0.7 Parameter ETA %time # This can take some time… min_merror = float(&quot;Inf&quot;) best_params = None for eta in [.3, .2, .1, .05, .01, .005]: print(&quot;CV with eta={}&quot;.format(eta)) # We update our parameters params[&#39;eta&#39;] = eta # Run and time CV cv_results = xgb.cv( params, dtrain, num_boost_round=num_boost_round, seed=42, nfold=5, metrics=[&#39;merror&#39;], early_stopping_rounds=10 ) # Update best score mean_mae = cv_results[&#39;test-merror-mean&#39;].min() boost_rounds = cv_results[&#39;test-merror-mean&#39;].argmin() print(&quot;\\tMAE {} for {} rounds\\n&quot;.format(mean_mae, boost_rounds)) if mean_mae &lt; min_mae: min_mae = mean_mae best_params = eta print(&quot;Best params: {}, merror: {}&quot;.format(best_params, min_mae)) Wall time: 0 ns CV with eta=0.3 MAE 0.3316686 for 67 rounds CV with eta=0.2 MAE 0.3316686 for 67 rounds CV with eta=0.1 MAE 0.3316686 for 67 rounds CV with eta=0.05 MAE 0.3316686 for 67 rounds CV with eta=0.01 MAE 0.3316686 for 67 rounds CV with eta=0.005 MAE 0.3316686 for 67 rounds Best params: None, merror: 0.3316686 params[&#39;eta&#39;] = .3 Results This are the final parameters of our tunned model. params {&#39;objective&#39;: &#39;multi:softmax&#39;, &#39;base_score&#39;: 0.5, &#39;booster&#39;: &#39;gbtree&#39;, &#39;colsample_bylevel&#39;: 1, &#39;colsample_bynode&#39;: 1, &#39;colsample_bytree&#39;: 0.7, &#39;gamma&#39;: 0, &#39;gpu_id&#39;: -1, &#39;interaction_constraints&#39;: &#39;&#39;, &#39;learning_rate&#39;: 0.300000012, &#39;max_delta_step&#39;: 0, &#39;max_depth&#39;: 7, &#39;min_child_weight&#39;: 5, &#39;monotone_constraints&#39;: &#39;()&#39;, &#39;n_jobs&#39;: 0, &#39;num_parallel_tree&#39;: 1, &#39;random_state&#39;: 0, &#39;reg_alpha&#39;: 0, &#39;reg_lambda&#39;: 1, &#39;scale_pos_weight&#39;: None, &#39;subsample&#39;: 0.9, &#39;tree_method&#39;: &#39;exact&#39;, &#39;validate_parameters&#39;: 1, &#39;verbosity&#39;: None, &#39;num_class&#39;: 4, &#39;eval_metric&#39;: &#39;merror&#39;, &#39;eta&#39;: 0.3} Let’s train a model with it and see how well it does on our test set! model = xgb.train( params, dtrain, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)], early_stopping_rounds=1000, verbose_eval=100 ) [0] Test-merror:0.45679 Will train until Test-merror hasn&#39;t improved in 1000 rounds. [100] Test-merror:0.34321 [200] Test-merror:0.33827 [300] Test-merror:0.34321 [400] Test-merror:0.34321 [500] Test-merror:0.34815 [600] Test-merror:0.35062 [700] Test-merror:0.34815 [800] Test-merror:0.34815 [900] Test-merror:0.35062 [999] Test-merror:0.35556 num_boost_round = model.best_iteration + 1 best_model = xgb.train( params, dtrain, verbose_eval=100, num_boost_round=num_boost_round, evals=[(dtest, &quot;Test&quot;)] ) [0] Test-merror:0.45679 [100] Test-merror:0.34321 [200] Test-merror:0.33827 [278] Test-merror:0.32593 metrics.accuracy_score(best_model.predict(dtest), y_test) 0.674074074074074 We did not arrive in an enhanced model with this tunning. Anyone is welcome to continue this tunning and achieve a superior accuracy. Confusion Matrix We will now analyse according to each class the performance of the model. The best way to do it is with a confusion matrix. We can see how many points were missclassified and where were then classified to if not the right rating. cm = confusion_matrix(y_test, y_pred_XGB) fig, ax = plt.subplots(figsize=(8,8)) sns.heatmap(cm, annot = True, ax = ax, vmin=0, vmax=150, fmt=&quot;d&quot;, linewidths=.5, linecolor = &#39;white&#39;, cmap=&quot;Reds&quot;) # annot=True to annotate cells # labels, title and ticks ax.set_xlabel(&#39;Predicted labels&#39;) ax.set_ylabel(&#39;True labels&#39;); ax.set_title(&#39;Confusion Matrix&#39;); ax.xaxis.set_ticklabels([&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;]) ax.yaxis.set_ticklabels([&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;]); # This part is to correct a bug from the heatmap funciton from pyplot b, t = plt.ylim() # discover the values for bottom and top b += 0.5 # Add 0.5 to the bottom t -= 0.5 # Subtract 0.5 from the top plt.ylim(b, t) # update the ylim(bottom, top) values plt.show() Analysis Given the fact that the dataset is very unbalanced, with have achieved a very low accuracy (actually 0) for very risky companies. To deal with it we wiould have to apply upsampling techniques which we may in a future work. Now we analyse other metrics as Precision, recall and F1 from our targets. print(classification_report(y_test, y_pred_XGB, target_names = [&#39;Medium Risk&#39;,&#39;Highest Risk&#39;, &#39;Low Risk&#39;, &#39;High Risk&#39;])) precision recall f1-score support Medium Risk 0.72 0.83 0.77 148 Highest Risk 0.00 0.00 0.00 8 Low Risk 0.73 0.67 0.70 107 High Risk 0.64 0.60 0.62 142 accuracy 0.69 405 macro avg 0.52 0.53 0.52 405 weighted avg 0.68 0.69 0.68 405 Apparetly the fact that we have more labels in the edium Risk has enhanced its classification. However, overall we have achieved good classification scaores for most, with the exception of Highest Risk. Feature Selection In our tast task we will identify which features were the most valuable for our model. In our first step we will check if by any chance we can increase the accuracy of our model extracting a feature. thresholds = sort(XGB_model.feature_importances_) for thresh in thresholds: # select features using threshold selection = SelectFromModel(XGB_model, threshold=thresh, prefit=True) select_X_train = selection.transform(X_train) # train model selection_model = XGBClassifier() selection_model.fit(select_X_train, y_train) # eval model select_X_test = selection.transform(X_test) y_pred = selection_model.predict(select_X_test) predictions = [round(value) for value in y_pred] accuracy = accuracy_score(y_test, predictions) print(&quot;Thresh=%.3f, n=%d, Accuracy: %.2f%%&quot; % (thresh, select_X_train.shape[1], accuracy*100.0)) Thresh=0.025, n=26, Accuracy: 69.14% Thresh=0.026, n=25, Accuracy: 67.16% Thresh=0.026, n=24, Accuracy: 67.16% Thresh=0.027, n=23, Accuracy: 64.69% Thresh=0.027, n=22, Accuracy: 64.44% Thresh=0.027, n=21, Accuracy: 65.93% Thresh=0.028, n=20, Accuracy: 64.44% ... It is not the case. Now lets visualize which are the most relevant features. from xgboost import plot_importance fig, ax = plt.subplots(figsize=(8, 8)) # xgboost.plot_importance(..., ax=ax) plot_importance(model, ax=ax) plt.show() Visualize Companies Bonus: In this dataset we are working exclusevely with companies that are traded in the stock exchanges from the US. Now, we will visualize which companies are considered secure to lend money according to agencies. We will make 4 different wordclouds, one for each rating of risk. #### Create a function to generate text for the word cloud def WCloud(dataframe, column, rating): words = &#39;&#39; # iterate through the csv file for val in dataframe.loc[dataframe[&#39;Rating&#39;] == rating, column]: # typecaste each val to string val = str(val) val = val.replace(&quot;.&quot;, &quot;&quot;) val = val.replace(&quot;,&quot;, &quot;&quot;) # split the value tokens = val.split() #Converts each token into lowercase for i in range(len(tokens)): tokens[i] = tokens[i].lower() words += &quot; &quot;.join(tokens) + &quot; &quot; return words You may observe that some companies may be in different plots. Thats because they have been rated in different times with different rates.","@context":"https://schema.org"}</script><link rel="stylesheet" href="/assets/css/main-default.css" /><link id="color-scheme" rel="stylesheet" href="/assets/css/main-default.css" /><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/apple-icon-60x60.png" /><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/apple-icon-114x114.png" /><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/apple-icon-152x152.png" /><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/android-icon-192x192.png" /><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" /><link rel="icon" href="/favicon.ico" type="image/x-icon" /><script src="https://cdn.jsdelivr.net/npm/ga-lite@1/dist/ga-lite.min.js" async></script><script> var galite = galite || {}; galite.UA = 'UA-92266803-3';</script><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script><script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script></head><div class="wrapper"><div class="container"><div class="main"><div class="main-container shadow"><div class="title-space"> <h1>Corporate Credit Rating Forecasting</h1></div><hr class="dashed"> <main> <ul class="breadcrumbs"> <li><a href="/">Home</a></li> <li><a href="/blog/">Blog</a></li> <li><a href="#">Corporatecreditra...</a></li> </ul><div class="meta" data-aos="fade-up"> <p> <small> <span> <i class="fa fa-calendar" aria-hidden="true"></i> 01 Nov 2018&nbsp; </span> <span> <i class="fa fa-user" aria-hidden="true"></i> Alan Gewerc&nbsp; </span> <span> <i class="fa fa-clock-o" aria-hidden="true"></i> 48 mins read. </span> </small> </p></div><div class="featured-image" style="background-image: url(/assets/images/finance.jpg)" data-aos="zoom-in" ></div><div class="container"> <article> <h3 id="introduction">Introduction</h3> <p>This notebook contains the results of the data analysis performed on a set of corporate credit ratings given by ratings agencies to a set of companies. The aim of the data analysis is to build a machine learning model from the rating data that can be used to predict the rating a company will receive.</p> <p>The first section section of the notebook shows the exploratory data analysis (EDA) performed to explore and understand the data. It looks at each attribute (variable) in the data to understand the nature and distribution of the attribute values. It also examines the correlation between the variables through visual analysis. A summary at the end highlights the key findings of the EDA.</p> <p>The second section shows the development of a machine learning model. Many diffferent models are tested and the performance of all models are compared. Subsequently, a winner is selected and we do hyperparameter tunning.</p> <p>In the model evaluation step we use different techniques such as a confusion matrix and scores as F1, Precision and Recall to understand different aspects of the performance of the model. We also perform feature selection to know what financial indicators are more relevant for the rating agencies.</p> <h3 id="the-dataset">The Dataset</h3> <p>There are 30 features for every company of which 25 are financial indicators. They can be divided in: <br /></p> <ul> <li><strong>Liquidity Measurement Ratios</strong>: currentRatio, quickRatio, cashRatio, daysOfSalesOutstanding</li> <li><strong>Profitability Indicator Ratios</strong>: grossProfitMargin, operatingProfitMargin, pretaxProfitMargin, netProfitMargin, effectiveTaxRate, returnOnAssets, returnOnEquity, returnOnCapitalEmployed</li> <li><strong>Debt Ratios</strong>: debtRatio, debtEquityRatio</li> <li><strong>Operating Performance Ratios</strong>: assetTurnover</li> <li><strong>Cash Flow Indicator Ratios</strong>: operatingCashFlowPerShare, freeCashFlowPerShare, cashPerShare, operatingCashFlowSalesRatio, freeCashFlowOperatingCashFlowRatio</li> </ul> <h3 id="libraries-used">Libraries used:</h3> <ul> <li>pandas</li> <li>numpy</li> <li>matplotlib</li> <li>seaborn</li> <li>random</li> <li>sklearn</li> <li>xgboost</li> <li>wordcloud</li> </ul> <p>Load the Libraries used in the notebook</p><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pdf
import numpy as np
from numpy import loadtxt
from numpy import sort
import matplotlib.pyplot as plt
%matplotlib inline
from matplotlib.ticker import PercentFormatter
import matplotlib.ticker as mtick
from wordcloud import WordCloud, STOPWORDS 
from random import sample
import seaborn as sns
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn  ....
</code></pre></div></div><p><br /></p> <h4 id="import-dataset">Import Dataset</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/corporate_rating.csv'</span><span class="p">)</span>
</code></pre></div></div><h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2> <p>Our first step is to perform an exploratory data analysis to understand the charateristics of dataset. Here are some quesitons we will try to adress:</p> <ul> <li>What are the dimensions of the data?</li> <li>How do predictors relate to each other?</li> <li>What are the classes of the data?</li> <li>How are the predictors distributed?</li> <li>How are the labels distributed?</li> <li>Do we have missing values?</li> <li>Are outliers are relevant?</li> <li>Are there any transformations that must be done with the dataset?</li> </ul><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Display the dimensions
</span><span class="k">print</span><span class="p">(</span><span class="s">"The credit rating dataset has"</span><span class="p">,</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">"records, each with"</span><span class="p">,</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="s">"attributes"</span><span class="p">)</span>
</code></pre></div></div><p><samp> The credit rating dataset has 2029 records, each with 31 attributes </samp></p> <p>We will now use the function <code class="highlighter-rouge">.info()</code> to see the classes of columns and search missing values.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Display the structure
</span><span class="n">df_rating</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div><p><samp class="text-primary"> RangeIndex: 2029 entries, 0 to 2028<br /> Data columns (total 31 columns):<br /> Rating 2029 non-null object<br /> Name 2029 non-null object<br /> Symbol 2029 non-null object<br /> Rating Agency Name 2029 non-null object<br /> Date 2029 non-null object<br /> Sector 2029 non-null object<br /> currentRatio 2029 non-null float64<br /> quickRatio 2029 non-null float64<br /> cashRatio 2029 non-null float64<br /> daysOfSalesOutstanding 2029 non-null float64<br /> netProfitMargin 2029 non-null float64<br /> pretaxProfitMargin 2029 non-null float64<br /> grossProfitMargin 2029 non-null float64<br /> operatingProfitMargin 2029 non-null float64<br /> returnOnAssets 2029 non-null float64<br /> ... dtypes: float64(25), object(6)<br /> memory usage: 491.5+ KB<br /> </samp></p> <p><br /> We have 26 columns of numerical data and 6 descriptive columns (one of which is the label).There are no missing values. <br /> A first look at the data: <br /></p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div><div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Rating</th> <th>Name</th> <th>Symbol</th> <th>Rating Agency Name</th> <th>Date</th> <th>Sector</th> <th>currentRatio</th> <th>...</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>A</td> <td>Whirlpool Corporation</td> <td>WHR</td> <td>Egan-Jones Ratings Company</td> <td>11/27/2015</td> <td>Consumer Durables</td> <td>0.945894</td> <td>...</td> </tr> <tr> <td>1</td> <td>BBB</td> <td>Whirlpool Corporation</td> <td>WHR</td> <td>Egan-Jones Ratings Company</td> <td>2/13/2014</td> <td>Consumer Durables</td> <td>1.033559</td> <td>...</td> </tr> <tr> <td>2</td> <td>BBB</td> <td>Whirlpool Corporation</td> <td>WHR</td> <td>Fitch Ratings</td> <td>3/6/2015</td> <td>Consumer Durables</td> <td>0.963703</td> <td>...</td> </tr> <tr> <td>3</td> <td>BBB</td> <td>Whirlpool Corporation</td> <td>WHR</td> <td>Fitch Ratings</td> <td>6/15/2012</td> <td>Consumer Durables</td> <td>1.019851</td> <td>...</td> </tr> <tr> <td>4</td> <td>BBB</td> <td>Whirlpool Corporation</td> <td>WHR</td> <td>Standard &amp; Poor's Ratings Services</td> <td>10/24/2016</td> <td>Consumer Durables</td> <td>0.957844</td> <td>...</td> </tr> </tbody> </table> <p>5 rows × 31 columns</p></div><h3 id="analyse-labels">Analyse Labels</h3> <p>As we know we are working with ordinal labels. That means there is a scale from more secure to less secure ratings. For instance, the triple-A (AAA) is the most secure rating a company can receive. On the other hand, the rating D is the less secure. It means the company will likely default on its creditors. Let’s have a first look at the how many reatings we have of each in the dataset.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating</span><span class="p">.</span><span class="n">Rating</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div><p><samp class="text-primary"> BBB 671<br /> BB 490<br /> A 398<br /> B 302<br /> AA 89<br /> CCC 64<br /> AAA 7<br /> CC 5<br /> C 2<br /> D 1<br /> Name: Rating, dtype: int64<br /> </samp> <br /></p> <p>We observe that the dataset is very unbalanced. We have 671 triple-Bs (BBB) but only 1 D. However, we are working with Ratings from different companies such as <code class="highlighter-rouge">Moody's</code>, <code class="highlighter-rouge">Standard &amp; Poor's</code> and more. Therefore it is preferred to simplify the labels according to this table from the website <a href="https://www.investopedia.com/terms/c/corporate-credit-rating.asp">investopedia</a>. We will classify our labels according to the grading risk and not the rate.</p> <table> <thead> <tr> <th>Bond Rating</th> <th> </th> <th> </th> <th> </th> <th> </th> </tr> </thead> <tbody> <tr> <td>Moody’s</td> <td>Standard &amp; Poor’s</td> <td>Fitch</td> <td>Grade</td> <td>Risk</td> </tr> </tbody> <tbody> <tr> <td>Aaa</td> <td>AAA</td> <td>AAA</td> <td>Investment</td> <td>Lowest Risk</td> </tr> <tr> <td>Aa</td> <td>AA</td> <td>AA</td> <td>Investment</td> <td>Low Risk</td> </tr> <tr> <td>A</td> <td>A</td> <td>A</td> <td>Investment</td> <td>Low Risk</td> </tr> <tr> <td>Baa</td> <td>BBB</td> <td>BBB</td> <td>Investment</td> <td>Medium Risk</td> </tr> <tr> <td>Ba, B</td> <td>BB, B</td> <td>BB, B</td> <td>Junk</td> <td>High Risk</td> </tr> <tr> <td>Caa/Ca</td> <td>CCC/CC/C</td> <td>CCC/CC/C</td> <td>Junk</td> <td>Highest Risk</td> </tr> <tr> <td>C</td> <td>D</td> <td>D</td> <td>Junk</td> <td>In Default</td> </tr> </tbody> </table> <p>To do it we will replace with a dictonary each of this ratings.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rating_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s">'AAA'</span><span class="p">:</span><span class="s">'Lowest Risk'</span><span class="p">,</span> 
               <span class="s">'AA'</span><span class="p">:</span><span class="s">'Low Risk'</span><span class="p">,</span>
               <span class="s">'A'</span><span class="p">:</span><span class="s">'Low Risk'</span><span class="p">,</span>
               <span class="s">'BBB'</span><span class="p">:</span><span class="s">'Medium Risk'</span><span class="p">,</span> 
               <span class="s">'BB'</span><span class="p">:</span><span class="s">'High Risk'</span><span class="p">,</span>
               <span class="s">'B'</span><span class="p">:</span><span class="s">'High Risk'</span><span class="p">,</span>
               <span class="s">'CCC'</span><span class="p">:</span><span class="s">'Highest Risk'</span><span class="p">,</span> 
               <span class="s">'CC'</span><span class="p">:</span><span class="s">'Highest Risk'</span><span class="p">,</span>
               <span class="s">'C'</span><span class="p">:</span><span class="s">'Highest Risk'</span><span class="p">,</span>
               <span class="s">'D'</span><span class="p">:</span><span class="s">'In Default'</span><span class="p">}</span>

<span class="n">df_rating</span><span class="p">.</span><span class="n">Rating</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">Rating</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">rating_dict</span><span class="p">)</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ax</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span>
                                             <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span>
                                             <span class="n">title</span><span class="o">=</span><span class="s">"Count of Rating by Type"</span><span class="p">,</span>
                                             <span class="n">grid</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_17_0.png" alt="png" /></p> <p>Unfortunately, given the lack of Credit Ratings classified as <code class="highlighter-rouge">Lowest Risk</code> and <code class="highlighter-rouge">In Default</code> we will have to eliminate then from the table. However, the dataset will keep unbalanced and if needed we will have to adress this issue in further steps.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">[</span><span class="n">df_rating</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">]</span><span class="o">!=</span><span class="s">'Lowest Risk'</span><span class="p">]</span> <span class="c1"># filter Lowest Risk
</span><span class="n">df_rating</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">[</span><span class="n">df_rating</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">]</span><span class="o">!=</span><span class="s">'In Default'</span><span class="p">]</span>  <span class="c1"># filter In Default
</span><span class="n">df_rating</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># reset index
</span></code></pre></div></div><h3 id="descriptive-statistics">Descriptive Statistics</h3> <p>Now we will use statistical tools, especially from pandas to improve the understanding from the dataset, especially the numerical features. We have seen there are 25 numerical columns in the dataset, all of each are financial indicators from the companies. The function <code class="highlighter-rouge">describe()</code> returns information about the distribution of the data such as <code class="highlighter-rouge">quantiles</code>, <code class="highlighter-rouge">min</code> and <code class="highlighter-rouge">max</code>.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Statistical summary 
</span><span class="n">df_rating</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div><div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>currentRatio</th> <th>quickRatio</th> <th>cashRatio</th> <th>daysOfSalesOutstanding</th> <th>netProfitMargin</th> <th>...</th> </tr> </thead> <tbody> <tr> <td>count</td> <td>2021.000000</td> <td>2021.000000</td> <td>2021.000000</td> <td>2021.000000</td> <td>2021.000000</td> <td>...</td> <td>2021.000000</td> </tr> <tr> <td>mean</td> <td>3.535411</td> <td>2.657150</td> <td>0.669048</td> <td>334.855415</td> <td>0.278725</td> <td>...</td> </tr> <tr> <td>std</td> <td>44.139386</td> <td>33.009920</td> <td>3.590902</td> <td>4456.606352</td> <td>6.076128</td> <td>...</td> </tr> <tr> <td>min</td> <td>-0.932005</td> <td>-1.893266</td> <td>-0.192736</td> <td>-811.845623</td> <td>-101.845815</td> <td>...</td> </tr> <tr> <td>25%</td> <td>1.071930</td> <td>0.602298</td> <td>0.131433</td> <td>22.806507</td> <td>0.020894</td> <td>...</td> </tr> <tr> <td>50%</td> <td>1.492804</td> <td>0.979094</td> <td>0.297859</td> <td>42.281804</td> <td>0.064323</td> <td>...</td> </tr> <tr> <td>75%</td> <td>2.160710</td> <td>1.450457</td> <td>0.625355</td> <td>59.165369</td> <td>0.113871</td> <td>...</td> </tr> <tr> <td>max</td> <td>1725.505005</td> <td>1139.541703</td> <td>125.917417</td> <td>115961.637400</td> <td>198.517873</td> <td>...</td> </tr> </tbody> </table> <p>8 rows × 25 columns</p></div><h3 id="skewness-and-outliers">Skewness and Outliers</h3> <p>We observe a lot of skewness in the data with this first exploration. In this case, it means that most variables in the dataset may strong presence of outliers. Taking as observation the table above the first column:</p> <ul> <li><code class="highlighter-rouge">currentRatio</code>: This 50% of its variables between <code class="highlighter-rouge">1.071</code> and <code class="highlighter-rouge">2.166891</code>. The minimum value is <code class="highlighter-rouge">-0.932005</code> however the maximum value is <code class="highlighter-rouge">1725.505005</code>. It means, in other words, there is a giant outlier that is extremely distant from most points from the data (currentRatio).</li> </ul> <p>The same pattern can be observed in the following columns such as <code class="highlighter-rouge">quickRatio</code>, <code class="highlighter-rouge">cashRatio</code>, <code class="highlighter-rouge">daysOfSalesOutstanding</code>, <code class="highlighter-rouge">netProfitMargin</code> and so on.</p> <p>To observe how this reflect on the distribution of the data lets make some plots of variables chose randomly.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">column_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df_rating</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">31</span><span class="p">])</span>
<span class="n">column_list</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">column_list</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="n">column_list</span><span class="p">)</span>
</code></pre></div></div><p><samp class="text-primary"></samp></p><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['operatingCashFlowSalesRatio', 'grossProfitMargin', 'returnOnEquity', 'companyEquityMultiplier'] &lt;/samp&gt;
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">figure</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">].</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">].</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">].</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">].</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>

<span class="n">figure</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_24_0.png" alt="png" /></p> <p>As predicted, the data is comtaminated by outliers. We canot observe real behaviour of the distribution because some points differ too much from the others. We will use the function <code class="highlighter-rouge">.skew</code> from pandas in all columns. It should return between 0 and 1 if a column is normally distributed.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating</span><span class="p">.</span><span class="n">skew</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div><p><samp class="text-primary"> currentRatio 34.271115<br /> quickRatio 30.864610<br /> cashRatio 27.046952<br /> daysOfSalesOutstanding 20.359098<br /> netProfitMargin 17.585073<br /> pretaxProfitMargin 22.052558<br /> grossProfitMargin -14.198688<br /> operatingProfitMargin 26.441502<br /> returnOnAssets -32.049111<br /> returnOnCapitalEmployed -33.252701<br /> returnOnEquity 31.639845<br /> assetTurnover 25.968848<br /> fixedAssetTurnover 26.068762<br /> debtEquityRatio 0.268074<br /> debtRatio 1.284256<br /> effectiveTaxRate 32.265705<br /> freeCashFlowOperatingCashFlowRatio -22.868222<br /> freeCashFlowPerShare 33.610677<br /> cashPerShare 33.958646<br /> companyEquityMultiplier 0.268175<br /> ebitPerRevenue 22.055668<br /> enterpriseValueMultiple 13.920117<br /> operatingCashFlowPerShare 30.292914<br /> operatingCashFlowSalesRatio 25.400129<br /> payablesTurnover 25.868293<br /> dtype: float64<br /> </samp></p> <p><br /> <br /> We observe this is a generalized problem. As we can see almost all columns are extremely skewed. We will now go deeper in the investigation of outliers. The following code will return the proportion of outliers in each column . The definition of outlier will be the one from the boxplot - above or bellow <code class="highlighter-rouge">1.5 x IQR</code>.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">31</span><span class="p">]:</span>

    <span class="n">q1</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
    <span class="n">q3</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">iqr</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">-</span> <span class="n">q1</span> <span class="c1">#Interquartile range
</span>    <span class="n">fence_low</span>  <span class="o">=</span> <span class="n">q3</span><span class="o">-</span><span class="mf">1.5</span><span class="o">*</span><span class="n">iqr</span>
    <span class="n">fence_high</span> <span class="o">=</span> <span class="n">q1</span><span class="o">+</span><span class="mf">1.5</span><span class="o">*</span><span class="n">iqr</span>
    <span class="n">lower_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_rating</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">fence_low</span><span class="p">)</span>  <span class="p">,</span><span class="n">c</span><span class="p">])</span>
    <span class="n">upper_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_rating</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">fence_high</span><span class="p">)</span>  <span class="p">,</span><span class="n">c</span><span class="p">])</span>
    <span class="n">outlier_count</span> <span class="o">=</span> <span class="n">upper_out</span><span class="o">+</span><span class="n">lower_out</span>
    <span class="n">prop_out</span> <span class="o">=</span> <span class="n">outlier_count</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df_rating</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="s">": "</span><span class="o">+</span><span class="s">"{:.2%}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">prop_out</span><span class="p">))</span>

</code></pre></div></div><p><samp class="text-primary"> currentRatio : 18.01%<br /> quickRatio : 19.05%<br /> cashRatio : 14.84%<br /> daysOfSalesOutstanding : 23.55%<br /> netProfitMargin : 25.09%<br /> pretaxProfitMargin : 24.49%<br /> grossProfitMargin : 0.99%<br /> operatingProfitMargin : 22.12%<br /> returnOnAssets : 24.25%<br /> returnOnCapitalEmployed : 22.07%<br /> returnOnEquity : 28.70%<br /> assetTurnover : 15.83%<br /> fixedAssetTurnover : 13.46%<br /> debtEquityRatio : 22.07%<br /> debtRatio : 21.33%<br /> effectiveTaxRate : 28.06%<br /> freeCashFlowOperatingCashFlowRatio : 16.92%<br /> freeCashFlowPerShare : 23.55%<br /> cashPerShare : 17.12%<br /> companyEquityMultiplier : 22.02%<br /> ebitPerRevenue : 24.34%<br /> enterpriseValueMultiple : 23.70%<br /> operatingCashFlowPerShare : 17.66%<br /> operatingCashFlowSalesRatio : 16.87%<br /> payablesTurnover : 14.45%<br /></samp></p> <p>Most columns have a significant number of outliers. However it is not clear for us if there are a few rows that all outliers or each of the rows may be contributing individually with some outliers. We will now check by row the distribution of outliers. We will create a new dataframe that <code class="highlighter-rouge">df_rating_outlier</code> that will be used with this purpose. In this dataframe every cell will 1 one if the corresponding cell is an outlier in <code class="highlighter-rouge">df_raint</code> and 0 if it is not.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating_outlier</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df_rating_outlier</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">31</span><span class="p">]:</span>
    
    <span class="n">q1</span> <span class="o">=</span> <span class="n">df_rating_outlier</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
    <span class="n">q3</span> <span class="o">=</span> <span class="n">df_rating_outlier</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">iqr</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">-</span> <span class="n">q1</span> <span class="c1">#Interquartile range
</span>    <span class="n">fence_low</span>  <span class="o">=</span> <span class="n">q3</span><span class="o">-</span><span class="mf">1.5</span><span class="o">*</span><span class="n">iqr</span>
    <span class="n">fence_high</span> <span class="o">=</span> <span class="n">q1</span><span class="o">+</span><span class="mf">1.5</span><span class="o">*</span><span class="n">iqr</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_rating_outlier</span><span class="p">)):</span>
        
        <span class="k">if</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">fence_low</span> <span class="ow">or</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">fence_high</span><span class="p">:</span> <span class="c1"># if Outlier
</span>            
            <span class="n">df_rating_outlier</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Not Outlier
</span>            <span class="n">df_rating_outlier</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></div><p>Now we will be able to count how many outliers each row has and plot it.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating_outlier</span><span class="p">[</span><span class="s">"total"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_rating_outlier</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_rating_outlier</span><span class="p">.</span><span class="n">total</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_33_1.png" alt="png" /></p> <p>This is a very interesting plot. We can see that only up to 400 rows don’t have any outliers. Most rows have outliers and maybe they will be useful in the further classification tasks. Therefore we see no value in excluding the outliers from the dataset. However we will perform a transformation on the data so we can reduce its negative impact.</p> <h4 id="data-reshaping">Data reshaping</h4> <p>We will now perform the following steps in each of the numerical data.</p> <ol> <li>Normalize the data between 0 and 1 (and multiply by 1.000).</li> <li>Apply log on base 10 on each of the variables.</li> </ol><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">31</span><span class="p">]:</span>

    <span class="n">df_rating</span><span class="p">[[</span><span class="n">c</span><span class="p">]]</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[[</span><span class="n">c</span><span class="p">]].</span><span class="n">to_numpy</span><span class="p">())</span><span class="o">*</span><span class="mi">1000</span>
    <span class="n">df_rating</span><span class="p">[[</span><span class="n">c</span><span class="p">]]</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">log10</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mf">0.01</span><span class="p">))</span>
</code></pre></div></div><h3 id="again-the-plots">Again the plots</h3><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">figure</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">].</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">].</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">].</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">].</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df_rating</span><span class="p">[</span><span class="n">column_list</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>

<span class="n">figure</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_37_0.png" alt="png" /></p> <p>We have a problem with respect to vizualisation of the data. The impact of the outliers is so big that we cannot observe the patterns in the data. To enhance our visualization we will from now ignore outliers. We will replace then by values with lower impact such as the lower hinge. In this way we will be able to continue with our EDA. To preserve our dataset we will use a new table called <code class="highlighter-rouge">df_rating_no_out</code>.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating_no_out</span> <span class="o">=</span> <span class="n">df_rating</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">31</span><span class="p">]:</span>

    <span class="n">q05</span> <span class="o">=</span> <span class="n">df_rating_no_out</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.10</span><span class="p">)</span>
    <span class="n">q95</span> <span class="o">=</span> <span class="n">df_rating_no_out</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.90</span><span class="p">)</span>
    <span class="n">iqr</span> <span class="o">=</span> <span class="n">q95</span> <span class="o">-</span> <span class="n">q05</span> <span class="c1">#Interquartile range
</span>    <span class="n">fence_low</span>  <span class="o">=</span> <span class="n">q05</span><span class="o">-</span><span class="mf">1.5</span><span class="o">*</span><span class="n">iqr</span>
    <span class="n">fence_high</span> <span class="o">=</span> <span class="n">q95</span><span class="o">+</span><span class="mf">1.5</span><span class="o">*</span><span class="n">iqr</span>
    <span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_rating_no_out</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">fence_high</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_rating_no_out</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
    <span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_rating_no_out</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">fence_low</span><span class="p">,</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_rating_no_out</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
    
</code></pre></div></div><p>Now that we have this dataframe we can use it use it to observe the data from a different angle. We will be able to observe the distribution that was hidden by the outliers. The first step:</p> <ul> <li>Plot all columns (boxplot) by each label:<code class="highlighter-rouge">High Risk</code>, <code class="highlighter-rouge">Low Risk</code>, <code class="highlighter-rouge">Medium Risk</code>, <code class="highlighter-rouge">Highest Risk</code>.</li> </ul><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">figure</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">44</span><span class="p">))</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">30</span><span class="p">]:</span>
    
    <span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">Rating</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">df_rating_no_out</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="s">"Set3"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">j</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">i</span><span class="o">+=</span><span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">j</span><span class="o">+=</span><span class="mi">1</span>    

</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_41_0.png" alt="png" /></p> <p>The most interesting point about the previous plots is the fact that they clearly show a difference in the medians and distribution according to the rating (Risk). It points to a scenario where the variables will have good predictive power for classification. Following with our analysis we will create scatter plots to see if we can observe who the variables relate to each other and how labels can be observer in respect to it.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_rating</span><span class="p">.</span><span class="n">colors</span> <span class="o">=</span> <span class="s">'a'</span>
<span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_rating_no_out</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Lowest Risk'</span><span class="p">,</span> <span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'r'</span>
<span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_rating_no_out</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Low Risk'</span><span class="p">,</span> <span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'g'</span>
<span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_rating_no_out</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Medium Risk'</span><span class="p">,</span> <span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'b'</span>
<span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_rating_no_out</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'High Risk'</span><span class="p">,</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'y'</span>
<span class="n">df_rating_no_out</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_rating_no_out</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Highest Risk'</span><span class="p">,</span> <span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'m'</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">column_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df_rating</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">31</span><span class="p">])</span>
<span class="n">column_list</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">column_list</span><span class="p">,</span><span class="mi">12</span><span class="p">)</span> 
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">figure</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">14</span><span class="p">))</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>

    <span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">column_list</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">column_list</span><span class="p">[</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="s">"color"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_rating_no_out</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">j</span> <span class="o">+=</span><span class="mi">1</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="n">i</span><span class="o">+=</span><span class="mi">1</span>
</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_45_0.png" alt="png" /></p> <p>In fact, we are working with a dataset that has a big numer of dimensions. With two variables it would not be possible to make any predictions. However this is not the case. Unfortunately we are not able to vizualise the data in all its dimensions, but luckely we will be able to perform accurate classificaitons.</p> <h1 id="machine-learning">Machine Learning</h1> <p>Is it possible to predict what creidt profile a company will receive from a rating agency based on its financial indicators? If so, what are the most important predictors? Apparently not much work has been done with regards to this question. This academic <a href="https://www.researchgate.net/publication/331386740_Credit_Rating_Forecasting_Using_Machine_Learning_Techniques">paper</a> was the only work found about it. It is worth checking it out. As we will do it, it tests most ML algorithms and identifies the most important features.</p> <p>In the following steps we will perform the following:</p> <ol> <li>Prepare the dataset <ul> <li>Split in train and test</li> <li>Transform/Encode the features kand labels</li> </ul> </li> <li>Test a wide range of ML models (Tree-based, Probabilistic and so on).</li> <li>Compare the accuracry of all models.</li> <li>Choose our winning model and tune hyperparameters to target a higher accuracy.</li> <li>Make a more profound evaluation of the result with a confusion matrix and different measures.</li> <li>identify the most important features to predict the rating.</li> </ol> <h2 id="prepare-the-dataset">Prepare the Dataset</h2><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">le</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_rating</span><span class="p">.</span><span class="n">Sector</span><span class="p">)</span>
<span class="n">df_rating</span><span class="p">.</span><span class="n">Sector</span> <span class="o">=</span> <span class="n">le</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_rating</span><span class="p">.</span><span class="n">Sector</span><span class="p">)</span> <span class="c1"># encode sector
</span><span class="n">le</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_rating</span><span class="p">.</span><span class="n">Rating</span><span class="p">)</span>
<span class="n">df_rating</span><span class="p">.</span><span class="n">Rating</span> <span class="o">=</span> <span class="n">le</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_rating</span><span class="p">.</span><span class="n">Rating</span><span class="p">)</span> <span class="c1"># encode rating
</span></code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_rating</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1234</span><span class="p">)</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">5</span><span class="p">:</span><span class="mi">31</span><span class="p">],</span> <span class="n">df_train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">5</span><span class="p">:</span><span class="mi">31</span><span class="p">],</span> <span class="n">df_test</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div><h1 id="fit-models">Fit Models</h1> <p>Now we will test a range of models. In each we will fit the model in the train data, make predictons for the test data and obtain the accuracy. In later steps we will compare the accuracy of all the models. We will use primarily the library <code class="highlighter-rouge">sklearn</code> but also <code class="highlighter-rouge">XGBoost</code>.</p> <h4 id="xgboost">XGBoost</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">XGB_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">objective</span> <span class="o">=</span><span class="s">'multi:softmax'</span><span class="p">,</span> <span class="n">num_class</span> <span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">XGB_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_XGB</span> <span class="o">=</span> <span class="n">XGB_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_XGB</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_XGB</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"XGB Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_XGB</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">XGB Accuracy: 0.691358024691358</div><p><br /><br /></p> <h4 id="gradient-boosting-classifier">Gradient Boosting Classifier</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">GBT_model</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">GBT_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_GBT</span> <span class="o">=</span> <span class="n">GBT_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_GBT</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_GBT</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"GBT Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_GBT</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">GBT Accuracy: 0.6320987654320988</div><p><br /><br /></p> <h4 id="random-forest">Random Forest</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RF_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">RF_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_RF</span> <span class="o">=</span> <span class="n">RF_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_RF</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_RF</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"RF Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_RF</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">RF Accuracy: 0.6246913580246913</div><p><br /><br /></p> <h4 id="support-vector-machine">Support Vector Machine</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SVC_model</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">SVC_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_SVM</span> <span class="o">=</span> <span class="n">SVC_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_SVM</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_SVM</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"SVM Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_SVM</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">SVM Accuracy: 0.5333333333333333</div><p><br /><br /></p> <h4 id="neural-network">Neural Network</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MLP_model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'logistic'</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>
<span class="n">MLP_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_MLP</span> <span class="o">=</span> <span class="n">MLP_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_MLP</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_MLP</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"MLP Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_MLP</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">MLP Accuracy: 0.3654320987654321</div><p><br /><br /></p> <h4 id="naive-bayes">Naive Bayes</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">GNB_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">GNB_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_GNB</span> <span class="o">=</span> <span class="n">GNB_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_GNB</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_GNB</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"GNB Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_GNB</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">GNB Accuracy: 0.30864197530864196</div><p><br /><br /></p> <h4 id="linear-discriminant-analysis">Linear Discriminant Analysis</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LDA_model</span> <span class="o">=</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span>
<span class="n">LDA_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_LDA</span> <span class="o">=</span> <span class="n">LDA_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_LDA</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_LDA</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"LDA Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_LDA</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">LDA Accuracy: 0.38765432098765434</div><p><br /><br /></p> <h4 id="quadratic-discriminant-analysis">Quadratic Discriminant Analysis</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">QDA_model</span> <span class="o">=</span> <span class="n">QuadraticDiscriminantAnalysis</span><span class="p">()</span>
<span class="n">QDA_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_QDA</span> <span class="o">=</span> <span class="n">QDA_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_QDA</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_QDA</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"QDA Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_QDA</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">QDA Accuracy: 0.35555555555555557</div><p><br /><br /></p> <h4 id="k-nearest-neighbours">K Nearest Neighbours</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">KNN_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">KNN_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_KNN</span> <span class="o">=</span> <span class="n">KNN_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_KNN</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_KNN</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"KNN Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_KNN</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">KNN Accuracy: 0.5802469135802469</div><p><br /><br /></p> <h4 id="logistic-regression">Logistic Regression</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LR_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span> <span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s">'multinomial'</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s">'newton-cg'</span><span class="p">)</span>
<span class="n">LR_model</span> <span class="o">=</span> <span class="n">LR_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_LR</span> <span class="o">=</span> <span class="n">LR_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Accuracy_LR</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_LR</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"LR Accuracy:"</span><span class="p">,</span><span class="n">Accuracy_LR</span><span class="p">)</span>
</code></pre></div></div><div class="p-3 mb-2 bg-dark text-white">LR Accuracy: 0.3925925925925926</div><p><br /><br /></p> <h2 id="compare-results">Compare Results</h2><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">accuracy_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">Accuracy_XGB</span><span class="p">,</span> <span class="n">Accuracy_GBT</span><span class="p">,</span> <span class="n">Accuracy_RF</span><span class="p">,</span> <span class="n">Accuracy_SVM</span><span class="p">,</span> <span class="n">Accuracy_MLP</span><span class="p">,</span> <span class="n">Accuracy_GNB</span><span class="p">,</span> 
                 <span class="n">Accuracy_LDA</span><span class="p">,</span> <span class="n">Accuracy_QDA</span><span class="p">,</span> <span class="n">Accuracy_KNN</span><span class="p">,</span> <span class="n">Accuracy_LR</span><span class="p">]</span>

<span class="n">model_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">'XGBboost'</span><span class="p">,</span> <span class="s">'Gradient Boosting'</span><span class="p">,</span> <span class="s">'Random Forest'</span><span class="p">,</span> <span class="s">'Support Vector Machine'</span><span class="p">,</span> 
              <span class="s">"Neural Network"</span><span class="p">,</span> <span class="s">'Naive Bayes'</span><span class="p">,</span> <span class="s">'Linear Discriminat'</span><span class="p">,</span> <span class="s">'Quadratic Discriminat'</span><span class="p">,</span> 
              <span class="s">'KNN'</span><span class="p">,</span> <span class="s">'Logistic Regression'</span><span class="p">]</span>

<span class="n">df_accuracy</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'Model'</span><span class="p">:</span> <span class="n">model_list</span><span class="p">,</span> <span class="s">'Accuracy'</span><span class="p">:</span> <span class="n">accuracy_list</span><span class="p">})</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df_accuracy</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Accuracy'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">Model</span><span class="p">)</span>
<span class="n">df_accuracy</span> <span class="o">=</span> <span class="n">df_accuracy</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Accuracy'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">reset_index</span><span class="p">().</span><span class="n">drop</span><span class="p">([</span><span class="s">'index'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="c1"># make barplot and sort bars
</span><span class="n">x</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Model'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"Accuracy"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_accuracy</span><span class="p">,</span> <span class="n">order</span> <span class="o">=</span> <span class="n">order</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">"rocket"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Model"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Accuracy"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Accuracy by Model"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="n">linestyle</span><span class="o">=</span><span class="s">'-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="s">'0.5'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">().</span><span class="n">yaxis</span><span class="p">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">mtick</span><span class="p">.</span><span class="n">PercentFormatter</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_list</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">i</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">df_accuracy</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">'Accuracy'</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">((</span><span class="n">df_accuracy</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">'Accuracy'</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">+</span><span class="s">'%'</span><span class="p">,</span> 
             <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">,</span><span class="n">horizontalalignment</span><span class="o">=</span><span class="s">'center'</span><span class="p">)</span>

<span class="n">y_value</span><span class="o">=</span><span class="p">[</span><span class="s">'{:,.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="s">'%'</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ax</span><span class="p">.</span><span class="n">get_yticks</span><span class="p">()]</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">y_value</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_73_0.png" alt="png" /></p> <p>We have our winner. XGboost is the best performing model.</p> <h2 id="xgboost-hyperparameter-tunning">XGBoost Hyperparameter Tunning</h2> <p>The XGboost model has achieved a very high accuracy given that we have 4 different classes. Now we will try to increase the performance even more. We will use a cross-validation approach and we will follow similar steps to this <a href="https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f">tutorial</a>. First we load the train and test data into DMatrices. <code class="highlighter-rouge">DMatrix</code> is a data structure used by XGBoost to optimize both memory efficiency and training speed.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">dtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div><h4 id="the-params-dictionary">The params dictionary</h4> <p>We create a dictonary with the parameters from our previous XGboost model.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span> <span class="o">=</span> <span class="n">XGB_model</span><span class="p">.</span><span class="n">get_xgb_params</span><span class="p">()</span>
</code></pre></div></div><div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="p">{</span><span class="err">'objective':</span><span class="w"> </span><span class="err">'multi:softmax'</span><span class="p">,</span><span class="w">
     </span><span class="err">'base_score':</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w">
     </span><span class="err">'booster':</span><span class="w"> </span><span class="err">'gbtree'</span><span class="p">,</span><span class="w">
     </span><span class="err">'colsample_bylevel':</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
     </span><span class="err">'colsample_bynode':</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
     </span><span class="err">'colsample_bytree':</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
     </span><span class="err">'gamma':</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
     </span><span class="err">'gpu_id':</span><span class="w"> </span><span class="mi">-1</span><span class="p">,</span><span class="w">
     </span><span class="err">'interaction_constraints':</span><span class="w"> </span><span class="err">''</span><span class="p">,</span><span class="w">
     </span><span class="err">'learning_rate':</span><span class="w"> </span><span class="mf">0.300000012</span><span class="p">,</span><span class="w">
     </span><span class="err">'max_delta_step':</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
     </span><span class="err">'max_depth':</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w">
     </span><span class="err">'min_child_weight':</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
     </span><span class="err">'monotone_constraints':</span><span class="w"> </span><span class="err">'()'</span><span class="p">,</span><span class="w">
     </span><span class="err">'n_jobs':</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
     </span><span class="err">'num_parallel_tree':</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
     </span><span class="err">'random_state':</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
     </span><span class="err">'reg_alpha':</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
     </span><span class="err">'reg_lambda':</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
     </span><span class="err">'scale_pos_weight':</span><span class="w"> </span><span class="err">None</span><span class="p">,</span><span class="w">
     </span><span class="err">'subsample':</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
     </span><span class="err">'tree_method':</span><span class="w"> </span><span class="err">'exact'</span><span class="p">,</span><span class="w">
     </span><span class="err">'validate_parameters':</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
     </span><span class="err">'verbosity':</span><span class="w"> </span><span class="err">None</span><span class="p">,</span><span class="w">
     </span><span class="err">'num_class':</span><span class="w"> </span><span class="mi">4</span><span class="p">}</span><span class="w">
</span></code></pre></div></div><p>We will use the <code class="highlighter-rouge">merror</code> error parameter from classification. It is basic an accuracy.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span><span class="p">[</span><span class="s">'eval_metric'</span><span class="p">]</span> <span class="o">=</span> <span class="s">"merror"</span>
</code></pre></div></div><p>The num_boost_round which corresponds to the maximum number of boosting rounds that we allow.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">1000</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">dtrain</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="n">num_boost_round</span><span class="p">,</span>
    <span class="n">evals</span><span class="o">=</span><span class="p">[(</span><span class="n">dtest</span><span class="p">,</span> <span class="s">"Test"</span><span class="p">)],</span>
    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">verbose_eval</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Best merror: {:.2f} with {} rounds"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                 <span class="n">model</span><span class="p">.</span><span class="n">best_score</span><span class="p">,</span>
                 <span class="n">model</span><span class="p">.</span><span class="n">best_iteration</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0]	Test-merror:0.44691&lt;br&gt;
Will train until Test-merror hasn't improved in 50 rounds.&lt;br&gt;
[30]	Test-merror:0.34568&lt;br&gt;
[60]	Test-merror:0.32839&lt;br&gt;
[90]	Test-merror:0.30617&lt;br&gt;
[120]	Test-merror:0.30864&lt;br&gt;
[150]	Test-merror:0.30864&lt;br&gt;
Stopping. Best iteration:&lt;br&gt;
[104]	Test-merror:0.29877&lt;br&gt;

Best merror: 0.30 with 105 rounds
</code></pre></div></div><h4 id="using-xgboosts-cv">Using XGBoost’s CV</h4> <p>In order to tune the other hyperparameters, we will use the cv function from XGBoost. It allows us to run cross-validation on our training dataset and returns a mean merror score. We will use a <code class="highlighter-rouge">k = 5</code> for every parameter.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cv_results</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">cv</span><span class="p">(</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">dtrain</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="n">num_boost_round</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">nfold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s">'merror'</span><span class="p">},</span>
    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">verbose_eval</span><span class="o">=</span><span class="mi">30</span>
<span class="p">)</span>
<span class="n">cv_results</span><span class="p">.</span><span class="n">tail</span><span class="p">()</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0]	train-merror:0.24412+0.00946	test-merror:0.44677+0.01983
[30]	train-merror:0.00015+0.00031	test-merror:0.35580+0.04214
[60]	train-merror:0.00000+0.00000	test-merror:0.34466+0.03896
[90]	train-merror:0.00000+0.00000	test-merror:0.34775+0.04295
</code></pre></div></div><div> <style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } </style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>train-merror-mean</th> <th>train-merror-std</th> <th>test-merror-mean</th> <th>test-merror-std</th> </tr> </thead> <tbody> <tr> <td>55</td> <td>0.0</td> <td>0.0</td> <td>0.347756</td> <td>0.036916</td> </tr> <tr> <td>56</td> <td>0.0</td> <td>0.0</td> <td>0.345899</td> <td>0.036946</td> </tr> <tr> <td>57</td> <td>0.0</td> <td>0.0</td> <td>0.345284</td> <td>0.039353</td> </tr> <tr> <td>58</td> <td>0.0</td> <td>0.0</td> <td>0.343426</td> <td>0.038823</td> </tr> <tr> <td>59</td> <td>0.0</td> <td>0.0</td> <td>0.342811</td> <td>0.037624</td> </tr> </tbody> </table></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cv_results</span><span class="p">[</span><span class="s">'test-merror-mean'</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.34281059999999997
</code></pre></div></div><p>Now we are ready to start tuning. We will first tune our parameters to minimize the merror on cross-validation, and then check the performance of our model on the test dataset.</p> <h4 id="parameters-max_depth-and-min_child_weight">Parameters <code class="highlighter-rouge">max_depth</code> and <code class="highlighter-rouge">min_child_weight</code>.</h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gridsearch_params</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">max_depth</span><span class="p">,</span> <span class="n">min_child_weight</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">max_depth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">12</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">min_child_weight</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="p">]</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define initial best params and MAE
</span><span class="n">min_merror</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"Inf"</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="bp">None</span>
<span class="k">for</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">min_child_weight</span> <span class="ow">in</span> <span class="n">gridsearch_params</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"CV with max_depth={}, min_child_weight={}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                             <span class="n">max_depth</span><span class="p">,</span>
                             <span class="n">min_child_weight</span><span class="p">))</span>
    
    <span class="c1"># Update our parameters
</span>    <span class="n">params</span><span class="p">[</span><span class="s">'max_depth'</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_depth</span>
    <span class="n">params</span><span class="p">[</span><span class="s">'min_child_weight'</span><span class="p">]</span> <span class="o">=</span> <span class="n">min_child_weight</span>
    <span class="c1"># Run CV
</span>    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">cv</span><span class="p">(</span>
        <span class="n">params</span><span class="p">,</span>
        <span class="n">dtrain</span><span class="p">,</span>
        <span class="n">num_boost_round</span><span class="o">=</span><span class="n">num_boost_round</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">nfold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s">'merror'</span><span class="p">},</span>
        <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">verbose_eval</span><span class="o">=</span><span class="bp">False</span>

    <span class="p">)</span>
    <span class="c1"># Update best merror
</span>    <span class="n">mean_merror</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s">'test-merror-mean'</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span>
    <span class="n">boost_rounds</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s">'test-merror-mean'</span><span class="p">].</span><span class="n">argmin</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">MAE {} for {} rounds"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">mean_merror</span><span class="p">,</span> <span class="n">boost_rounds</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">mean_merror</span> <span class="o">&lt;</span> <span class="n">min_merror</span><span class="p">:</span>
        <span class="n">min_merror</span> <span class="o">=</span> <span class="n">mean_merror</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_depth</span><span class="p">,</span><span class="n">min_child_weight</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Best params: {}, {}, merror: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">best_params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">best_params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">min_merror</span><span class="p">))</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CV with max_depth=5, min_child_weight=5
	MAE 0.3533254 for 75 rounds
CV with max_depth=5, min_child_weight=6
	MAE 0.3533292 for 132 rounds
CV with max_depth=5, min_child_weight=7
	MAE 0.3588922 for 100 rounds
CV with max_depth=6, min_child_weight=5
	MAE 0.3496082 for 84 rounds
CV with max_depth=6, min_child_weight=6
	MAE 0.3508504 for 165 rounds
CV with max_depth=6, min_child_weight=7
	MAE 0.3545598 for 79 rounds
CV with max_depth=7, min_child_weight=5
	MAE 0.33784559999999997 for 82 rounds
CV with max_depth=7, min_child_weight=6
	MAE 0.3471276 for 220 rounds
CV with max_depth=7, min_child_weight=7
	MAE 0.3533136 for 45 rounds
CV with max_depth=8, min_child_weight=5
	MAE 0.3446568 for 70 rounds
CV with max_depth=8, min_child_weight=6
	MAE 0.3514716 for 45 rounds
CV with max_depth=8, min_child_weight=7
	MAE 0.35703860000000004 for 95 rounds
CV with max_depth=9, min_child_weight=5
	MAE 0.3409416 for 80 rounds
CV with max_depth=9, min_child_weight=6
	MAE 0.3384664 for 60 rounds
CV with max_depth=9, min_child_weight=7
	MAE 0.34961180000000003 for 60 rounds
CV with max_depth=10, min_child_weight=5
	MAE 0.3458856 for 46 rounds
CV with max_depth=10, min_child_weight=6
	MAE 0.3403222 for 135 rounds
CV with max_depth=10, min_child_weight=7
	MAE 0.34712400000000004 for 43 rounds
CV with max_depth=11, min_child_weight=5
	MAE 0.3390972 for 117 rounds
CV with max_depth=11, min_child_weight=6
	MAE 0.34837559999999995 for 81 rounds
CV with max_depth=11, min_child_weight=7
	MAE 0.34157399999999993 for 134 rounds
Best params: 7, 5, merror: 0.33784559999999997
</code></pre></div></div><p>We get the best score with a max_depth of 9 and min_child_weight of 6, so let’s</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span><span class="p">[</span><span class="s">'max_depth'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">params</span><span class="p">[</span><span class="s">'min_child_weight'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
</code></pre></div></div><h4 id="parameters-subsample-and-colsample_bytree">Parameters <code class="highlighter-rouge">subsample</code> and <code class="highlighter-rouge">colsample_bytree</code></h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gridsearch_params</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">subsample</span><span class="p">,</span> <span class="n">colsample</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">subsample</span> <span class="ow">in</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">11</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">colsample</span> <span class="ow">in</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="mf">10.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">11</span><span class="p">)]</span>
<span class="p">]</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define initial best params and MAE
</span><span class="n">min_merror</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"Inf"</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="bp">None</span>

<span class="k">for</span> <span class="n">subsample</span><span class="p">,</span> <span class="n">colsample</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">gridsearch_params</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"CV with subsample={}, colsample={}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                             <span class="n">subsample</span><span class="p">,</span>
                             <span class="n">colsample</span><span class="p">))</span>
    <span class="c1"># We update our parameters
</span>    <span class="n">params</span><span class="p">[</span><span class="s">'subsample'</span><span class="p">]</span> <span class="o">=</span> <span class="n">subsample</span>
    <span class="n">params</span><span class="p">[</span><span class="s">'colsample_bytree'</span><span class="p">]</span> <span class="o">=</span> <span class="n">colsample</span>
    
    <span class="c1"># Run CV
</span>    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">cv</span><span class="p">(</span>
        <span class="n">params</span><span class="p">,</span>
        <span class="n">dtrain</span><span class="p">,</span>
        <span class="n">num_boost_round</span><span class="o">=</span><span class="n">num_boost_round</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">nfold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s">'merror'</span><span class="p">},</span>
        <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">verbose_eval</span><span class="o">=</span><span class="bp">False</span>
    <span class="p">)</span>
    
    <span class="c1"># Update best MAE
</span>    <span class="n">mean_merror</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s">'test-merror-mean'</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span>
    <span class="n">boost_rounds</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s">'test-merror-mean'</span><span class="p">].</span><span class="n">argmin</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">MAE {} for {} rounds"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">mean_merror</span><span class="p">,</span> <span class="n">boost_rounds</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">mean_merror</span> <span class="o">&lt;</span> <span class="n">min_merror</span><span class="p">:</span>
        <span class="n">min_merror</span> <span class="o">=</span> <span class="n">mean_merror</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="p">(</span><span class="n">subsample</span><span class="p">,</span><span class="n">colsample</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Best params: {}, {}, merror: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">best_params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">best_params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">min_mae</span><span class="p">))</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CV with subsample=1.0, colsample=1.0
	MAE 0.34280299999999997 for 57 rounds
CV with subsample=1.0, colsample=0.9
	MAE 0.35086200000000006 for 47 rounds
CV with subsample=1.0, colsample=0.8
	MAE 0.335384 for 53 rounds
CV with subsample=1.0, colsample=0.7
	MAE 0.3477508 for 46 rounds
CV with subsample=0.9, colsample=1.0
	MAE 0.3489852 for 47 rounds
CV with subsample=0.9, colsample=0.9
	MAE 0.36075179999999996 for 32 rounds
CV with subsample=0.9, colsample=0.8
	MAE 0.35519259999999997 for 22 rounds
CV with subsample=0.9, colsample=0.7
	MAE 0.3316686 for 67 rounds
CV with subsample=0.8, colsample=1.0
	MAE 0.344668 for 22 rounds
CV with subsample=0.8, colsample=0.9
	MAE 0.344045 for 31 rounds
CV with subsample=0.8, colsample=0.8
	MAE 0.3490044 for 49 rounds
CV with subsample=0.8, colsample=0.7
	MAE 0.356431 for 41 rounds
CV with subsample=0.7, colsample=1.0
	MAE 0.34713720000000003 for 51 rounds
CV with subsample=0.7, colsample=0.9
	MAE 0.352079 for 66 rounds
CV with subsample=0.7, colsample=0.8
	MAE 0.34591779999999994 for 65 rounds
CV with subsample=0.7, colsample=0.7
	MAE 0.3521078 for 57 rounds
Best params: 0.9, 0.7, merror: 0.3316686
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span><span class="p">[</span><span class="s">'subsample'</span><span class="p">]</span> <span class="o">=</span><span class="mf">0.9</span>
<span class="n">params</span><span class="p">[</span><span class="s">'colsample_bytree'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.7</span>
</code></pre></div></div><h4 id="parameter-eta">Parameter <code class="highlighter-rouge">ETA</code></h4><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">time</span>
<span class="c1"># This can take some time…
</span><span class="n">min_merror</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"Inf"</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="bp">None</span>

<span class="k">for</span> <span class="n">eta</span> <span class="ow">in</span> <span class="p">[.</span><span class="mi">3</span><span class="p">,</span> <span class="p">.</span><span class="mi">2</span><span class="p">,</span> <span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="p">.</span><span class="mi">05</span><span class="p">,</span> <span class="p">.</span><span class="mi">01</span><span class="p">,</span> <span class="p">.</span><span class="mi">005</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"CV with eta={}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span>
    <span class="c1"># We update our parameters
</span>    <span class="n">params</span><span class="p">[</span><span class="s">'eta'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eta</span>
    <span class="c1"># Run and time CV
</span>    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">cv</span><span class="p">(</span>
            <span class="n">params</span><span class="p">,</span>
            <span class="n">dtrain</span><span class="p">,</span>
            <span class="n">num_boost_round</span><span class="o">=</span><span class="n">num_boost_round</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
            <span class="n">nfold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'merror'</span><span class="p">],</span>
            <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
    <span class="c1"># Update best score
</span>    <span class="n">mean_mae</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s">'test-merror-mean'</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span>
    <span class="n">boost_rounds</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s">'test-merror-mean'</span><span class="p">].</span><span class="n">argmin</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">MAE {} for {} rounds</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">mean_mae</span><span class="p">,</span> <span class="n">boost_rounds</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">mean_mae</span> <span class="o">&lt;</span> <span class="n">min_mae</span><span class="p">:</span>
        <span class="n">min_mae</span> <span class="o">=</span> <span class="n">mean_mae</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="n">eta</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Best params: {}, merror: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">best_params</span><span class="p">,</span> <span class="n">min_mae</span><span class="p">))</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Wall time: 0 ns
CV with eta=0.3
	MAE 0.3316686 for 67 rounds

CV with eta=0.2
	MAE 0.3316686 for 67 rounds

CV with eta=0.1
	MAE 0.3316686 for 67 rounds

CV with eta=0.05
	MAE 0.3316686 for 67 rounds

CV with eta=0.01
	MAE 0.3316686 for 67 rounds

CV with eta=0.005
	MAE 0.3316686 for 67 rounds

Best params: None, merror: 0.3316686
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span><span class="p">[</span><span class="s">'eta'</span><span class="p">]</span> <span class="o">=</span> <span class="p">.</span><span class="mi">3</span>
</code></pre></div></div><h4 id="results">Results</h4> <p>This are the final parameters of our tunned model.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'objective': 'multi:softmax',
 'base_score': 0.5,
 'booster': 'gbtree',
 'colsample_bylevel': 1,
 'colsample_bynode': 1,
 'colsample_bytree': 0.7,
 'gamma': 0,
 'gpu_id': -1,
 'interaction_constraints': '',
 'learning_rate': 0.300000012,
 'max_delta_step': 0,
 'max_depth': 7,
 'min_child_weight': 5,
 'monotone_constraints': '()',
 'n_jobs': 0,
 'num_parallel_tree': 1,
 'random_state': 0,
 'reg_alpha': 0,
 'reg_lambda': 1,
 'scale_pos_weight': None,
 'subsample': 0.9,
 'tree_method': 'exact',
 'validate_parameters': 1,
 'verbosity': None,
 'num_class': 4,
 'eval_metric': 'merror',
 'eta': 0.3}
</code></pre></div></div><p>Let’s train a model with it and see how well it does on our test set!</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">dtrain</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="n">num_boost_round</span><span class="p">,</span>
    <span class="n">evals</span><span class="o">=</span><span class="p">[(</span><span class="n">dtest</span><span class="p">,</span> <span class="s">"Test"</span><span class="p">)],</span>
    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">verbose_eval</span><span class="o">=</span><span class="mi">100</span>
<span class="p">)</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0]	Test-merror:0.45679
Will train until Test-merror hasn't improved in 1000 rounds.
[100]	Test-merror:0.34321
[200]	Test-merror:0.33827
[300]	Test-merror:0.34321
[400]	Test-merror:0.34321
[500]	Test-merror:0.34815
[600]	Test-merror:0.35062
[700]	Test-merror:0.34815
[800]	Test-merror:0.34815
[900]	Test-merror:0.35062
[999]	Test-merror:0.35556
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_boost_round</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">best_iteration</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">dtrain</span><span class="p">,</span>
    <span class="n">verbose_eval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">num_boost_round</span><span class="o">=</span><span class="n">num_boost_round</span><span class="p">,</span>
    <span class="n">evals</span><span class="o">=</span><span class="p">[(</span><span class="n">dtest</span><span class="p">,</span> <span class="s">"Test"</span><span class="p">)]</span>
<span class="p">)</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0]	Test-merror:0.45679
[100]	Test-merror:0.34321
[200]	Test-merror:0.33827
[278]	Test-merror:0.32593
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.674074074074074
</code></pre></div></div><p>We did not arrive in an enhanced model with this tunning. Anyone is welcome to continue this tunning and achieve a superior accuracy.</p> <h2 id="confusion-matrix">Confusion Matrix</h2> <p>We will now analyse according to each class the performance of the model. The best way to do it is with a confusion matrix. We can see how many points were missclassified and where were then classified to if not the right rating.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_XGB</span><span class="p">)</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">"d"</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">linecolor</span> <span class="o">=</span> <span class="s">'white'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"Reds"</span><span class="p">)</span> <span class="c1"># annot=True to annotate cells
</span>
<span class="c1"># labels, title and ticks
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Predicted labels'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'True labels'</span><span class="p">);</span> 
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Confusion Matrix'</span><span class="p">);</span> 
<span class="n">ax</span><span class="p">.</span><span class="n">xaxis</span><span class="p">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s">'Medium Risk'</span><span class="p">,</span><span class="s">'Highest Risk'</span><span class="p">,</span> <span class="s">'Low Risk'</span><span class="p">,</span> <span class="s">'High Risk'</span><span class="p">])</span>
<span class="n">ax</span><span class="p">.</span><span class="n">yaxis</span><span class="p">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s">'Medium Risk'</span><span class="p">,</span><span class="s">'Highest Risk'</span><span class="p">,</span> <span class="s">'Low Risk'</span><span class="p">,</span> <span class="s">'High Risk'</span><span class="p">]);</span>

<span class="c1"># This part is to correct a bug from the heatmap funciton from pyplot
</span><span class="n">b</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">()</span> <span class="c1"># discover the values for bottom and top
</span><span class="n">b</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="c1"># Add 0.5 to the bottom
</span><span class="n">t</span> <span class="o">-=</span> <span class="mf">0.5</span> <span class="c1"># Subtract 0.5 from the top
</span><span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="c1"># update the ylim(bottom, top) values
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_108_0.png" alt="png" /></p> <h4 id="analysis">Analysis</h4> <p>Given the fact that the dataset is very unbalanced, with have achieved a very low accuracy (actually 0) for very risky companies. To deal with it we wiould have to apply upsampling techniques which we may in a future work. Now we analyse other metrics as Precision, recall and F1 from our targets.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_XGB</span><span class="p">,</span> <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Medium Risk'</span><span class="p">,</span><span class="s">'Highest Risk'</span><span class="p">,</span> <span class="s">'Low Risk'</span><span class="p">,</span> <span class="s">'High Risk'</span><span class="p">]))</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

 Medium Risk       0.72      0.83      0.77       148
Highest Risk       0.00      0.00      0.00         8
    Low Risk       0.73      0.67      0.70       107
   High Risk       0.64      0.60      0.62       142

    accuracy                           0.69       405
   macro avg       0.52      0.53      0.52       405
weighted avg       0.68      0.69      0.68       405
</code></pre></div></div><p>Apparetly the fact that we have more labels in the edium Risk has enhanced its classification. However, overall we have achieved good classification scaores for most, with the exception of Highest Risk.</p> <h2 id="feature-selection">Feature Selection</h2> <p>In our tast task we will identify which features were the most valuable for our model. In our first step we will check if by any chance we can increase the accuracy of our model extracting a feature.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">thresholds</span> <span class="o">=</span> <span class="n">sort</span><span class="p">(</span><span class="n">XGB_model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span>
<span class="k">for</span> <span class="n">thresh</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
    <span class="c1"># select features using threshold
</span>    <span class="n">selection</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">XGB_model</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">thresh</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">select_X_train</span> <span class="o">=</span> <span class="n">selection</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="c1"># train model
</span>    <span class="n">selection_model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
    <span class="n">selection_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">select_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="c1"># eval model
</span>    <span class="n">select_X_test</span> <span class="o">=</span> <span class="n">selection</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">selection_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">select_X_test</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">y_pred</span><span class="p">]</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Thresh=%.3f, n=%d, Accuracy: %.2f%%"</span> <span class="o">%</span> <span class="p">(</span><span class="n">thresh</span><span class="p">,</span> <span class="n">select_X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">accuracy</span><span class="o">*</span><span class="mf">100.0</span><span class="p">))</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Thresh=0.025, n=26, Accuracy: 69.14%
Thresh=0.026, n=25, Accuracy: 67.16%
Thresh=0.026, n=24, Accuracy: 67.16%
Thresh=0.027, n=23, Accuracy: 64.69%
Thresh=0.027, n=22, Accuracy: 64.44%
Thresh=0.027, n=21, Accuracy: 65.93%
Thresh=0.028, n=20, Accuracy: 64.44%
...
</code></pre></div></div><p><br /> It is not the case. Now lets visualize which are the most relevant features.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">plot_importance</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="c1"># xgboost.plot_importance(..., ax=ax)
</span>
<span class="n">plot_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_114_0.png" alt="png" /></p> <h1 id="visualize-companies">Visualize Companies</h1> <p><strong>Bonus</strong>: In this dataset we are working exclusevely with companies that are traded in the stock exchanges from the US. Now, we will visualize which companies are considered secure to lend money according to agencies. We will make 4 different wordclouds, one for each rating of risk.</p> <p>#### Create a function to generate text for the word cloud</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">WCloud</span><span class="p">(</span><span class="n">dataframe</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">rating</span><span class="p">):</span>
    
    <span class="n">words</span> <span class="o">=</span> <span class="s">''</span>
    
    <span class="c1"># iterate through the csv file 
</span>    <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">dataframe</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">dataframe</span><span class="p">[</span><span class="s">'Rating'</span><span class="p">]</span> <span class="o">==</span> <span class="n">rating</span><span class="p">,</span> <span class="n">column</span><span class="p">]:</span>
      
        <span class="c1"># typecaste each val to string 
</span>        <span class="n">val</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"."</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">val</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">","</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>

        <span class="c1"># split the value 
</span>        <span class="n">tokens</span> <span class="o">=</span> <span class="n">val</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>

        <span class="c1">#Converts each token into lowercase 
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)):</span> 
            <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">lower</span><span class="p">()</span> 

        <span class="n">words</span> <span class="o">+=</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">+</span> <span class="s">" "</span>
        
    <span class="k">return</span> <span class="n">words</span>
</code></pre></div></div><p><img src="/assets/images/corporateCreditRatingPrediction-Copy1_124_1.png" alt="png" /></p> <p>You may observe that some companies may be in different plots. Thats because they have been rated in different times with different rates.</p> </article></div><hr class="dashed" /><div class="container"><div class="row" data-aos="fade-up"><div class="col-md-12"><div class="share-box"> <i class="fa fa-share-alt" aria-hidden="true"></i> <a class="f nostyle" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/blog/corporateCreditRatingPrediction/" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-facebook-official fa"></i ></a> <a class="t nostyle" href="https://twitter.com/intent/tweet?text=&url=http://localhost:4000/blog/corporateCreditRatingPrediction/" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-twitter fa"></i ></a> <a class="g nostyle" href="https://plus.google.com/share?url=http://localhost:4000/blog/corporateCreditRatingPrediction/" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-google-plus fa"></i ></a> <a class="r nostyle" href="http://www.reddit.com/submit?url=http://localhost:4000/blog/corporateCreditRatingPrediction/" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-reddit fa"></i ></a> <a class="l nostyle" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/blog/corporateCreditRatingPrediction/&title=&summary=&source=webjeda" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-linkedin fa"></i ></a> <a class="e nostyle" href="mailto:?subject=&amp;body=Check&amp;out&amp;this&amp;site&amp;http://localhost:4000/blog/corporateCreditRatingPrediction/" ><i class="fa fa-envelope fa"></i ></a></div></div></div><div class="row"><div class="col-md-12"> <p class="categories" data-aos="fade-up"> <span><a href="/categories/#data-science">Data science</a></span> <span><a href="/categories/#finance">Finance</a></span> <span><a href="/categories/#machine-learning">Machine learning</a></span> <span><a href="/categories/#deep-learning">Deep learning</a></span> </p></div></div><div id="disqus_thread" data-aos="fade-up"></div><script defer> (function() { var d = document, s = d.createElement("script"); s.src = "//webjeda-demo.disqus.com/embed.js"; s.setAttribute("data-timestamp", +new Date()); (d.head || d.body).appendChild(s); })();</script><noscript>Please enable JavaScript to view the comments</noscript><div class="recent" data-aos="fade-up"><div class=""> <h3>Recent Articles</h3></div><div class="recent-grid"><div class="items" data-aos="fade-up"> <a class="nostyle item" href="/blog/Bootstrap-to-Quantify-Uncertainty/"><div class="cards"><div class="image" style="background-image: url(/assets/images/bootstrap_inf.png)" ></div><p class="title"><small>Bootstrap to Quantify Uncertainty</small></p></div></a></div><div class="items" data-aos="fade-up"> <a class="nostyle item" href="/blog/dog/"><div class="cards"><div class="image" style="background-image: url(/assets/images/anthony-tori-102062.jpg)" ></div><p class="title"><small>An Algorithm for a Dog Identification App</small></p></div></a></div><div class="items" data-aos="fade-up"> <a class="nostyle item" href="/blog/blackcurrant/"><div class="cards"><div class="image" style="background-image: url(/assets/images/blackcurrant.jpg)" ></div><p class="title"><small>Blackcurrant Jekyll Theme</small></p></div></a></div><div class="items" data-aos="fade-up"> <a class="nostyle item" href="/blog/EM-Clustering/"><div class="cards"><div class="image" style="background-image: url(/assets/images/cluster.png)" ></div><p class="title"><small>Expectation Maximization for News Clustering</small></p></div></a></div></div></div></div></main><footer data-aos="fade-up"><div class="text-right"> <p class="copy"> <i class="fa fa-at"></i> 2018 <a class="rev" href="http://localhost:4000">Blackcurrant</a> </p></div></footer></div></div></div></div><!DOCTYPE html><html><head><meta name="viewport" content="width=device-width, initial-scale=1"> <style> .sidenav { width: 230px; position: fixed; z-index: 1; top: 100px; left: 30px; overflow-x: hidden; padding: 8px 0; } .sidenav a { padding: 6px 8px 6px 16px; text-decoration: none; color: #444; font-size: 22px; display: block; } .sidenav a:hover { color: #064579; } .top-bar { background-color: #222222; } </style></head><body><div class="sidenav"> <a href="#home"><i class="fa fa-fw fa-home"></i> Home</a> <a href="#Projects"><i class="fa fa-area-chart"></i> Projects</a></div><script src="/assets/js/jQuery.min.js"></script><script> $(document).ready(function () { $(".loader").hide(); });</script><script> (function () { var css = document.createElement('link'); css.href = '/assets/font-awesome-4.7.0/css/font-awesome.min.css'; css.rel = 'stylesheet'; css.type = 'text/css'; document.getElementsByTagName('head')[0].appendChild(css); })();</script><noscript><link rel="stylesheet" href="/assets/font-awesome-4.7.0/css/font-awesome.min.css"> </noscript><script> $("#search-input").keyup(function () { $("main").hide(); $("search-container").show(); if (!$('#search-input').val()) { $("main").show(); $("search-container").hide(); } });</script><script src="/assets/js/jekyll-search.min.js" type="text/javascript"></script><script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-container'), searchResultTemplate: '<a class="nostyle" href="{url}"><div class="blog borders cards"><div class="image" style="background-image: url({image});"></div><div class="content"><h3 class="title">{title}</h3><p class="description">{description}</p></div></div></a>', noResultsText: 'No results found', json: '/search.json' })</script><script> (function () { var css = document.createElement('link'); css.href = 'https://unpkg.com/aos@2.3.1/dist/aos.css'; css.rel = 'stylesheet'; css.type = 'text/css'; document.getElementsByTagName('head')[0].appendChild(css); })();</script><noscript><link rel="stylesheet" href="/assets/animate-on-scroll/aos.min.css"> </noscript><script src="/assets/animate-on-scroll/aos.min.js"></script><script> AOS.init({ duration: 600, once: true, disable: 'mobile' });</script></body></html>