<!-- This layout is used in all pages. Making changes here will efect all pages. We recommend not to change anything here. --> <!DOCTYPE html><html lang="en"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" /><link rel="dns-prefetch" href="//fonts.googleapis.com" /><link rel="dns-prefetch" href="//google-analytics.com" /><link rel="dns-prefetch" href="//www.google-analytics.com" /><link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com" /><link rel="dns-prefetch" href="//ajax.googleapis.com" /><link rel="dns-prefetch" href="//fonts.gstatic.com" /><link rel="dns-prefetch" href="https://webjeda-demo.disqus.com/" /><title>Recommender system using Pyspark (ALS algorithm) | Welcome to my Website</title><meta name="generator" content="Jekyll v3.8.4" /><meta property="og:title" content="Recommender system using Pyspark (ALS algorithm)" /><meta name="author" content="Alan Gewerc" /><meta property="og:locale" content="en_US" /><meta name="description" content="Introduction Recommender Systems are algorithms designed to make suggestions of items to users of a certain platform based on their previous patterns. They are used in the tech industry by companies such as Netflix, YouTube, Facebook, Amazon, Expedia, Spotify and so on. More recently, recommender systems have become more diffuse and are not limited to big tech companies, but virtually every company can create its own system (with the right dataset). The benefits of using such systems are enormous, as described here, here and here. In a nutshell, it can drive traffic, deliver personalised content, enhance customer engagement, increase sales and much more. The architecture of the recommendation engine is dependent on the business domain and the attributes of the dataset at one’s disposal. For instance, customers on eBay frequently provide ratings for products scaling on 1 (unhappy) to 5 (very happy). Spotify holds information about the gender of music one listens to. Uber eats should know what your favourite type of food is. Instagram has user patterns of likes in images. Such data sources document interactions between users and products (items). In addition, the platform may access personal information from users, such as their location, age, sex and so on. Not to mention the complete metadata of their items. There are three especially common methods to design a recommender system: Collaborative Filtering, Content-based Filtering and hybrid techniques. Content-based systems aim to make recommendations based on some previous information about the customer and the products. For instance, if Netflix knows you like drama movies, it might recommend you movies of this gender. However, in a collaborative filtering approach, it might simply ignore the gender of the film. The features used in this case are exclusively users rating patterns. For instance, if you watched five different series on Netflix and have rated five each of them, just like some other random user, then you might be interested to know what else he has rated as five stars. Hybrid systems make use of both techniques. In this project, we will use of Alternating Least Square Matrix Factorization, a Collaborative Filtering algorithm. We will build a recommender system for restaurants in the city of Toronto. Requirements: Python Apache Spark Import Libraries and Initialize spark session !pip install pyspark #import libraries from pyspark import SparkContext from pyspark.ml.recommendation import ALS from pyspark.sql import SparkSession ,Row from pyspark.sql.functions import col from pyspark.sql import SQLContext from pyspark.ml.feature import StringIndexer from pyspark.ml import Pipeline from pyspark.ml.evaluation import RegressionEvaluator from pyspark.sql.types import StructType,StructField,IntegerType import matplotlib.pyplot as plt %matplotlib inline appName=&quot;Collaborative Filtering with PySpark&quot; #initialize the spark session spark = SparkSession.builder.appName(appName).getOrCreate() #get sparkcontext from the sparksession sc = spark.sparkContext sqlContext = SQLContext(sc) Load Dataset in Apache Spark Dataset We will be working with yelp dataset. It contains millions of reviews of businesses across the world. We will limit ourselves to the restaurants in the city of Toronto, Canada. The relevant files for us are the following: yelp_academic_dataset_business.json:Contains information about every review made every customer for every business (millions of reviews). yelp_academic_dataset_review.json: Contains multiple characteristics from businesses such as parking available, type of food, etc. Spark SQL Since we are working with json files we use the function read.json. It takes a json file and transform it to a dataframe. We use sqlContextfrom the module Spark SQL. Spark SQL is a Spark module for structured data processing. It allows use to perform SQL queries in dataframes such as join, groupby, select and so on. df_business = sqlContext.read.json(&#39;../input/yelp-dataset/yelp_academic_dataset_business.json&#39;) df_review = sqlContext.read.json(&#39;/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json&#39;) Filter Rows and columns Our dataset contains many columns, and most of them won’t be used in this project. From the table df_business, we want only the essential features of businesses such as the id, name, stars, category and so on. We are exclusively interested in companies that are restaurants and in the city of Toronto. Therefore we apply the function filter in the columns city and category to enforce this restriction. From the table df_review, we want only the reviews from the selected table above. We use an inner join of df_review and df_business to eliminate all other businesses from the table reviews. df_business = df_business.select(&quot;business_id&quot;,&quot;name&quot;, &quot;stars&quot;, &quot;review_count&quot;, &quot;attributes&quot;, &quot;categories&quot;, &quot;city&quot;).withColumnRenamed(&quot;stars&quot;, &quot;stars_restaurant&quot;) df_business = df_business.filter((df_business[&#39;city&#39;] == &#39;Toronto&#39;) &amp; (df_business.categories.contains(&#39;Restaurants&#39;))).drop(&#39;city&#39;) df_review = df_review.join(df_business, on=&#39;business_id&#39;, how=&#39;inner&#39;) Lets make a quick visualisation to the basic elements of our review table. df_review.select([&#39;business_id&#39;, &#39;user_id&#39;, &#39;stars&#39;]).show() +--------------------+--------------------+-----+ | business_id| user_id|stars| +--------------------+--------------------+-----+ |qUWqjjjfpB2-4P3He...|TZQSUDDcA4ek5gBd6...| 4.0| |9Eghhu_LzEJgDKNgi...|iFEM16O5BeKvf_AHs...| 3.0| |cDoo0Pf1d_P79Rq3Z...|1kNsEAhGU8d8xugMu...| 3.0| |4m_hApwQ054v3ue_O...|Eg_VTAQwK3CxYTORN...| 5.0| |jM6JjZXFAQQANwdlE...|IIE2OX5haarGNefY2...| 5.0| |PMPMHHLe9vFzcR67i...|RRhco4irDXPk5EJmv...| 5.0| |IfUkm42SB9D0m_Zbk...|Kl6jNDAE7PG_VVQaf...| 4.0| |NrJSy3dgcXErFtOKG...|is1nHZ4oBqqmBm_mf...| 4.0| |nY2oBwH3s5sKox1mE...|JnPIjvC0cmooNDfsa...| 5.0| |tWdp26XQEJqJGnRmF...|IeojscL3rg3x3vtmR...| 4.0| |tJcpzXzykNSLuzWwa...|6WmMHMBM4FLGyK98-...| 1.0| |PjtX-5vSTBVyWfMRE...|pMefTWo6gMdx8WhYS...| 4.0| |28adZ4lsuUeVB2aWz...|BwwqlPVsJk1dbUyNw...| 5.0| |tvYID0arhN-shKGUr...|kmOvnwtroMBC8y9lO...| 1.0| |sSdHUsUZ4mvkb5ymI...|0aHFybE0id9DD97Qz...| 4.0| |n-5dPbGyziS0SOkVD...|Fw8Lj7q7DqTh-m3hG...| 4.0| |0a1BBSewiusfCalA9...|hYnq9-wO-RzmiTTGM...| 4.0| |uG0yvj2JWfCf0eaIg...|yiLiYYg6MM7Pmuo6j...| 5.0| |4POPYEONJpkfhWOMx...|vxf427mKFMUxpfbHC...| 2.0| |w7DEm_2Gj_xF0qeRd...|BOmBm4j0r2JPqi6V6...| 4.0| +--------------------+--------------------+-----+ only showing top 20 rows Exploratory Data Analysis Let’s have a quick visualisation of the data. We plot a histogram of the ratings from users. However, to make visualisations we have to convert the data from dataframe (pyspark) to pandas. First we use the .collect() and later we extract the the values. reviews = df_review.select(&#39;stars&#39;).collect() review_list = [reviews[i][0] for i in range(len(reviews))] plt.hist(review_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5, histtype=&#39;stepfilled&#39;, color=&#39;steelblue&#39;, edgecolor=&#39;none&#39;) plt.ylabel(&#39;Frequency&#39;) plt.xlabel(&#39;Rating&#39;) plt.style.use(&#39;seaborn-white&#39;) Quite generous public from Toronto. Most ratings are above 3. Now let’s see the distribution of ratings of each restaurant. restaurant_reviews = df_business.select(&#39;stars_restaurant&#39;).collect() restaurant_reviews_list = [restaurant_reviews[i][0] for i in range(len(restaurant_reviews))] plt.hist(restaurant_reviews_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5, histtype=&#39;stepfilled&#39;, color=&#39;steelblue&#39;, edgecolor=&#39;none&#39;) plt.ylabel(&#39;Frequency&#39;) plt.xlabel(&#39;Rating&#39;) plt.style.use(&#39;seaborn-white&#39;) Here were see a more normally distributed curve. Aditionally we can see that most restaurants do pretty well in terms of average rating. Now let’s visualise what the most popular type of restaurants in Toronto are. What kind of food do they serve? We will create a word cloud. restaurant_categories = df_business.select(&#39;categories&#39;).collect() restaurant_categories_list = [restaurant_categories[i][0] for i in range(len(restaurant_categories))] text = &quot; &quot;.join(review for review in restaurant_categories_list) from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # eliminate useless words text = text.replace(&#39;Restaurants&#39;, &quot;&quot;) text = text.replace(&#39;bars&#39;, &quot;&quot;) text = text.replace(&#39;food&#39;, &quot;&quot;) # Generate a word cloud image wordcloud = WordCloud(background_color=&quot;white&quot;).generate(text) # Display the generated image: # the matplotlib way: plt.figure(figsize=(10,8)) plt.imshow(wordcloud, interpolation=&#39;bilinear&#39;) plt.axis(&quot;off&quot;) plt.show() Convert String to index Before starting the modelling process, we must convert all columns that will be used in the model to integer. This is compulsory for the ALS model from PySpark. The columns that need to be converted are the business_id and user_id. We use the StringIndexer function imported in from pyspark.ml.feature. indexer = [StringIndexer(inputCol=column, outputCol=column+&quot;_index&quot;) for column in [&#39;business_id&#39;, &#39;user_id&#39;]] pipeline = Pipeline(stages=indexer) transformed = pipeline.fit(df_review).transform(df_review) transformed.select([&#39;business_id&#39;, &#39;user_id&#39;,&#39;business_id_index&#39;, &#39;user_id_index&#39;]) Split Dataset in train and test (training, test) = transformed.randomSplit([0.8, 0.2]) Create ALS model Alternating Least Square is a matrix factorisation algorithm implemented in Apache Spark ML and built for large-scale collaborative filtering problems. Matrix factorization (or decomposition) The basic idea is to decompose a matrix in smaller parts in the same way we can do for a number. For instance, we can say that the number four can be decomposed in two times two (4 = 2 x 2). In the same way, we can do a decomposition of a matrix. Here is an example of how can we decompose a matrix that has ratings for restaurants by clients: If we are able to find the hidden matrices, we will be able to calculate the expected rating that every client will give to each restaurant. This is our goal with the algorithm. But how to find the hidden matrices? The math in this process is extensive and is not our goal to discuss it in here. You can read it about in here. It is very a very similar process to the stochastic gradient descent. Parameters (as described on Spark website) - numBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10). - rank is the number of latent factors in the model (defaults to 10). - maxIter is the maximum number of iterations to run (defaults to 10). - regParam specifies the regularization parameter in ALS (defaults to 1.0). - implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback). - alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0). - nonnegative specifies whether or not to use nonnegative constraints for least squares (defaults to false). als=ALS(maxIter=5, regParam=0.09, rank=25, userCol=&quot;user_id_index&quot;, itemCol=&quot;business_id_index&quot;, ratingCol=&quot;stars&quot;, coldStartStrategy=&quot;drop&quot;, nonnegative=True) model=als.fit(training) Evaluate RMSE evaluator=RegressionEvaluator(metricName=&quot;rmse&quot;,labelCol=&quot;stars&quot;,predictionCol=&quot;prediction&quot;) predictions=model.transform(test) rmse=evaluator.evaluate(predictions) print(&quot;RMSE=&quot;+str(rmse)) RMSE=1.3651734482322269 Our model is doing pretty well. We have achieved a 1.36 average squared error. Lets see an applied case of a recommendation for a customer. In future works we can include a step of parameter tunning as in here. Visualize Recommendations Now we visualise recommendations for user 30 (could be any other). test = model.recommendForAllUsers(20).filter(col(&#39;user_id_index&#39;)==30).select(&quot;recommendations&quot;).collect() topRestaurants = [] for item in test[0][0]: topRestaurants.append(item.business_id_index) schema = StructType([StructField(&quot;business_id_index&quot;,IntegerType(),True)]) restaurants = spark.createDataFrame(topRestaurants,IntegerType()).toDF(&quot;business_id_index&quot;) transformed\ .select([&#39;business_id&#39;, &#39;user_id&#39;, &#39;stars&#39;, &#39;categories&#39;])\ .filter(col(&#39;user_id_index&#39;)==30)\ .show() restaurants\ .join(transformed, on = &#39;business_id_index&#39;, how = &#39;inner&#39;)\ .select([&#39;business_id&#39;, &#39;stars&#39;, &#39;categories&#39;, &#39;name&#39;])\ .drop_duplicates(subset=[&#39;name&#39;])\ .show() +--------------------+--------------------+-----+--------------------+ | business_id| user_id|stars| categories| +--------------------+--------------------+-----+--------------------+ |9XLH_grfIYKR7d5ZT...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Ital...| |A7waf6G3cvnLfAqKe...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Italian| |kuJRRmmmDUXqwM6kN...|i6V3NyTdkBVwPpH7r...| 4.0|Nightlife, Food, ...| |aEnoF_79jQE83s-I7...|i6V3NyTdkBVwPpH7r...| 3.0|Food, Restaurants...| |d4bVdEDwxmyB0M-w5...|i6V3NyTdkBVwPpH7r...| 4.0|Breakfast &amp; Brunc...| |28adZ4lsuUeVB2aWz...|i6V3NyTdkBVwPpH7r...| 5.0|Bars, Food, Gastr...| |cTbFJzHQzFSX-z3JF...|i6V3NyTdkBVwPpH7r...| 4.0|Restaurants, Amer...| |eQCYur0033RkZdh5V...|i6V3NyTdkBVwPpH7r...| 3.0|Italian, Breakfas...| |Ycp3Agr7dt71TZkeK...|i6V3NyTdkBVwPpH7r...| 3.0|French, Breakfast...| |7HrCELR6uv2HkgL7a...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Seaf...| |sHXIiGercy22UVpwM...|i6V3NyTdkBVwPpH7r...| 4.0|Comfort Food, Nig...| |nDn2h-_c7Xk4UwM0a...|i6V3NyTdkBVwPpH7r...| 4.0|Mediterranean, Gr...| |Cx0o524EbpLh8Luvj...|i6V3NyTdkBVwPpH7r...| 5.0|Mediterranean, Mi...| |K5Q2vkF5UpytV9Q1r...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Japa...| |lCwUmc0IEhIMz7lyZ...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Vege...| |siaRCT2-PkyeXUVKr...|i6V3NyTdkBVwPpH7r...| 3.0|Restaurants, Chin...| |O66Zy8Y13VBm72ZDh...|i6V3NyTdkBVwPpH7r...| 4.0|American (New), R...| |KuIxm6FVNmlvpssWJ...|i6V3NyTdkBVwPpH7r...| 4.0|Mediterranean, Gr...| |I2nw7LGLSHN4uUgnH...|i6V3NyTdkBVwPpH7r...| 3.0|American (New), F...| |Ww-qDl1G9Kr7igS3o...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Amer...| +--------------------+--------------------+-----+--------------------+ only showing top 20 rows +--------------------+-----+--------------------+--------------------+ | business_id|stars| categories| name| +--------------------+-----+--------------------+--------------------+ |3VuAagJSUzWDgisd4...| 4.0|Canadian (New), B...| Fuse| |TiQBE6BdjSg9MF3UC...| 5.0|Indian, Sri Lanka...| New Kalyani| |nVFZTB3uwW_NkAlqI...| 5.0|Restaurants, Cate...| Latte Booth| |zNCGTEwBrmrVLfjxl...| 5.0|Desserts, Cafes, ...|Ballissimo Loukou...| |MTneG8wJrUxIzIfnH...| 5.0|Event Planning &amp; ...| Baby Point Lounge| |xUsYf7lB0bi1zGEw4...| 5.0|Food, Barbeque, F...|Stoke Stack Barbecue| |rdWy6OF9QldlIxlYV...| 4.0|Restaurants, Pers...| Tabriz| |eohcbvMCGegrUCDnj...| 5.0|Thai, Restaurants...| Qinthai Cuisine| |58pzEN_yy2hjPjtml...| 1.0|Restaurants, Fili...| Kalesa Restobar| |ScdakSPeGerwzJu2D...| 5.0|Pakistani, Indian...| Shalimar Grill| |Q0fQ5FRT0ug80Vk9X...| 5.0|Cocktail Bars, Re...| Viajero Cantina| |GFBiGcIZ8Wqm6wtTL...| 4.0|Restaurants, Chinese| Taste of Qin Yun| |fcayaG-BUicxcIZwG...| 5.0|Japanese, Restaur...| Hiwa| |Xja69DDoUqbPwFOSB...| 4.0|Restaurants, Pizz...| Slice N Bites| |4Nn9QoRDkOr-DWMF7...| 5.0|Portuguese, Resta...|Brasileirissimo S...| |U7JrKn4fYW2RpJa7N...| 5.0|Restaurants, Cana...|The Carlton Resta...| |CJq8OmZuScJ1jUUjx...| 5.0|Restaurants, Sush...| Hoya Sushi| |sSp-ZbEsVDKf8Y2OA...| 5.0|Cafes, Meat Shops...| Speducci Mercatto| |hT5kvnJnBWzUWrSpq...| 5.0|Chicken Wings, Ca...| The Sky Stars| |zWgoKXfq75Zhm8qcu...| 4.0|Sandwiches, Fast ...| Euro Bite| +--------------------+-----+--------------------+--------------------+" /><meta property="og:description" content="Introduction Recommender Systems are algorithms designed to make suggestions of items to users of a certain platform based on their previous patterns. They are used in the tech industry by companies such as Netflix, YouTube, Facebook, Amazon, Expedia, Spotify and so on. More recently, recommender systems have become more diffuse and are not limited to big tech companies, but virtually every company can create its own system (with the right dataset). The benefits of using such systems are enormous, as described here, here and here. In a nutshell, it can drive traffic, deliver personalised content, enhance customer engagement, increase sales and much more. The architecture of the recommendation engine is dependent on the business domain and the attributes of the dataset at one’s disposal. For instance, customers on eBay frequently provide ratings for products scaling on 1 (unhappy) to 5 (very happy). Spotify holds information about the gender of music one listens to. Uber eats should know what your favourite type of food is. Instagram has user patterns of likes in images. Such data sources document interactions between users and products (items). In addition, the platform may access personal information from users, such as their location, age, sex and so on. Not to mention the complete metadata of their items. There are three especially common methods to design a recommender system: Collaborative Filtering, Content-based Filtering and hybrid techniques. Content-based systems aim to make recommendations based on some previous information about the customer and the products. For instance, if Netflix knows you like drama movies, it might recommend you movies of this gender. However, in a collaborative filtering approach, it might simply ignore the gender of the film. The features used in this case are exclusively users rating patterns. For instance, if you watched five different series on Netflix and have rated five each of them, just like some other random user, then you might be interested to know what else he has rated as five stars. Hybrid systems make use of both techniques. In this project, we will use of Alternating Least Square Matrix Factorization, a Collaborative Filtering algorithm. We will build a recommender system for restaurants in the city of Toronto. Requirements: Python Apache Spark Import Libraries and Initialize spark session !pip install pyspark #import libraries from pyspark import SparkContext from pyspark.ml.recommendation import ALS from pyspark.sql import SparkSession ,Row from pyspark.sql.functions import col from pyspark.sql import SQLContext from pyspark.ml.feature import StringIndexer from pyspark.ml import Pipeline from pyspark.ml.evaluation import RegressionEvaluator from pyspark.sql.types import StructType,StructField,IntegerType import matplotlib.pyplot as plt %matplotlib inline appName=&quot;Collaborative Filtering with PySpark&quot; #initialize the spark session spark = SparkSession.builder.appName(appName).getOrCreate() #get sparkcontext from the sparksession sc = spark.sparkContext sqlContext = SQLContext(sc) Load Dataset in Apache Spark Dataset We will be working with yelp dataset. It contains millions of reviews of businesses across the world. We will limit ourselves to the restaurants in the city of Toronto, Canada. The relevant files for us are the following: yelp_academic_dataset_business.json:Contains information about every review made every customer for every business (millions of reviews). yelp_academic_dataset_review.json: Contains multiple characteristics from businesses such as parking available, type of food, etc. Spark SQL Since we are working with json files we use the function read.json. It takes a json file and transform it to a dataframe. We use sqlContextfrom the module Spark SQL. Spark SQL is a Spark module for structured data processing. It allows use to perform SQL queries in dataframes such as join, groupby, select and so on. df_business = sqlContext.read.json(&#39;../input/yelp-dataset/yelp_academic_dataset_business.json&#39;) df_review = sqlContext.read.json(&#39;/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json&#39;) Filter Rows and columns Our dataset contains many columns, and most of them won’t be used in this project. From the table df_business, we want only the essential features of businesses such as the id, name, stars, category and so on. We are exclusively interested in companies that are restaurants and in the city of Toronto. Therefore we apply the function filter in the columns city and category to enforce this restriction. From the table df_review, we want only the reviews from the selected table above. We use an inner join of df_review and df_business to eliminate all other businesses from the table reviews. df_business = df_business.select(&quot;business_id&quot;,&quot;name&quot;, &quot;stars&quot;, &quot;review_count&quot;, &quot;attributes&quot;, &quot;categories&quot;, &quot;city&quot;).withColumnRenamed(&quot;stars&quot;, &quot;stars_restaurant&quot;) df_business = df_business.filter((df_business[&#39;city&#39;] == &#39;Toronto&#39;) &amp; (df_business.categories.contains(&#39;Restaurants&#39;))).drop(&#39;city&#39;) df_review = df_review.join(df_business, on=&#39;business_id&#39;, how=&#39;inner&#39;) Lets make a quick visualisation to the basic elements of our review table. df_review.select([&#39;business_id&#39;, &#39;user_id&#39;, &#39;stars&#39;]).show() +--------------------+--------------------+-----+ | business_id| user_id|stars| +--------------------+--------------------+-----+ |qUWqjjjfpB2-4P3He...|TZQSUDDcA4ek5gBd6...| 4.0| |9Eghhu_LzEJgDKNgi...|iFEM16O5BeKvf_AHs...| 3.0| |cDoo0Pf1d_P79Rq3Z...|1kNsEAhGU8d8xugMu...| 3.0| |4m_hApwQ054v3ue_O...|Eg_VTAQwK3CxYTORN...| 5.0| |jM6JjZXFAQQANwdlE...|IIE2OX5haarGNefY2...| 5.0| |PMPMHHLe9vFzcR67i...|RRhco4irDXPk5EJmv...| 5.0| |IfUkm42SB9D0m_Zbk...|Kl6jNDAE7PG_VVQaf...| 4.0| |NrJSy3dgcXErFtOKG...|is1nHZ4oBqqmBm_mf...| 4.0| |nY2oBwH3s5sKox1mE...|JnPIjvC0cmooNDfsa...| 5.0| |tWdp26XQEJqJGnRmF...|IeojscL3rg3x3vtmR...| 4.0| |tJcpzXzykNSLuzWwa...|6WmMHMBM4FLGyK98-...| 1.0| |PjtX-5vSTBVyWfMRE...|pMefTWo6gMdx8WhYS...| 4.0| |28adZ4lsuUeVB2aWz...|BwwqlPVsJk1dbUyNw...| 5.0| |tvYID0arhN-shKGUr...|kmOvnwtroMBC8y9lO...| 1.0| |sSdHUsUZ4mvkb5ymI...|0aHFybE0id9DD97Qz...| 4.0| |n-5dPbGyziS0SOkVD...|Fw8Lj7q7DqTh-m3hG...| 4.0| |0a1BBSewiusfCalA9...|hYnq9-wO-RzmiTTGM...| 4.0| |uG0yvj2JWfCf0eaIg...|yiLiYYg6MM7Pmuo6j...| 5.0| |4POPYEONJpkfhWOMx...|vxf427mKFMUxpfbHC...| 2.0| |w7DEm_2Gj_xF0qeRd...|BOmBm4j0r2JPqi6V6...| 4.0| +--------------------+--------------------+-----+ only showing top 20 rows Exploratory Data Analysis Let’s have a quick visualisation of the data. We plot a histogram of the ratings from users. However, to make visualisations we have to convert the data from dataframe (pyspark) to pandas. First we use the .collect() and later we extract the the values. reviews = df_review.select(&#39;stars&#39;).collect() review_list = [reviews[i][0] for i in range(len(reviews))] plt.hist(review_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5, histtype=&#39;stepfilled&#39;, color=&#39;steelblue&#39;, edgecolor=&#39;none&#39;) plt.ylabel(&#39;Frequency&#39;) plt.xlabel(&#39;Rating&#39;) plt.style.use(&#39;seaborn-white&#39;) Quite generous public from Toronto. Most ratings are above 3. Now let’s see the distribution of ratings of each restaurant. restaurant_reviews = df_business.select(&#39;stars_restaurant&#39;).collect() restaurant_reviews_list = [restaurant_reviews[i][0] for i in range(len(restaurant_reviews))] plt.hist(restaurant_reviews_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5, histtype=&#39;stepfilled&#39;, color=&#39;steelblue&#39;, edgecolor=&#39;none&#39;) plt.ylabel(&#39;Frequency&#39;) plt.xlabel(&#39;Rating&#39;) plt.style.use(&#39;seaborn-white&#39;) Here were see a more normally distributed curve. Aditionally we can see that most restaurants do pretty well in terms of average rating. Now let’s visualise what the most popular type of restaurants in Toronto are. What kind of food do they serve? We will create a word cloud. restaurant_categories = df_business.select(&#39;categories&#39;).collect() restaurant_categories_list = [restaurant_categories[i][0] for i in range(len(restaurant_categories))] text = &quot; &quot;.join(review for review in restaurant_categories_list) from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # eliminate useless words text = text.replace(&#39;Restaurants&#39;, &quot;&quot;) text = text.replace(&#39;bars&#39;, &quot;&quot;) text = text.replace(&#39;food&#39;, &quot;&quot;) # Generate a word cloud image wordcloud = WordCloud(background_color=&quot;white&quot;).generate(text) # Display the generated image: # the matplotlib way: plt.figure(figsize=(10,8)) plt.imshow(wordcloud, interpolation=&#39;bilinear&#39;) plt.axis(&quot;off&quot;) plt.show() Convert String to index Before starting the modelling process, we must convert all columns that will be used in the model to integer. This is compulsory for the ALS model from PySpark. The columns that need to be converted are the business_id and user_id. We use the StringIndexer function imported in from pyspark.ml.feature. indexer = [StringIndexer(inputCol=column, outputCol=column+&quot;_index&quot;) for column in [&#39;business_id&#39;, &#39;user_id&#39;]] pipeline = Pipeline(stages=indexer) transformed = pipeline.fit(df_review).transform(df_review) transformed.select([&#39;business_id&#39;, &#39;user_id&#39;,&#39;business_id_index&#39;, &#39;user_id_index&#39;]) Split Dataset in train and test (training, test) = transformed.randomSplit([0.8, 0.2]) Create ALS model Alternating Least Square is a matrix factorisation algorithm implemented in Apache Spark ML and built for large-scale collaborative filtering problems. Matrix factorization (or decomposition) The basic idea is to decompose a matrix in smaller parts in the same way we can do for a number. For instance, we can say that the number four can be decomposed in two times two (4 = 2 x 2). In the same way, we can do a decomposition of a matrix. Here is an example of how can we decompose a matrix that has ratings for restaurants by clients: If we are able to find the hidden matrices, we will be able to calculate the expected rating that every client will give to each restaurant. This is our goal with the algorithm. But how to find the hidden matrices? The math in this process is extensive and is not our goal to discuss it in here. You can read it about in here. It is very a very similar process to the stochastic gradient descent. Parameters (as described on Spark website) - numBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10). - rank is the number of latent factors in the model (defaults to 10). - maxIter is the maximum number of iterations to run (defaults to 10). - regParam specifies the regularization parameter in ALS (defaults to 1.0). - implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback). - alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0). - nonnegative specifies whether or not to use nonnegative constraints for least squares (defaults to false). als=ALS(maxIter=5, regParam=0.09, rank=25, userCol=&quot;user_id_index&quot;, itemCol=&quot;business_id_index&quot;, ratingCol=&quot;stars&quot;, coldStartStrategy=&quot;drop&quot;, nonnegative=True) model=als.fit(training) Evaluate RMSE evaluator=RegressionEvaluator(metricName=&quot;rmse&quot;,labelCol=&quot;stars&quot;,predictionCol=&quot;prediction&quot;) predictions=model.transform(test) rmse=evaluator.evaluate(predictions) print(&quot;RMSE=&quot;+str(rmse)) RMSE=1.3651734482322269 Our model is doing pretty well. We have achieved a 1.36 average squared error. Lets see an applied case of a recommendation for a customer. In future works we can include a step of parameter tunning as in here. Visualize Recommendations Now we visualise recommendations for user 30 (could be any other). test = model.recommendForAllUsers(20).filter(col(&#39;user_id_index&#39;)==30).select(&quot;recommendations&quot;).collect() topRestaurants = [] for item in test[0][0]: topRestaurants.append(item.business_id_index) schema = StructType([StructField(&quot;business_id_index&quot;,IntegerType(),True)]) restaurants = spark.createDataFrame(topRestaurants,IntegerType()).toDF(&quot;business_id_index&quot;) transformed\ .select([&#39;business_id&#39;, &#39;user_id&#39;, &#39;stars&#39;, &#39;categories&#39;])\ .filter(col(&#39;user_id_index&#39;)==30)\ .show() restaurants\ .join(transformed, on = &#39;business_id_index&#39;, how = &#39;inner&#39;)\ .select([&#39;business_id&#39;, &#39;stars&#39;, &#39;categories&#39;, &#39;name&#39;])\ .drop_duplicates(subset=[&#39;name&#39;])\ .show() +--------------------+--------------------+-----+--------------------+ | business_id| user_id|stars| categories| +--------------------+--------------------+-----+--------------------+ |9XLH_grfIYKR7d5ZT...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Ital...| |A7waf6G3cvnLfAqKe...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Italian| |kuJRRmmmDUXqwM6kN...|i6V3NyTdkBVwPpH7r...| 4.0|Nightlife, Food, ...| |aEnoF_79jQE83s-I7...|i6V3NyTdkBVwPpH7r...| 3.0|Food, Restaurants...| |d4bVdEDwxmyB0M-w5...|i6V3NyTdkBVwPpH7r...| 4.0|Breakfast &amp; Brunc...| |28adZ4lsuUeVB2aWz...|i6V3NyTdkBVwPpH7r...| 5.0|Bars, Food, Gastr...| |cTbFJzHQzFSX-z3JF...|i6V3NyTdkBVwPpH7r...| 4.0|Restaurants, Amer...| |eQCYur0033RkZdh5V...|i6V3NyTdkBVwPpH7r...| 3.0|Italian, Breakfas...| |Ycp3Agr7dt71TZkeK...|i6V3NyTdkBVwPpH7r...| 3.0|French, Breakfast...| |7HrCELR6uv2HkgL7a...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Seaf...| |sHXIiGercy22UVpwM...|i6V3NyTdkBVwPpH7r...| 4.0|Comfort Food, Nig...| |nDn2h-_c7Xk4UwM0a...|i6V3NyTdkBVwPpH7r...| 4.0|Mediterranean, Gr...| |Cx0o524EbpLh8Luvj...|i6V3NyTdkBVwPpH7r...| 5.0|Mediterranean, Mi...| |K5Q2vkF5UpytV9Q1r...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Japa...| |lCwUmc0IEhIMz7lyZ...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Vege...| |siaRCT2-PkyeXUVKr...|i6V3NyTdkBVwPpH7r...| 3.0|Restaurants, Chin...| |O66Zy8Y13VBm72ZDh...|i6V3NyTdkBVwPpH7r...| 4.0|American (New), R...| |KuIxm6FVNmlvpssWJ...|i6V3NyTdkBVwPpH7r...| 4.0|Mediterranean, Gr...| |I2nw7LGLSHN4uUgnH...|i6V3NyTdkBVwPpH7r...| 3.0|American (New), F...| |Ww-qDl1G9Kr7igS3o...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Amer...| +--------------------+--------------------+-----+--------------------+ only showing top 20 rows +--------------------+-----+--------------------+--------------------+ | business_id|stars| categories| name| +--------------------+-----+--------------------+--------------------+ |3VuAagJSUzWDgisd4...| 4.0|Canadian (New), B...| Fuse| |TiQBE6BdjSg9MF3UC...| 5.0|Indian, Sri Lanka...| New Kalyani| |nVFZTB3uwW_NkAlqI...| 5.0|Restaurants, Cate...| Latte Booth| |zNCGTEwBrmrVLfjxl...| 5.0|Desserts, Cafes, ...|Ballissimo Loukou...| |MTneG8wJrUxIzIfnH...| 5.0|Event Planning &amp; ...| Baby Point Lounge| |xUsYf7lB0bi1zGEw4...| 5.0|Food, Barbeque, F...|Stoke Stack Barbecue| |rdWy6OF9QldlIxlYV...| 4.0|Restaurants, Pers...| Tabriz| |eohcbvMCGegrUCDnj...| 5.0|Thai, Restaurants...| Qinthai Cuisine| |58pzEN_yy2hjPjtml...| 1.0|Restaurants, Fili...| Kalesa Restobar| |ScdakSPeGerwzJu2D...| 5.0|Pakistani, Indian...| Shalimar Grill| |Q0fQ5FRT0ug80Vk9X...| 5.0|Cocktail Bars, Re...| Viajero Cantina| |GFBiGcIZ8Wqm6wtTL...| 4.0|Restaurants, Chinese| Taste of Qin Yun| |fcayaG-BUicxcIZwG...| 5.0|Japanese, Restaur...| Hiwa| |Xja69DDoUqbPwFOSB...| 4.0|Restaurants, Pizz...| Slice N Bites| |4Nn9QoRDkOr-DWMF7...| 5.0|Portuguese, Resta...|Brasileirissimo S...| |U7JrKn4fYW2RpJa7N...| 5.0|Restaurants, Cana...|The Carlton Resta...| |CJq8OmZuScJ1jUUjx...| 5.0|Restaurants, Sush...| Hoya Sushi| |sSp-ZbEsVDKf8Y2OA...| 5.0|Cafes, Meat Shops...| Speducci Mercatto| |hT5kvnJnBWzUWrSpq...| 5.0|Chicken Wings, Ca...| The Sky Stars| |zWgoKXfq75Zhm8qcu...| 4.0|Sandwiches, Fast ...| Euro Bite| +--------------------+-----+--------------------+--------------------+" /><link rel="canonical" href="http://localhost:4000/blog/Recommender-System/" /><meta property="og:url" content="http://localhost:4000/blog/Recommender-System/" /><meta property="og:site_name" content="Welcome to my Website" /><meta property="og:image" content="http://localhost:4000/assets/images/recommendation.JPG" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-07-16T18:12:00+08:00" /><script type="application/ld+json"> {"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/Recommender-System/"},"datePublished":"2020-07-16T18:12:00+08:00","description":"Introduction Recommender Systems are algorithms designed to make suggestions of items to users of a certain platform based on their previous patterns. They are used in the tech industry by companies such as Netflix, YouTube, Facebook, Amazon, Expedia, Spotify and so on. More recently, recommender systems have become more diffuse and are not limited to big tech companies, but virtually every company can create its own system (with the right dataset). The benefits of using such systems are enormous, as described here, here and here. In a nutshell, it can drive traffic, deliver personalised content, enhance customer engagement, increase sales and much more. The architecture of the recommendation engine is dependent on the business domain and the attributes of the dataset at one’s disposal. For instance, customers on eBay frequently provide ratings for products scaling on 1 (unhappy) to 5 (very happy). Spotify holds information about the gender of music one listens to. Uber eats should know what your favourite type of food is. Instagram has user patterns of likes in images. Such data sources document interactions between users and products (items). In addition, the platform may access personal information from users, such as their location, age, sex and so on. Not to mention the complete metadata of their items. There are three especially common methods to design a recommender system: Collaborative Filtering, Content-based Filtering and hybrid techniques. Content-based systems aim to make recommendations based on some previous information about the customer and the products. For instance, if Netflix knows you like drama movies, it might recommend you movies of this gender. However, in a collaborative filtering approach, it might simply ignore the gender of the film. The features used in this case are exclusively users rating patterns. For instance, if you watched five different series on Netflix and have rated five each of them, just like some other random user, then you might be interested to know what else he has rated as five stars. Hybrid systems make use of both techniques. In this project, we will use of Alternating Least Square Matrix Factorization, a Collaborative Filtering algorithm. We will build a recommender system for restaurants in the city of Toronto. Requirements: Python Apache Spark Import Libraries and Initialize spark session !pip install pyspark #import libraries from pyspark import SparkContext from pyspark.ml.recommendation import ALS from pyspark.sql import SparkSession ,Row from pyspark.sql.functions import col from pyspark.sql import SQLContext from pyspark.ml.feature import StringIndexer from pyspark.ml import Pipeline from pyspark.ml.evaluation import RegressionEvaluator from pyspark.sql.types import StructType,StructField,IntegerType import matplotlib.pyplot as plt %matplotlib inline appName=&quot;Collaborative Filtering with PySpark&quot; #initialize the spark session spark = SparkSession.builder.appName(appName).getOrCreate() #get sparkcontext from the sparksession sc = spark.sparkContext sqlContext = SQLContext(sc) Load Dataset in Apache Spark Dataset We will be working with yelp dataset. It contains millions of reviews of businesses across the world. We will limit ourselves to the restaurants in the city of Toronto, Canada. The relevant files for us are the following: yelp_academic_dataset_business.json:Contains information about every review made every customer for every business (millions of reviews). yelp_academic_dataset_review.json: Contains multiple characteristics from businesses such as parking available, type of food, etc. Spark SQL Since we are working with json files we use the function read.json. It takes a json file and transform it to a dataframe. We use sqlContextfrom the module Spark SQL. Spark SQL is a Spark module for structured data processing. It allows use to perform SQL queries in dataframes such as join, groupby, select and so on. df_business = sqlContext.read.json(&#39;../input/yelp-dataset/yelp_academic_dataset_business.json&#39;) df_review = sqlContext.read.json(&#39;/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json&#39;) Filter Rows and columns Our dataset contains many columns, and most of them won’t be used in this project. From the table df_business, we want only the essential features of businesses such as the id, name, stars, category and so on. We are exclusively interested in companies that are restaurants and in the city of Toronto. Therefore we apply the function filter in the columns city and category to enforce this restriction. From the table df_review, we want only the reviews from the selected table above. We use an inner join of df_review and df_business to eliminate all other businesses from the table reviews. df_business = df_business.select(&quot;business_id&quot;,&quot;name&quot;, &quot;stars&quot;, &quot;review_count&quot;, &quot;attributes&quot;, &quot;categories&quot;, &quot;city&quot;).withColumnRenamed(&quot;stars&quot;, &quot;stars_restaurant&quot;) df_business = df_business.filter((df_business[&#39;city&#39;] == &#39;Toronto&#39;) &amp; (df_business.categories.contains(&#39;Restaurants&#39;))).drop(&#39;city&#39;) df_review = df_review.join(df_business, on=&#39;business_id&#39;, how=&#39;inner&#39;) Lets make a quick visualisation to the basic elements of our review table. df_review.select([&#39;business_id&#39;, &#39;user_id&#39;, &#39;stars&#39;]).show() +--------------------+--------------------+-----+ | business_id| user_id|stars| +--------------------+--------------------+-----+ |qUWqjjjfpB2-4P3He...|TZQSUDDcA4ek5gBd6...| 4.0| |9Eghhu_LzEJgDKNgi...|iFEM16O5BeKvf_AHs...| 3.0| |cDoo0Pf1d_P79Rq3Z...|1kNsEAhGU8d8xugMu...| 3.0| |4m_hApwQ054v3ue_O...|Eg_VTAQwK3CxYTORN...| 5.0| |jM6JjZXFAQQANwdlE...|IIE2OX5haarGNefY2...| 5.0| |PMPMHHLe9vFzcR67i...|RRhco4irDXPk5EJmv...| 5.0| |IfUkm42SB9D0m_Zbk...|Kl6jNDAE7PG_VVQaf...| 4.0| |NrJSy3dgcXErFtOKG...|is1nHZ4oBqqmBm_mf...| 4.0| |nY2oBwH3s5sKox1mE...|JnPIjvC0cmooNDfsa...| 5.0| |tWdp26XQEJqJGnRmF...|IeojscL3rg3x3vtmR...| 4.0| |tJcpzXzykNSLuzWwa...|6WmMHMBM4FLGyK98-...| 1.0| |PjtX-5vSTBVyWfMRE...|pMefTWo6gMdx8WhYS...| 4.0| |28adZ4lsuUeVB2aWz...|BwwqlPVsJk1dbUyNw...| 5.0| |tvYID0arhN-shKGUr...|kmOvnwtroMBC8y9lO...| 1.0| |sSdHUsUZ4mvkb5ymI...|0aHFybE0id9DD97Qz...| 4.0| |n-5dPbGyziS0SOkVD...|Fw8Lj7q7DqTh-m3hG...| 4.0| |0a1BBSewiusfCalA9...|hYnq9-wO-RzmiTTGM...| 4.0| |uG0yvj2JWfCf0eaIg...|yiLiYYg6MM7Pmuo6j...| 5.0| |4POPYEONJpkfhWOMx...|vxf427mKFMUxpfbHC...| 2.0| |w7DEm_2Gj_xF0qeRd...|BOmBm4j0r2JPqi6V6...| 4.0| +--------------------+--------------------+-----+ only showing top 20 rows Exploratory Data Analysis Let’s have a quick visualisation of the data. We plot a histogram of the ratings from users. However, to make visualisations we have to convert the data from dataframe (pyspark) to pandas. First we use the .collect() and later we extract the the values. reviews = df_review.select(&#39;stars&#39;).collect() review_list = [reviews[i][0] for i in range(len(reviews))] plt.hist(review_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5, histtype=&#39;stepfilled&#39;, color=&#39;steelblue&#39;, edgecolor=&#39;none&#39;) plt.ylabel(&#39;Frequency&#39;) plt.xlabel(&#39;Rating&#39;) plt.style.use(&#39;seaborn-white&#39;) Quite generous public from Toronto. Most ratings are above 3. Now let’s see the distribution of ratings of each restaurant. restaurant_reviews = df_business.select(&#39;stars_restaurant&#39;).collect() restaurant_reviews_list = [restaurant_reviews[i][0] for i in range(len(restaurant_reviews))] plt.hist(restaurant_reviews_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5, histtype=&#39;stepfilled&#39;, color=&#39;steelblue&#39;, edgecolor=&#39;none&#39;) plt.ylabel(&#39;Frequency&#39;) plt.xlabel(&#39;Rating&#39;) plt.style.use(&#39;seaborn-white&#39;) Here were see a more normally distributed curve. Aditionally we can see that most restaurants do pretty well in terms of average rating. Now let’s visualise what the most popular type of restaurants in Toronto are. What kind of food do they serve? We will create a word cloud. restaurant_categories = df_business.select(&#39;categories&#39;).collect() restaurant_categories_list = [restaurant_categories[i][0] for i in range(len(restaurant_categories))] text = &quot; &quot;.join(review for review in restaurant_categories_list) from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # eliminate useless words text = text.replace(&#39;Restaurants&#39;, &quot;&quot;) text = text.replace(&#39;bars&#39;, &quot;&quot;) text = text.replace(&#39;food&#39;, &quot;&quot;) # Generate a word cloud image wordcloud = WordCloud(background_color=&quot;white&quot;).generate(text) # Display the generated image: # the matplotlib way: plt.figure(figsize=(10,8)) plt.imshow(wordcloud, interpolation=&#39;bilinear&#39;) plt.axis(&quot;off&quot;) plt.show() Convert String to index Before starting the modelling process, we must convert all columns that will be used in the model to integer. This is compulsory for the ALS model from PySpark. The columns that need to be converted are the business_id and user_id. We use the StringIndexer function imported in from pyspark.ml.feature. indexer = [StringIndexer(inputCol=column, outputCol=column+&quot;_index&quot;) for column in [&#39;business_id&#39;, &#39;user_id&#39;]] pipeline = Pipeline(stages=indexer) transformed = pipeline.fit(df_review).transform(df_review) transformed.select([&#39;business_id&#39;, &#39;user_id&#39;,&#39;business_id_index&#39;, &#39;user_id_index&#39;]) Split Dataset in train and test (training, test) = transformed.randomSplit([0.8, 0.2]) Create ALS model Alternating Least Square is a matrix factorisation algorithm implemented in Apache Spark ML and built for large-scale collaborative filtering problems. Matrix factorization (or decomposition) The basic idea is to decompose a matrix in smaller parts in the same way we can do for a number. For instance, we can say that the number four can be decomposed in two times two (4 = 2 x 2). In the same way, we can do a decomposition of a matrix. Here is an example of how can we decompose a matrix that has ratings for restaurants by clients: If we are able to find the hidden matrices, we will be able to calculate the expected rating that every client will give to each restaurant. This is our goal with the algorithm. But how to find the hidden matrices? The math in this process is extensive and is not our goal to discuss it in here. You can read it about in here. It is very a very similar process to the stochastic gradient descent. Parameters (as described on Spark website) - numBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10). - rank is the number of latent factors in the model (defaults to 10). - maxIter is the maximum number of iterations to run (defaults to 10). - regParam specifies the regularization parameter in ALS (defaults to 1.0). - implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback). - alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0). - nonnegative specifies whether or not to use nonnegative constraints for least squares (defaults to false). als=ALS(maxIter=5, regParam=0.09, rank=25, userCol=&quot;user_id_index&quot;, itemCol=&quot;business_id_index&quot;, ratingCol=&quot;stars&quot;, coldStartStrategy=&quot;drop&quot;, nonnegative=True) model=als.fit(training) Evaluate RMSE evaluator=RegressionEvaluator(metricName=&quot;rmse&quot;,labelCol=&quot;stars&quot;,predictionCol=&quot;prediction&quot;) predictions=model.transform(test) rmse=evaluator.evaluate(predictions) print(&quot;RMSE=&quot;+str(rmse)) RMSE=1.3651734482322269 Our model is doing pretty well. We have achieved a 1.36 average squared error. Lets see an applied case of a recommendation for a customer. In future works we can include a step of parameter tunning as in here. Visualize Recommendations Now we visualise recommendations for user 30 (could be any other). test = model.recommendForAllUsers(20).filter(col(&#39;user_id_index&#39;)==30).select(&quot;recommendations&quot;).collect() topRestaurants = [] for item in test[0][0]: topRestaurants.append(item.business_id_index) schema = StructType([StructField(&quot;business_id_index&quot;,IntegerType(),True)]) restaurants = spark.createDataFrame(topRestaurants,IntegerType()).toDF(&quot;business_id_index&quot;) transformed\\ .select([&#39;business_id&#39;, &#39;user_id&#39;, &#39;stars&#39;, &#39;categories&#39;])\\ .filter(col(&#39;user_id_index&#39;)==30)\\ .show() restaurants\\ .join(transformed, on = &#39;business_id_index&#39;, how = &#39;inner&#39;)\\ .select([&#39;business_id&#39;, &#39;stars&#39;, &#39;categories&#39;, &#39;name&#39;])\\ .drop_duplicates(subset=[&#39;name&#39;])\\ .show() +--------------------+--------------------+-----+--------------------+ | business_id| user_id|stars| categories| +--------------------+--------------------+-----+--------------------+ |9XLH_grfIYKR7d5ZT...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Ital...| |A7waf6G3cvnLfAqKe...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Italian| |kuJRRmmmDUXqwM6kN...|i6V3NyTdkBVwPpH7r...| 4.0|Nightlife, Food, ...| |aEnoF_79jQE83s-I7...|i6V3NyTdkBVwPpH7r...| 3.0|Food, Restaurants...| |d4bVdEDwxmyB0M-w5...|i6V3NyTdkBVwPpH7r...| 4.0|Breakfast &amp; Brunc...| |28adZ4lsuUeVB2aWz...|i6V3NyTdkBVwPpH7r...| 5.0|Bars, Food, Gastr...| |cTbFJzHQzFSX-z3JF...|i6V3NyTdkBVwPpH7r...| 4.0|Restaurants, Amer...| |eQCYur0033RkZdh5V...|i6V3NyTdkBVwPpH7r...| 3.0|Italian, Breakfas...| |Ycp3Agr7dt71TZkeK...|i6V3NyTdkBVwPpH7r...| 3.0|French, Breakfast...| |7HrCELR6uv2HkgL7a...|i6V3NyTdkBVwPpH7r...| 2.0|Restaurants, Seaf...| |sHXIiGercy22UVpwM...|i6V3NyTdkBVwPpH7r...| 4.0|Comfort Food, Nig...| |nDn2h-_c7Xk4UwM0a...|i6V3NyTdkBVwPpH7r...| 4.0|Mediterranean, Gr...| |Cx0o524EbpLh8Luvj...|i6V3NyTdkBVwPpH7r...| 5.0|Mediterranean, Mi...| |K5Q2vkF5UpytV9Q1r...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Japa...| |lCwUmc0IEhIMz7lyZ...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Vege...| |siaRCT2-PkyeXUVKr...|i6V3NyTdkBVwPpH7r...| 3.0|Restaurants, Chin...| |O66Zy8Y13VBm72ZDh...|i6V3NyTdkBVwPpH7r...| 4.0|American (New), R...| |KuIxm6FVNmlvpssWJ...|i6V3NyTdkBVwPpH7r...| 4.0|Mediterranean, Gr...| |I2nw7LGLSHN4uUgnH...|i6V3NyTdkBVwPpH7r...| 3.0|American (New), F...| |Ww-qDl1G9Kr7igS3o...|i6V3NyTdkBVwPpH7r...| 5.0|Restaurants, Amer...| +--------------------+--------------------+-----+--------------------+ only showing top 20 rows +--------------------+-----+--------------------+--------------------+ | business_id|stars| categories| name| +--------------------+-----+--------------------+--------------------+ |3VuAagJSUzWDgisd4...| 4.0|Canadian (New), B...| Fuse| |TiQBE6BdjSg9MF3UC...| 5.0|Indian, Sri Lanka...| New Kalyani| |nVFZTB3uwW_NkAlqI...| 5.0|Restaurants, Cate...| Latte Booth| |zNCGTEwBrmrVLfjxl...| 5.0|Desserts, Cafes, ...|Ballissimo Loukou...| |MTneG8wJrUxIzIfnH...| 5.0|Event Planning &amp; ...| Baby Point Lounge| |xUsYf7lB0bi1zGEw4...| 5.0|Food, Barbeque, F...|Stoke Stack Barbecue| |rdWy6OF9QldlIxlYV...| 4.0|Restaurants, Pers...| Tabriz| |eohcbvMCGegrUCDnj...| 5.0|Thai, Restaurants...| Qinthai Cuisine| |58pzEN_yy2hjPjtml...| 1.0|Restaurants, Fili...| Kalesa Restobar| |ScdakSPeGerwzJu2D...| 5.0|Pakistani, Indian...| Shalimar Grill| |Q0fQ5FRT0ug80Vk9X...| 5.0|Cocktail Bars, Re...| Viajero Cantina| |GFBiGcIZ8Wqm6wtTL...| 4.0|Restaurants, Chinese| Taste of Qin Yun| |fcayaG-BUicxcIZwG...| 5.0|Japanese, Restaur...| Hiwa| |Xja69DDoUqbPwFOSB...| 4.0|Restaurants, Pizz...| Slice N Bites| |4Nn9QoRDkOr-DWMF7...| 5.0|Portuguese, Resta...|Brasileirissimo S...| |U7JrKn4fYW2RpJa7N...| 5.0|Restaurants, Cana...|The Carlton Resta...| |CJq8OmZuScJ1jUUjx...| 5.0|Restaurants, Sush...| Hoya Sushi| |sSp-ZbEsVDKf8Y2OA...| 5.0|Cafes, Meat Shops...| Speducci Mercatto| |hT5kvnJnBWzUWrSpq...| 5.0|Chicken Wings, Ca...| The Sky Stars| |zWgoKXfq75Zhm8qcu...| 4.0|Sandwiches, Fast ...| Euro Bite| +--------------------+-----+--------------------+--------------------+","image":"http://localhost:4000/assets/images/recommendation.JPG","author":{"@type":"Person","name":"Alan Gewerc"},"headline":"Recommender system using Pyspark (ALS algorithm)","url":"http://localhost:4000/blog/Recommender-System/","dateModified":"2020-07-16T18:12:00+08:00","@context":"https://schema.org"}</script><link rel="stylesheet" href="/assets/css/main-default.css" /><link id="color-scheme" rel="stylesheet" href="/assets/css/main-default.css" /><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/apple-icon-60x60.png" /><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/apple-icon-114x114.png" /><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/apple-icon-152x152.png" /><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/android-icon-192x192.png" /><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" /><link rel="icon" href="/favicon.ico" type="image/x-icon" /><script src="https://cdn.jsdelivr.net/npm/ga-lite@1/dist/ga-lite.min.js" async></script><script> var galite = galite || {}; galite.UA = 'UA-174262091-1';</script><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script><script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script></head><div class="wrapper"><div class="container"><div class="main"><div class="main-container shadow"><div class="title-space"> <h1>Recommender system using Pyspark (ALS algorithm)</h1></div><hr class="dashed"> <main> <ul class="breadcrumbs"> <li><a href="/">Home</a></li> <li><a href="/blog/">Blog</a></li> <li><a href="#">Recommender system</a></li> </ul><div class="meta" data-aos="fade-up"> <p> <small> <span> <i class="fa fa-calendar" aria-hidden="true"></i> 16 Jul 2020&nbsp; </span> <span> <i class="fa fa-user" aria-hidden="true"></i> Alan Gewerc&nbsp; </span> <span> <i class="fa fa-clock-o" aria-hidden="true"></i> 32 mins read. </span> </small> </p></div><div class="featured-image" style="background-image: url(/assets/images/recommendation.JPG)" data-aos="zoom-in" ></div><div class="container"> <article> <h2 id="introduction">Introduction</h2> <p>Recommender Systems are algorithms designed to make suggestions of items to users of a certain platform based on their previous patterns. They are used in the tech industry by companies such as Netflix, YouTube, Facebook, Amazon, Expedia, Spotify and so on. More recently, recommender systems have become more diffuse and are not limited to big tech companies, but virtually every company can create its own system (with the right dataset). <br /><br /> The benefits of using such systems are enormous, as described <a href="https://towardsdatascience.com/5-advantages-recommendation-engines-can-offer-to-businesses-10b663977673">here</a>, <a href="https://medium.com/@triconinfotech/improving-customer-engagement-with-recommender-systems-b423bdbb4e55">here</a> and <a href="https://neoteric.eu/blog/how-to-boost-sales-with-a-recommender-system/">here</a>. In a nutshell, it can drive traffic, deliver personalised content, enhance customer engagement, increase sales and much more. <br /> The architecture of the recommendation engine is dependent on the business domain and the attributes of the dataset at one’s disposal. For instance, customers on eBay frequently provide ratings for products scaling on 1 (unhappy) to 5 (very happy). Spotify holds information about the gender of music one listens to. Uber eats should know what your favourite type of food is. Instagram has user patterns of likes in images. Such data sources document interactions between users and products (items). In addition, the platform may access personal information from users, such as their location, age, sex and so on. Not to mention the complete metadata of their items. There are three especially common methods to design a recommender system: <code class="highlighter-rouge">Collaborative Filtering</code>, <code class="highlighter-rouge">Content-based Filtering</code> and <code class="highlighter-rouge">hybrid techniques</code>. Content-based systems aim to make recommendations based on some previous information about the customer and the products. For instance, if Netflix knows you like drama movies, it might recommend you movies of this gender. However, in a collaborative filtering approach, it might simply ignore the gender of the film. The features used in this case are exclusively users rating patterns. For instance, if you watched five different series on Netflix and have rated five each of them, just like some other random user, then you might be interested to know what else he has rated as five stars. Hybrid systems make use of both techniques. <br /><br /> In this project, we will use of Alternating Least Square Matrix Factorization, a Collaborative Filtering algorithm. We will build a recommender system for restaurants in the city of Toronto.</p> <h4 id="requirements">Requirements:</h4> <ul> <li>Python</li> <li>Apache Spark</li> </ul> <h2 id="import-libraries-and-initialize-spark-session">Import Libraries and Initialize spark session</h2><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pyspark</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#import libraries
</span><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.recommendation</span> <span class="kn">import</span> <span class="n">ALS</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span> <span class="p">,</span><span class="n">Row</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SQLContext</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StringIndexer</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.evaluation</span> <span class="kn">import</span> <span class="n">RegressionEvaluator</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span><span class="n">StructField</span><span class="p">,</span><span class="n">IntegerType</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">appName</span><span class="o">=</span><span class="s">"Collaborative Filtering with PySpark"</span>

<span class="c1">#initialize the spark session
</span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">appName</span><span class="p">(</span><span class="n">appName</span><span class="p">).</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1">#get sparkcontext from the sparksession
</span><span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">sparkContext</span>
<span class="n">sqlContext</span> <span class="o">=</span> <span class="n">SQLContext</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
</code></pre></div></div><h2 id="load-dataset-in-apache-spark">Load Dataset in Apache Spark</h2> <h3 id="dataset">Dataset</h3> <p>We will be working with yelp <a href="https://www.kaggle.com/yelp-dataset/yelp-dataset">dataset</a>. It contains millions of reviews of businesses across the world. We will limit ourselves to the restaurants in the city of Toronto, Canada. The relevant files for us are the following:</p> <p><code class="highlighter-rouge">yelp_academic_dataset_business.json:</code>Contains information about every review made every customer for every business (millions of reviews). <br /> <code class="highlighter-rouge">yelp_academic_dataset_review.json:</code> Contains multiple characteristics from businesses such as <code class="highlighter-rouge">parking available</code>, <code class="highlighter-rouge">type of food</code>, etc.</p> <h3 id="spark-sql">Spark SQL</h3> <p>Since we are working with json files we use the function <code class="highlighter-rouge">read.json</code>. It takes a json file and transform it to a dataframe. We use <code class="highlighter-rouge">sqlContext</code>from the module Spark SQL. Spark SQL is a Spark module for structured data processing. It allows use to perform SQL queries in dataframes such as <code class="highlighter-rouge">join</code>, <code class="highlighter-rouge">groupby</code>, <code class="highlighter-rouge">select</code> and so on.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_business</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">json</span><span class="p">(</span><span class="s">'../input/yelp-dataset/yelp_academic_dataset_business.json'</span><span class="p">)</span>
<span class="n">df_review</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">json</span><span class="p">(</span><span class="s">'/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json'</span><span class="p">)</span>
</code></pre></div></div><h2 id="filter-rows-and-columns">Filter Rows and columns</h2> <p>Our dataset contains many columns, and most of them won’t be used in this project. From the table <code class="highlighter-rouge">df_business</code>, we want only the essential features of businesses such as the <code class="highlighter-rouge">id</code>, <code class="highlighter-rouge">name</code>, <code class="highlighter-rouge">stars</code>, <code class="highlighter-rouge">category</code> and so on. We are exclusively interested in companies that are restaurants and in the city of Toronto. Therefore we apply the function filter in the columns city and category to enforce this restriction. From the table <code class="highlighter-rouge">df_review</code>, we want only the reviews from the selected table above. We use an <code class="highlighter-rouge">inner join</code> of <code class="highlighter-rouge">df_review</code> and <code class="highlighter-rouge">df_business</code> to eliminate all other businesses from the table reviews.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_business</span> <span class="o">=</span> <span class="n">df_business</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"business_id"</span><span class="p">,</span><span class="s">"name"</span><span class="p">,</span> <span class="s">"stars"</span><span class="p">,</span> 
                                 <span class="s">"review_count"</span><span class="p">,</span> <span class="s">"attributes"</span><span class="p">,</span> 
                                 <span class="s">"categories"</span><span class="p">,</span> <span class="s">"city"</span><span class="p">).</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s">"stars"</span><span class="p">,</span> <span class="s">"stars_restaurant"</span><span class="p">)</span>

<span class="n">df_business</span> <span class="o">=</span> <span class="n">df_business</span><span class="p">.</span><span class="nb">filter</span><span class="p">((</span><span class="n">df_business</span><span class="p">[</span><span class="s">'city'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Toronto'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_business</span><span class="p">.</span><span class="n">categories</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="s">'Restaurants'</span><span class="p">))).</span><span class="n">drop</span><span class="p">(</span><span class="s">'city'</span><span class="p">)</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_review</span> <span class="o">=</span> <span class="n">df_review</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_business</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'business_id'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'inner'</span><span class="p">)</span>
</code></pre></div></div><p>Lets make a quick visualisation to the basic elements of our review table.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_review</span><span class="p">.</span><span class="n">select</span><span class="p">([</span><span class="s">'business_id'</span><span class="p">,</span> <span class="s">'user_id'</span><span class="p">,</span> <span class="s">'stars'</span><span class="p">]).</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------+--------------------+-----+
|         business_id|             user_id|stars|
+--------------------+--------------------+-----+
|qUWqjjjfpB2-4P3He...|TZQSUDDcA4ek5gBd6...|  4.0|
|9Eghhu_LzEJgDKNgi...|iFEM16O5BeKvf_AHs...|  3.0|
|cDoo0Pf1d_P79Rq3Z...|1kNsEAhGU8d8xugMu...|  3.0|
|4m_hApwQ054v3ue_O...|Eg_VTAQwK3CxYTORN...|  5.0|
|jM6JjZXFAQQANwdlE...|IIE2OX5haarGNefY2...|  5.0|
|PMPMHHLe9vFzcR67i...|RRhco4irDXPk5EJmv...|  5.0|
|IfUkm42SB9D0m_Zbk...|Kl6jNDAE7PG_VVQaf...|  4.0|
|NrJSy3dgcXErFtOKG...|is1nHZ4oBqqmBm_mf...|  4.0|
|nY2oBwH3s5sKox1mE...|JnPIjvC0cmooNDfsa...|  5.0|
|tWdp26XQEJqJGnRmF...|IeojscL3rg3x3vtmR...|  4.0|
|tJcpzXzykNSLuzWwa...|6WmMHMBM4FLGyK98-...|  1.0|
|PjtX-5vSTBVyWfMRE...|pMefTWo6gMdx8WhYS...|  4.0|
|28adZ4lsuUeVB2aWz...|BwwqlPVsJk1dbUyNw...|  5.0|
|tvYID0arhN-shKGUr...|kmOvnwtroMBC8y9lO...|  1.0|
|sSdHUsUZ4mvkb5ymI...|0aHFybE0id9DD97Qz...|  4.0|
|n-5dPbGyziS0SOkVD...|Fw8Lj7q7DqTh-m3hG...|  4.0|
|0a1BBSewiusfCalA9...|hYnq9-wO-RzmiTTGM...|  4.0|
|uG0yvj2JWfCf0eaIg...|yiLiYYg6MM7Pmuo6j...|  5.0|
|4POPYEONJpkfhWOMx...|vxf427mKFMUxpfbHC...|  2.0|
|w7DEm_2Gj_xF0qeRd...|BOmBm4j0r2JPqi6V6...|  4.0|
+--------------------+--------------------+-----+
only showing top 20 rows
</code></pre></div></div><h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2> <p>Let’s have a quick visualisation of the data. We plot a histogram of the ratings from users.</p> <p>However, to make visualisations we have to convert the data from dataframe (pyspark) to pandas. First we use the <code class="highlighter-rouge">.collect()</code> and later we extract the the values.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reviews</span> <span class="o">=</span> <span class="n">df_review</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'stars'</span><span class="p">).</span><span class="n">collect</span><span class="p">()</span>
<span class="n">review_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">reviews</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reviews</span><span class="p">))]</span>

<span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">review_list</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">,</span><span class="mf">5.5</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
         <span class="n">histtype</span><span class="o">=</span><span class="s">'stepfilled'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'steelblue'</span><span class="p">,</span>
         <span class="n">edgecolor</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Frequency'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Rating'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">'seaborn-white'</span><span class="p">)</span>
</code></pre></div></div><p><img src="/assets/images/Recommender-System_12_1.png" alt="png" /></p> <p>Quite generous public from Toronto. Most ratings are above 3. Now let’s see the distribution of ratings of each restaurant.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">restaurant_reviews</span> <span class="o">=</span> <span class="n">df_business</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'stars_restaurant'</span><span class="p">).</span><span class="n">collect</span><span class="p">()</span>
<span class="n">restaurant_reviews_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">restaurant_reviews</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">restaurant_reviews</span><span class="p">))]</span>


<span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">restaurant_reviews_list</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">,</span><span class="mf">5.5</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
         <span class="n">histtype</span><span class="o">=</span><span class="s">'stepfilled'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'steelblue'</span><span class="p">,</span>
         <span class="n">edgecolor</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Frequency'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Rating'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">'seaborn-white'</span><span class="p">)</span>
</code></pre></div></div><p><img src="/assets/images/Recommender-System_14_0.png" alt="png" /></p> <p>Here were see a more normally distributed curve. Aditionally we can see that most restaurants do pretty well in terms of average rating. Now let’s visualise what the most popular type of restaurants in Toronto are. What kind of food do they serve? We will create a word cloud.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">restaurant_categories</span> <span class="o">=</span> <span class="n">df_business</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'categories'</span><span class="p">).</span><span class="n">collect</span><span class="p">()</span>
<span class="n">restaurant_categories_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">restaurant_categories</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">restaurant_categories</span><span class="p">))]</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">review</span> <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">restaurant_categories_list</span><span class="p">)</span>
</code></pre></div></div><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span><span class="p">,</span> <span class="n">STOPWORDS</span><span class="p">,</span> <span class="n">ImageColorGenerator</span>

<span class="c1"># eliminate useless words
</span><span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'Restaurants'</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'bars'</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'food'</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>


<span class="c1"># Generate a word cloud image
</span><span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">background_color</span><span class="o">=</span><span class="s">"white"</span><span class="p">).</span><span class="n">generate</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># Display the generated image:
# the matplotlib way:
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'bilinear'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div><p><img src="/assets/images/Recommender-System_18_0.png" alt="png" /></p> <h2 id="convert-string-to-index">Convert String to index</h2> <p>Before starting the modelling process, we must convert all columns that will be used in the model to integer. This is compulsory for the ALS model from PySpark. The columns that need to be converted are the <code class="highlighter-rouge">business_id</code> and <code class="highlighter-rouge">user_id</code>.</p> <p>We use the <code class="highlighter-rouge">StringIndexer</code> function imported in from <code class="highlighter-rouge">pyspark.ml.feature</code>.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">indexer</span> <span class="o">=</span> <span class="p">[</span><span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="n">column</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="n">column</span><span class="o">+</span><span class="s">"_index"</span><span class="p">)</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'business_id'</span><span class="p">,</span> <span class="s">'user_id'</span><span class="p">]]</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="n">indexer</span><span class="p">)</span>
<span class="n">transformed</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_review</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df_review</span><span class="p">)</span>
<span class="n">transformed</span><span class="p">.</span><span class="n">select</span><span class="p">([</span><span class="s">'business_id'</span><span class="p">,</span> <span class="s">'user_id'</span><span class="p">,</span><span class="s">'business_id_index'</span><span class="p">,</span> <span class="s">'user_id_index'</span><span class="p">])</span>
</code></pre></div></div><h2 id="split-dataset-in-train-and-test">Split Dataset in train and test</h2><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="o">=</span> <span class="n">transformed</span><span class="p">.</span><span class="n">randomSplit</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
</code></pre></div></div><h2 id="create-als-model">Create ALS model</h2> <p>Alternating Least Square is a matrix factorisation algorithm implemented in Apache Spark ML and built for large-scale collaborative filtering problems.</p> <h4 id="matrix-factorization-or-decomposition">Matrix factorization (or decomposition)</h4> <p>The basic idea is to decompose a matrix in smaller parts in the same way we can do for a number. For instance, we can say that the number four can be decomposed in two times two (4 = 2 x 2). In the same way, we can do a decomposition of a matrix.</p> <p>Here is an example of how can we decompose a matrix that has ratings for restaurants by clients: <img src="/assets/images/Matrix_Factorization.jpg" alt="Presentatio4" /></p> <p>If we are able to find the hidden matrices, we will be able to calculate the expected rating that every client will give to each restaurant. This is our goal with the algorithm.</p> <h4 id="but-how-to-find-the-hidden-matrices">But how to find the hidden matrices?</h4> <p>The math in this process is extensive and is not our goal to discuss it in here. You can read it about in <a href="https://blog.insightdatascience.com/explicit-matrix-factorization-als-sgd-and-all-that-jazz-b00e4d9b21ea">here</a>. It is very a very similar process to the stochastic gradient descent.</p> <h4 id="parameters-as-described-on-spark-website">Parameters (as described on Spark <a href="http://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html">website</a>)</h4> <p><em>- <strong>numBlocks</strong> is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10).</em><br /> <em>- <strong>rank</strong> is the number of latent factors in the model (defaults to 10).</em><br /> <em>- <strong>maxIter</strong> is the maximum number of iterations to run (defaults to 10).</em><br /> <em>- <strong>regParam</strong> specifies the regularization parameter in ALS (defaults to 1.0).</em><br /> <em>- <strong>implicitPrefs</strong> specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).</em><br /> <em>- <strong>alpha</strong> is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0).</em><br /> <em>- <strong>nonnegative</strong> specifies whether or not to use nonnegative constraints for least squares (defaults to false).</em></p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">als</span><span class="o">=</span><span class="n">ALS</span><span class="p">(</span><span class="n">maxIter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">regParam</span><span class="o">=</span><span class="mf">0.09</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
        <span class="n">userCol</span><span class="o">=</span><span class="s">"user_id_index"</span><span class="p">,</span>
        <span class="n">itemCol</span><span class="o">=</span><span class="s">"business_id_index"</span><span class="p">,</span>
        <span class="n">ratingCol</span><span class="o">=</span><span class="s">"stars"</span><span class="p">,</span>
        <span class="n">coldStartStrategy</span><span class="o">=</span><span class="s">"drop"</span><span class="p">,</span>
        <span class="n">nonnegative</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">model</span><span class="o">=</span><span class="n">als</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>
</code></pre></div></div><h2 id="evaluate-rmse">Evaluate RMSE</h2><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">evaluator</span><span class="o">=</span><span class="n">RegressionEvaluator</span><span class="p">(</span><span class="n">metricName</span><span class="o">=</span><span class="s">"rmse"</span><span class="p">,</span><span class="n">labelCol</span><span class="o">=</span><span class="s">"stars"</span><span class="p">,</span><span class="n">predictionCol</span><span class="o">=</span><span class="s">"prediction"</span><span class="p">)</span>
<span class="n">predictions</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">rmse</span><span class="o">=</span><span class="n">evaluator</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"RMSE="</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">))</span>
</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RMSE=1.3651734482322269
</code></pre></div></div><p>Our model is doing pretty well. We have achieved a 1.36 average squared error. Lets see an applied case of a recommendation for a customer.</p> <p>In future works we can include a step of parameter tunning as in <a href="http://restanalytics.com/2019-02-27-Hyperparameter-Tuning-Alternating-Least-Squares-Recommender-System/">here</a>.</p> <h2 id="visualize-recommendations">Visualize Recommendations</h2> <p>Now we visualise recommendations for user 30 (could be any other).</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">recommendForAllUsers</span><span class="p">(</span><span class="mi">20</span><span class="p">).</span><span class="nb">filter</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">'user_id_index'</span><span class="p">)</span><span class="o">==</span><span class="mi">30</span><span class="p">).</span><span class="n">select</span><span class="p">(</span><span class="s">"recommendations"</span><span class="p">).</span><span class="n">collect</span><span class="p">()</span>
<span class="n">topRestaurants</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]:</span>        
    <span class="n">topRestaurants</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="n">business_id_index</span><span class="p">)</span>
    
<span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span><span class="n">StructField</span><span class="p">(</span><span class="s">"business_id_index"</span><span class="p">,</span><span class="n">IntegerType</span><span class="p">(),</span><span class="bp">True</span><span class="p">)])</span>
<span class="n">restaurants</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">topRestaurants</span><span class="p">,</span><span class="n">IntegerType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"business_id_index"</span><span class="p">)</span>


<span class="n">transformed</span>\
<span class="p">.</span><span class="n">select</span><span class="p">([</span><span class="s">'business_id'</span><span class="p">,</span> <span class="s">'user_id'</span><span class="p">,</span> <span class="s">'stars'</span><span class="p">,</span> <span class="s">'categories'</span><span class="p">])</span>\
<span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">'user_id_index'</span><span class="p">)</span><span class="o">==</span><span class="mi">30</span><span class="p">)</span>\
<span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">restaurants</span>\
<span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">transformed</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="s">'business_id_index'</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s">'inner'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">select</span><span class="p">([</span><span class="s">'business_id'</span><span class="p">,</span> <span class="s">'stars'</span><span class="p">,</span> <span class="s">'categories'</span><span class="p">,</span> <span class="s">'name'</span><span class="p">])</span>\
<span class="p">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">'name'</span><span class="p">])</span>\
<span class="p">.</span><span class="n">show</span><span class="p">()</span>


</code></pre></div></div><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------+--------------------+-----+--------------------+
|         business_id|             user_id|stars|          categories|
+--------------------+--------------------+-----+--------------------+
|9XLH_grfIYKR7d5ZT...|i6V3NyTdkBVwPpH7r...|  2.0|Restaurants, Ital...|
|A7waf6G3cvnLfAqKe...|i6V3NyTdkBVwPpH7r...|  2.0|Restaurants, Italian|
|kuJRRmmmDUXqwM6kN...|i6V3NyTdkBVwPpH7r...|  4.0|Nightlife, Food, ...|
|aEnoF_79jQE83s-I7...|i6V3NyTdkBVwPpH7r...|  3.0|Food, Restaurants...|
|d4bVdEDwxmyB0M-w5...|i6V3NyTdkBVwPpH7r...|  4.0|Breakfast &amp; Brunc...|
|28adZ4lsuUeVB2aWz...|i6V3NyTdkBVwPpH7r...|  5.0|Bars, Food, Gastr...|
|cTbFJzHQzFSX-z3JF...|i6V3NyTdkBVwPpH7r...|  4.0|Restaurants, Amer...|
|eQCYur0033RkZdh5V...|i6V3NyTdkBVwPpH7r...|  3.0|Italian, Breakfas...|
|Ycp3Agr7dt71TZkeK...|i6V3NyTdkBVwPpH7r...|  3.0|French, Breakfast...|
|7HrCELR6uv2HkgL7a...|i6V3NyTdkBVwPpH7r...|  2.0|Restaurants, Seaf...|
|sHXIiGercy22UVpwM...|i6V3NyTdkBVwPpH7r...|  4.0|Comfort Food, Nig...|
|nDn2h-_c7Xk4UwM0a...|i6V3NyTdkBVwPpH7r...|  4.0|Mediterranean, Gr...|
|Cx0o524EbpLh8Luvj...|i6V3NyTdkBVwPpH7r...|  5.0|Mediterranean, Mi...|
|K5Q2vkF5UpytV9Q1r...|i6V3NyTdkBVwPpH7r...|  5.0|Restaurants, Japa...|
|lCwUmc0IEhIMz7lyZ...|i6V3NyTdkBVwPpH7r...|  5.0|Restaurants, Vege...|
|siaRCT2-PkyeXUVKr...|i6V3NyTdkBVwPpH7r...|  3.0|Restaurants, Chin...|
|O66Zy8Y13VBm72ZDh...|i6V3NyTdkBVwPpH7r...|  4.0|American (New), R...|
|KuIxm6FVNmlvpssWJ...|i6V3NyTdkBVwPpH7r...|  4.0|Mediterranean, Gr...|
|I2nw7LGLSHN4uUgnH...|i6V3NyTdkBVwPpH7r...|  3.0|American (New), F...|
|Ww-qDl1G9Kr7igS3o...|i6V3NyTdkBVwPpH7r...|  5.0|Restaurants, Amer...|
+--------------------+--------------------+-----+--------------------+
only showing top 20 rows

+--------------------+-----+--------------------+--------------------+
|         business_id|stars|          categories|                name|
+--------------------+-----+--------------------+--------------------+
|3VuAagJSUzWDgisd4...|  4.0|Canadian (New), B...|                Fuse|
|TiQBE6BdjSg9MF3UC...|  5.0|Indian, Sri Lanka...|         New Kalyani|
|nVFZTB3uwW_NkAlqI...|  5.0|Restaurants, Cate...|         Latte Booth|
|zNCGTEwBrmrVLfjxl...|  5.0|Desserts, Cafes, ...|Ballissimo Loukou...|
|MTneG8wJrUxIzIfnH...|  5.0|Event Planning &amp; ...|   Baby Point Lounge|
|xUsYf7lB0bi1zGEw4...|  5.0|Food, Barbeque, F...|Stoke Stack Barbecue|
|rdWy6OF9QldlIxlYV...|  4.0|Restaurants, Pers...|              Tabriz|
|eohcbvMCGegrUCDnj...|  5.0|Thai, Restaurants...|     Qinthai Cuisine|
|58pzEN_yy2hjPjtml...|  1.0|Restaurants, Fili...|     Kalesa Restobar|
|ScdakSPeGerwzJu2D...|  5.0|Pakistani, Indian...|      Shalimar Grill|
|Q0fQ5FRT0ug80Vk9X...|  5.0|Cocktail Bars, Re...|     Viajero Cantina|
|GFBiGcIZ8Wqm6wtTL...|  4.0|Restaurants, Chinese|    Taste of Qin Yun|
|fcayaG-BUicxcIZwG...|  5.0|Japanese, Restaur...|                Hiwa|
|Xja69DDoUqbPwFOSB...|  4.0|Restaurants, Pizz...|       Slice N Bites|
|4Nn9QoRDkOr-DWMF7...|  5.0|Portuguese, Resta...|Brasileirissimo S...|
|U7JrKn4fYW2RpJa7N...|  5.0|Restaurants, Cana...|The Carlton Resta...|
|CJq8OmZuScJ1jUUjx...|  5.0|Restaurants, Sush...|          Hoya Sushi|
|sSp-ZbEsVDKf8Y2OA...|  5.0|Cafes, Meat Shops...|   Speducci Mercatto|
|hT5kvnJnBWzUWrSpq...|  5.0|Chicken Wings, Ca...|       The Sky Stars|
|zWgoKXfq75Zhm8qcu...|  4.0|Sandwiches, Fast ...|           Euro Bite|
+--------------------+-----+--------------------+--------------------+
</code></pre></div></div></article></div><hr class="dashed" /><div class="container"><div class="row" data-aos="fade-up"><div class="col-md-12"><div class="share-box"> <i class="fa fa-share-alt" aria-hidden="true"></i> <a class="f nostyle" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/blog/Recommender-System/" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-facebook-official fa"></i ></a> <a class="t nostyle" href="https://twitter.com/intent/tweet?text=&url=http://localhost:4000/blog/Recommender-System/" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-twitter fa"></i ></a> <a class="g nostyle" href="https://plus.google.com/share?url=http://localhost:4000/blog/Recommender-System/" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-google-plus fa"></i ></a> <a class="r nostyle" href="http://www.reddit.com/submit?url=http://localhost:4000/blog/Recommender-System/" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-reddit fa"></i ></a> <a class="l nostyle" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/blog/Recommender-System/&title=&summary=&source=webjeda" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><i class="fa fa-linkedin fa"></i ></a> <a class="e nostyle" href="mailto:?subject=&amp;body=Check&amp;out&amp;this&amp;site&amp;http://localhost:4000/blog/Recommender-System/" ><i class="fa fa-envelope fa"></i ></a></div></div></div><div class="row"><div class="col-md-12"> <p class="categories" data-aos="fade-up"> <span><a href="/categories/#work">Work</a></span> <span><a href="/categories/#projects">Projects</a></span> </p></div></div><div id="disqus_thread" data-aos="fade-up"></div><script defer> (function() { var d = document, s = d.createElement("script"); s.src = "//webjeda-demo.disqus.com/embed.js"; s.setAttribute("data-timestamp", +new Date()); (d.head || d.body).appendChild(s); })();</script><noscript>Please enable JavaScript to view the comments</noscript><div class="recent" data-aos="fade-up"><div class=""> <h3>Recent Articles</h3></div><div class="recent-grid"><div class="items" data-aos="fade-up"> <a class="nostyle item" href="/blog/Bootstrap-to-Quantify-Uncertainty/"><div class="cards"><div class="image" style="background-image: url(/assets/images/bootstrap_inf.png)" ></div><p class="title"><small>Bootstrap to Quantify Uncertainty</small></p></div></a></div><div class="items" data-aos="fade-up"> <a class="nostyle item" href="/blog/EM-Clustering/"><div class="cards"><div class="image" style="background-image: url(/assets/images/cluster.png)" ></div><p class="title"><small>Expectation-Maximization for News Clustering</small></p></div></a></div></div></div></div></main><footer data-aos="fade-up"><div class="text-right"> <p class="copy"> <i class="fa fa-at"></i> 2018 <a class="rev" href="http://localhost:4000">Blackcurrant</a> </p></div></footer></div></div></div></div><!DOCTYPE html><html><head><meta name="viewport" content="width=device-width, initial-scale=1"> <style> .sidenav { width: 230px; position: fixed; z-index: 1; top: 100px; left: 30px; overflow-x: hidden; padding: 8px 0; } .sidenav a { padding: 6px 8px 6px 16px; text-decoration: none; color: #444; font-size: 22px; display: block; } .sidenav a:hover { color: #064579; } .top-bar { background-color: #222222; } @media only screen and (min-width: 800px) { #test { display: none; } } </style></head><body><div class="sidenav"> <style> #content-desktop { display: inline; } #content-mobile { display: none; } </style><div class="d-none d-sm-block"> <a href="http://www.alangewerc.com"><i class="fa fa-fw fa-home"></i> Home</a> <a href="http://www.alangewerc.com/projects"><i class="fa fa-area-chart"></i> Projects</a> <a href="http://www.alangewerc.com/blog"><i class="fa fa-book"></i> Articles</a> <a href="http://www.alangewerc.com/contact"><i class="fa fa-address-book-o"></i> Contact</a></div></div><script src="/assets/js/jQuery.min.js"></script><script> $(document).ready(function () { $(".loader").hide(); });</script><script> (function () { var css = document.createElement('link'); css.href = '/assets/font-awesome-4.7.0/css/font-awesome.min.css'; css.rel = 'stylesheet'; css.type = 'text/css'; document.getElementsByTagName('head')[0].appendChild(css); })();</script><noscript><link rel="stylesheet" href="/assets/font-awesome-4.7.0/css/font-awesome.min.css"> </noscript><script> $("#search-input").keyup(function () { $("main").hide(); $("search-container").show(); if (!$('#search-input').val()) { $("main").show(); $("search-container").hide(); } });</script><script src="/assets/js/jekyll-search.min.js" type="text/javascript"></script><script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-container'), searchResultTemplate: '<a class="nostyle" href="{url}"><div class="blog borders cards"><div class="image" style="background-image: url({image});"></div><div class="content"><h3 class="title">{title}</h3><p class="description">{description}</p></div></div></a>', noResultsText: 'No results found', json: '/search.json' })</script><script> (function () { var css = document.createElement('link'); css.href = 'https://unpkg.com/aos@2.3.1/dist/aos.css'; css.rel = 'stylesheet'; css.type = 'text/css'; document.getElementsByTagName('head')[0].appendChild(css); })();</script><noscript><link rel="stylesheet" href="/assets/animate-on-scroll/aos.min.css"> </noscript><script src="/assets/animate-on-scroll/aos.min.js"></script><script> AOS.init({ duration: 600, once: true, disable: 'mobile' });</script></body></html>